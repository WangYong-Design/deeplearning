(Iteration 1 ) loss: 1.804881
(Iteration 21 ) loss: 1.026443
(Iteration 41 ) loss: 0.422634
(Iteration 61 ) loss: 0.795064
(Iteration 81 ) loss: 0.579908
(Iteration 101 ) loss: 0.502443
(Iteration 121 ) loss: 0.436177
(Iteration 141 ) loss: 0.860532
(Iteration 161 ) loss: 0.323378
(Iteration 181 ) loss: 0.405534
(Iteration 201 ) loss: 0.405727
(Iteration 221 ) loss: 0.539472
(Iteration 241 ) loss: 0.175584
(Iteration 261 ) loss: 0.388056
(Iteration 281 ) loss: 0.390568
(Iteration 301 ) loss: 0.497878
(Iteration 321 ) loss: 0.593863
(Iteration 341 ) loss: 0.626605
(Iteration 361 ) loss: 0.457124
(Iteration 381 ) loss: 0.238810
(Iteration 401 ) loss: 0.138389
(Iteration 421 ) loss: 0.240927
(Iteration 441 ) loss: 0.083329
(Iteration 461 ) loss: 0.293660
(Iteration 481 ) loss: 0.342104
(Iteration 501 ) loss: 0.353900
(Iteration 521 ) loss: 0.339944
(Iteration 541 ) loss: 0.273745
(Iteration 561 ) loss: 0.481066
(Iteration 581 ) loss: 0.178224
(Iteration 601 ) loss: 0.152773
(Iteration 621 ) loss: 0.271553
(Iteration 641 ) loss: 0.197992
(Iteration 661 ) loss: 0.172014
(Iteration 681 ) loss: 0.271722
(Iteration 701 ) loss: 0.734196
(Iteration 721 ) loss: 0.276232
(Iteration 741 ) loss: 0.306969
(Iteration 761 ) loss: 0.386967
(Iteration 781 ) loss: 0.141401
(Iteration 801 ) loss: 0.309707
(Iteration 821 ) loss: 0.407188
(Iteration 841 ) loss: 0.238928
(Iteration 861 ) loss: 0.185599
(Iteration 881 ) loss: 0.224220
(Iteration 901 ) loss: 0.556812
(Iteration 921 ) loss: 0.235054
(Iteration 941 ) loss: 0.115372
(Iteration 961 ) loss: 0.336715
(Iteration 981 ) loss: 0.054747
(Epoch 0 % 100) train loss: 0.32299384589977753, eval loss: 0.33409342752137566
(Iteration 1 ) loss: 0.293320
(Iteration 21 ) loss: 0.530860
(Iteration 41 ) loss: 0.268107
(Iteration 61 ) loss: 0.320325
(Iteration 81 ) loss: 0.539860
(Iteration 101 ) loss: 0.357554
(Iteration 121 ) loss: 0.551384
(Iteration 141 ) loss: 0.219816
(Iteration 161 ) loss: 0.365135
(Iteration 181 ) loss: 0.385794
(Iteration 201 ) loss: 0.312907
(Iteration 221 ) loss: 0.392045
(Iteration 241 ) loss: 0.272625
(Iteration 261 ) loss: 0.386830
(Iteration 281 ) loss: 0.231280
(Iteration 301 ) loss: 0.159655
(Iteration 321 ) loss: 0.108520
(Iteration 341 ) loss: 0.347252
(Iteration 361 ) loss: 0.500481
(Iteration 381 ) loss: 0.315645
(Iteration 401 ) loss: 0.120564
(Iteration 421 ) loss: 0.296087
(Iteration 441 ) loss: 0.325475
(Iteration 461 ) loss: 0.526783
(Iteration 481 ) loss: 0.179331
(Iteration 501 ) loss: 0.164827
(Iteration 521 ) loss: 0.416391
(Iteration 541 ) loss: 0.486402
(Iteration 561 ) loss: 0.176396
(Iteration 581 ) loss: 0.480180
(Iteration 601 ) loss: 0.261314
(Iteration 621 ) loss: 0.300108
(Iteration 641 ) loss: 0.549464
(Iteration 661 ) loss: 0.291405
(Iteration 681 ) loss: 0.198666
(Iteration 701 ) loss: 0.232177
(Iteration 721 ) loss: 0.465614
(Iteration 741 ) loss: 0.261560
(Iteration 761 ) loss: 0.179024
(Iteration 781 ) loss: 0.634891
(Iteration 801 ) loss: 0.081935
(Iteration 821 ) loss: 0.221261
(Iteration 841 ) loss: 0.353353
(Iteration 861 ) loss: 0.190377
(Iteration 881 ) loss: 0.289792
(Iteration 901 ) loss: 0.342058
(Iteration 921 ) loss: 0.367288
(Iteration 941 ) loss: 0.189728
(Iteration 961 ) loss: 0.217607
(Iteration 981 ) loss: 0.205260
(Epoch 1 % 100) train loss: 0.2717497646671244, eval loss: 0.2627493860662432
(Iteration 1 ) loss: 0.316321
(Iteration 21 ) loss: 0.232148
(Iteration 41 ) loss: 0.119951
(Iteration 61 ) loss: 0.175787
(Iteration 81 ) loss: 0.159598
(Iteration 101 ) loss: 0.057135
(Iteration 121 ) loss: 0.191431
(Iteration 141 ) loss: 0.122630
(Iteration 161 ) loss: 0.288308
(Iteration 181 ) loss: 0.270479
(Iteration 201 ) loss: 0.324365
(Iteration 221 ) loss: 0.284118
(Iteration 241 ) loss: 0.316990
(Iteration 261 ) loss: 0.397139
(Iteration 281 ) loss: 0.046841
(Iteration 301 ) loss: 0.331149
(Iteration 321 ) loss: 0.270851
(Iteration 341 ) loss: 0.361532
(Iteration 361 ) loss: 0.143708
(Iteration 381 ) loss: 0.427638
(Iteration 401 ) loss: 0.104134
(Iteration 421 ) loss: 0.131241
(Iteration 441 ) loss: 0.214185
(Iteration 461 ) loss: 0.276517
(Iteration 481 ) loss: 0.322279
(Iteration 501 ) loss: 0.140161
(Iteration 521 ) loss: 0.114955
(Iteration 541 ) loss: 0.112343
(Iteration 561 ) loss: 0.196164
(Iteration 581 ) loss: 0.170728
(Iteration 601 ) loss: 0.235254
(Iteration 621 ) loss: 0.126243
(Iteration 641 ) loss: 0.207604
(Iteration 661 ) loss: 0.264874
(Iteration 681 ) loss: 0.226700
(Iteration 701 ) loss: 0.108332
(Iteration 721 ) loss: 0.074749
(Iteration 741 ) loss: 0.185678
(Iteration 761 ) loss: 0.171261
(Iteration 781 ) loss: 0.109263
(Iteration 801 ) loss: 0.144923
(Iteration 821 ) loss: 0.299398
(Iteration 841 ) loss: 0.071657
(Iteration 861 ) loss: 0.131825
(Iteration 881 ) loss: 0.248379
(Iteration 901 ) loss: 0.066782
(Iteration 921 ) loss: 0.192809
(Iteration 941 ) loss: 0.227900
(Iteration 961 ) loss: 0.139205
(Iteration 981 ) loss: 0.065288
(Epoch 2 % 100) train loss: 0.13364383588153947, eval loss: 0.12939242816313384
(Iteration 1 ) loss: 0.143079
(Iteration 21 ) loss: 0.188527
(Iteration 41 ) loss: 0.180057
(Iteration 61 ) loss: 0.212493
(Iteration 81 ) loss: 0.045296
(Iteration 101 ) loss: 0.131178
(Iteration 121 ) loss: 0.048743
(Iteration 141 ) loss: 0.078201
(Iteration 161 ) loss: 0.264613
(Iteration 181 ) loss: 0.094539
(Iteration 201 ) loss: 0.083502
(Iteration 221 ) loss: 0.147902
(Iteration 241 ) loss: 0.057700
(Iteration 261 ) loss: 0.070177
(Iteration 281 ) loss: 0.037906
(Iteration 301 ) loss: 0.039384
(Iteration 321 ) loss: 0.090813
(Iteration 341 ) loss: 0.050882
(Iteration 361 ) loss: 0.123596
(Iteration 381 ) loss: 0.368341
(Iteration 401 ) loss: 0.068826
(Iteration 421 ) loss: 0.065575
(Iteration 441 ) loss: 0.033430
(Iteration 461 ) loss: 0.073150
(Iteration 481 ) loss: 0.107703
(Iteration 501 ) loss: 0.161146
(Iteration 521 ) loss: 0.137139
(Iteration 541 ) loss: 0.129852
(Iteration 561 ) loss: 0.107032
(Iteration 581 ) loss: 0.103245
(Iteration 601 ) loss: 0.094865
(Iteration 621 ) loss: 0.146667
(Iteration 641 ) loss: 0.048679
(Iteration 661 ) loss: 0.015181
(Iteration 681 ) loss: 0.094903
(Iteration 701 ) loss: 0.083580
(Iteration 721 ) loss: 0.050781
(Iteration 741 ) loss: 0.115591
(Iteration 761 ) loss: 0.013467
(Iteration 781 ) loss: 0.059153
(Iteration 801 ) loss: 0.076632
(Iteration 821 ) loss: 0.298461
(Iteration 841 ) loss: 0.236631
(Iteration 861 ) loss: 0.285420
(Iteration 881 ) loss: 0.108230
(Iteration 901 ) loss: 0.145971
(Iteration 921 ) loss: 0.048261
(Iteration 941 ) loss: 0.081230
(Iteration 961 ) loss: 0.009278
(Iteration 981 ) loss: 0.042672
(Epoch 3 % 100) train loss: 0.09764539381491792, eval loss: 0.09623041762822236
(Iteration 1 ) loss: 0.090642
(Iteration 21 ) loss: 0.099859
(Iteration 41 ) loss: 0.026256
(Iteration 61 ) loss: 0.309101
(Iteration 81 ) loss: 0.060423
(Iteration 101 ) loss: 0.150178
(Iteration 121 ) loss: 0.079053
(Iteration 141 ) loss: 0.032734
(Iteration 161 ) loss: 0.075258
(Iteration 181 ) loss: 0.013052
(Iteration 201 ) loss: 0.063841
(Iteration 221 ) loss: 0.053647
(Iteration 241 ) loss: 0.107465
(Iteration 261 ) loss: 0.003388
(Iteration 281 ) loss: 0.034999
(Iteration 301 ) loss: 0.030434
(Iteration 321 ) loss: 0.059082
(Iteration 341 ) loss: 0.007082
(Iteration 361 ) loss: 0.059157
(Iteration 381 ) loss: 0.109730
(Iteration 401 ) loss: 0.075453
(Iteration 421 ) loss: 0.088122
(Iteration 441 ) loss: 0.077620
(Iteration 461 ) loss: 0.154373
(Iteration 481 ) loss: 0.062599
(Iteration 501 ) loss: 0.085406
(Iteration 521 ) loss: 0.050822
(Iteration 541 ) loss: 0.092098
(Iteration 561 ) loss: 0.135273
(Iteration 581 ) loss: 0.015998
(Iteration 601 ) loss: 0.052853
(Iteration 621 ) loss: 0.032792
(Iteration 641 ) loss: 0.013780
(Iteration 661 ) loss: 0.097788
(Iteration 681 ) loss: 0.077900
(Iteration 701 ) loss: 0.073686
(Iteration 721 ) loss: 0.193059
(Iteration 741 ) loss: 0.019838
(Iteration 761 ) loss: 0.030936
(Iteration 781 ) loss: 0.027087
(Iteration 801 ) loss: 0.159553
(Iteration 821 ) loss: 0.018037
(Iteration 841 ) loss: 0.016020
(Iteration 861 ) loss: 0.032734
(Iteration 881 ) loss: 0.153583
(Iteration 901 ) loss: 0.135673
(Iteration 921 ) loss: 0.142326
(Iteration 941 ) loss: 0.109585
(Iteration 961 ) loss: 0.022250
(Iteration 981 ) loss: 0.025777
(Epoch 4 % 100) train loss: 0.07063719896717549, eval loss: 0.07454733236023935
(Iteration 1 ) loss: 0.060772
(Iteration 21 ) loss: 0.024633
(Iteration 41 ) loss: 0.034181
(Iteration 61 ) loss: 0.079536
(Iteration 81 ) loss: 0.098984
(Iteration 101 ) loss: 0.061011
(Iteration 121 ) loss: 0.045715
(Iteration 141 ) loss: 0.075537
(Iteration 161 ) loss: 0.226487
(Iteration 181 ) loss: 0.264259
(Iteration 201 ) loss: 0.049017
(Iteration 221 ) loss: 0.033978
(Iteration 241 ) loss: 0.126816
(Iteration 261 ) loss: 0.094629
(Iteration 281 ) loss: 0.077092
(Iteration 301 ) loss: 0.108986
(Iteration 321 ) loss: 0.010423
(Iteration 341 ) loss: 0.020440
(Iteration 361 ) loss: 0.024414
(Iteration 381 ) loss: 0.013743
(Iteration 401 ) loss: 0.068024
(Iteration 421 ) loss: 0.027783
(Iteration 441 ) loss: 0.055942
(Iteration 461 ) loss: 0.072345
(Iteration 481 ) loss: 0.036802
(Iteration 501 ) loss: 0.020683
(Iteration 521 ) loss: 0.068752
(Iteration 541 ) loss: 0.084693
(Iteration 561 ) loss: 0.024481
(Iteration 581 ) loss: 0.021359
(Iteration 601 ) loss: 0.159936
(Iteration 621 ) loss: 0.112025
(Iteration 641 ) loss: 0.022875
(Iteration 661 ) loss: 0.042679
(Iteration 681 ) loss: 0.075729
(Iteration 701 ) loss: 0.004300
(Iteration 721 ) loss: 0.144923
(Iteration 741 ) loss: 0.060962
(Iteration 761 ) loss: 0.132687
(Iteration 781 ) loss: 0.011642
(Iteration 801 ) loss: 0.030823
(Iteration 821 ) loss: 0.014946
(Iteration 841 ) loss: 0.029297
(Iteration 861 ) loss: 0.002502
(Iteration 881 ) loss: 0.024275
(Iteration 901 ) loss: 0.150793
(Iteration 921 ) loss: 0.091043
(Iteration 941 ) loss: 0.036945
(Iteration 961 ) loss: 0.030369
(Iteration 981 ) loss: 0.056351
(Epoch 5 % 100) train loss: 0.04707814355536864, eval loss: 0.04994785377035711
(Iteration 1 ) loss: 0.093362
(Iteration 21 ) loss: 0.047804
(Iteration 41 ) loss: 0.058986
(Iteration 61 ) loss: 0.043399
(Iteration 81 ) loss: 0.019368
(Iteration 101 ) loss: 0.028145
(Iteration 121 ) loss: 0.038468
(Iteration 141 ) loss: 0.005548
(Iteration 161 ) loss: 0.026647
(Iteration 181 ) loss: 0.016446
(Iteration 201 ) loss: 0.020744
(Iteration 221 ) loss: 0.113137
(Iteration 241 ) loss: 0.017091
(Iteration 261 ) loss: 0.021489
(Iteration 281 ) loss: 0.100051
(Iteration 301 ) loss: 0.024773
(Iteration 321 ) loss: 0.018415
(Iteration 341 ) loss: 0.106503
(Iteration 361 ) loss: 0.019431
(Iteration 381 ) loss: 0.095025
(Iteration 401 ) loss: 0.015078
(Iteration 421 ) loss: 0.058247
(Iteration 441 ) loss: 0.016891
(Iteration 461 ) loss: 0.003729
(Iteration 481 ) loss: 0.028113
(Iteration 501 ) loss: 0.010001
(Iteration 521 ) loss: 0.014694
(Iteration 541 ) loss: 0.009777
(Iteration 561 ) loss: 0.157701
(Iteration 581 ) loss: 0.024116
(Iteration 601 ) loss: 0.019899
(Iteration 621 ) loss: 0.041697
(Iteration 641 ) loss: 0.011262
(Iteration 661 ) loss: 0.038401
(Iteration 681 ) loss: 0.033707
(Iteration 701 ) loss: 0.031768
(Iteration 721 ) loss: 0.012800
(Iteration 741 ) loss: 0.086830
(Iteration 761 ) loss: 0.053408
(Iteration 781 ) loss: 0.031751
(Iteration 801 ) loss: 0.020964
(Iteration 821 ) loss: 0.029920
(Iteration 841 ) loss: 0.020049
(Iteration 861 ) loss: 0.052145
(Iteration 881 ) loss: 0.013043
(Iteration 901 ) loss: 0.062113
(Iteration 921 ) loss: 0.031172
(Iteration 941 ) loss: 0.064466
(Iteration 961 ) loss: 0.014585
(Iteration 981 ) loss: 0.074527
(Epoch 6 % 100) train loss: 0.05097954985408096, eval loss: 0.053442594363771065
(Iteration 1 ) loss: 0.072245
(Iteration 21 ) loss: 0.002959
(Iteration 41 ) loss: 0.057112
(Iteration 61 ) loss: 0.148200
(Iteration 81 ) loss: 0.032473
(Iteration 101 ) loss: 0.027445
(Iteration 121 ) loss: 0.039223
(Iteration 141 ) loss: 0.033478
(Iteration 161 ) loss: 0.016236
(Iteration 181 ) loss: 0.005620
(Iteration 201 ) loss: 0.047333
(Iteration 221 ) loss: 0.013320
(Iteration 241 ) loss: 0.004135
(Iteration 261 ) loss: 0.016677
(Iteration 281 ) loss: 0.003250
(Iteration 301 ) loss: 0.024671
(Iteration 321 ) loss: 0.121657
(Iteration 341 ) loss: 0.007954
(Iteration 361 ) loss: 0.196428
(Iteration 381 ) loss: 0.038445
(Iteration 401 ) loss: 0.004815
(Iteration 421 ) loss: 0.072396
(Iteration 441 ) loss: 0.005604
(Iteration 461 ) loss: 0.014738
(Iteration 481 ) loss: 0.006628
(Iteration 501 ) loss: 0.007476
(Iteration 521 ) loss: 0.052382
(Iteration 541 ) loss: 0.051233
(Iteration 561 ) loss: 0.037764
(Iteration 581 ) loss: 0.041958
(Iteration 601 ) loss: 0.005349
(Iteration 621 ) loss: 0.024506
(Iteration 641 ) loss: 0.071295
(Iteration 661 ) loss: 0.080276
(Iteration 681 ) loss: 0.011408
(Iteration 701 ) loss: 0.023061
(Iteration 721 ) loss: 0.124010
(Iteration 741 ) loss: 0.012589
(Iteration 761 ) loss: 0.029845
(Iteration 781 ) loss: 0.002944
(Iteration 801 ) loss: 0.031171
(Iteration 821 ) loss: 0.012233
(Iteration 841 ) loss: 0.027940
(Iteration 861 ) loss: 0.127474
(Iteration 881 ) loss: 0.091742
(Iteration 901 ) loss: 0.016150
(Iteration 921 ) loss: 0.022357
(Iteration 941 ) loss: 0.072272
(Iteration 961 ) loss: 0.007872
(Iteration 981 ) loss: 0.038405
(Epoch 7 % 100) train loss: 0.03125772887255067, eval loss: 0.03200447228989443
(Iteration 1 ) loss: 0.095156
(Iteration 21 ) loss: 0.019144
(Iteration 41 ) loss: 0.065089
(Iteration 61 ) loss: 0.048121
(Iteration 81 ) loss: 0.039254
(Iteration 101 ) loss: 0.052512
(Iteration 121 ) loss: 0.072295
(Iteration 141 ) loss: 0.003248
(Iteration 161 ) loss: 0.050009
(Iteration 181 ) loss: 0.009849
(Iteration 201 ) loss: 0.047330
(Iteration 221 ) loss: 0.055633
(Iteration 241 ) loss: 0.043732
(Iteration 261 ) loss: 0.009141
(Iteration 281 ) loss: 0.009278
(Iteration 301 ) loss: 0.125329
(Iteration 321 ) loss: 0.183319
(Iteration 341 ) loss: 0.012358
(Iteration 361 ) loss: 0.014976
(Iteration 381 ) loss: 0.074336
(Iteration 401 ) loss: 0.026629
(Iteration 421 ) loss: 0.046641
(Iteration 441 ) loss: 0.028133
(Iteration 461 ) loss: 0.105881
(Iteration 481 ) loss: 0.031685
(Iteration 501 ) loss: 0.037114
(Iteration 521 ) loss: 0.017749
(Iteration 541 ) loss: 0.064080
(Iteration 561 ) loss: 0.044056
(Iteration 581 ) loss: 0.004283
(Iteration 601 ) loss: 0.038522
(Iteration 621 ) loss: 0.003150
(Iteration 641 ) loss: 0.004282
(Iteration 661 ) loss: 0.030947
(Iteration 681 ) loss: 0.112194
(Iteration 701 ) loss: 0.005942
(Iteration 721 ) loss: 0.016481
(Iteration 741 ) loss: 0.021463
(Iteration 761 ) loss: 0.023883
(Iteration 781 ) loss: 0.034802
(Iteration 801 ) loss: 0.132409
(Iteration 821 ) loss: 0.031071
(Iteration 841 ) loss: 0.047583
(Iteration 861 ) loss: 0.011683
(Iteration 881 ) loss: 0.007545
(Iteration 901 ) loss: 0.034111
(Iteration 921 ) loss: 0.053601
(Iteration 941 ) loss: 0.017916
(Iteration 961 ) loss: 0.046665
(Iteration 981 ) loss: 0.016521
(Epoch 8 % 100) train loss: 0.020521096075056554, eval loss: 0.021503389999386932
(Iteration 1 ) loss: 0.001159
(Iteration 21 ) loss: 0.026895
(Iteration 41 ) loss: 0.013696
(Iteration 61 ) loss: 0.012556
(Iteration 81 ) loss: 0.007120
(Iteration 101 ) loss: 0.001437
(Iteration 121 ) loss: 0.004822
(Iteration 141 ) loss: 0.013835
(Iteration 161 ) loss: 0.006643
(Iteration 181 ) loss: 0.012517
(Iteration 201 ) loss: 0.001591
(Iteration 221 ) loss: 0.004522
(Iteration 241 ) loss: 0.022225
(Iteration 261 ) loss: 0.053595
(Iteration 281 ) loss: 0.003229
(Iteration 301 ) loss: 0.022765
(Iteration 321 ) loss: 0.018110
(Iteration 341 ) loss: 0.007079
(Iteration 361 ) loss: 0.011343
(Iteration 381 ) loss: 0.014485
(Iteration 401 ) loss: 0.008023
(Iteration 421 ) loss: 0.044866
(Iteration 441 ) loss: 0.011180
(Iteration 461 ) loss: 0.015610
(Iteration 481 ) loss: 0.040364
(Iteration 501 ) loss: 0.042325
(Iteration 521 ) loss: 0.016405
(Iteration 541 ) loss: 0.013450
(Iteration 561 ) loss: 0.003915
(Iteration 581 ) loss: 0.025347
(Iteration 601 ) loss: 0.002229
(Iteration 621 ) loss: 0.016616
(Iteration 641 ) loss: 0.006796
(Iteration 661 ) loss: 0.007185
(Iteration 681 ) loss: 0.017797
(Iteration 701 ) loss: 0.063894
(Iteration 721 ) loss: 0.012039
(Iteration 741 ) loss: 0.037778
(Iteration 761 ) loss: 0.014667
(Iteration 781 ) loss: 0.025094
(Iteration 801 ) loss: 0.017105
(Iteration 821 ) loss: 0.000771
(Iteration 841 ) loss: 0.001982
(Iteration 861 ) loss: 0.015146
(Iteration 881 ) loss: 0.017503
(Iteration 901 ) loss: 0.005352
(Iteration 921 ) loss: 0.012858
(Iteration 941 ) loss: 0.026172
(Iteration 961 ) loss: 0.077797
(Iteration 981 ) loss: 0.033128
(Epoch 9 % 100) train loss: 0.022391032799217087, eval loss: 0.022145011807194512
(Iteration 1 ) loss: 0.005829
(Iteration 21 ) loss: 0.023325
(Iteration 41 ) loss: 0.033985
(Iteration 61 ) loss: 0.000187
(Iteration 81 ) loss: 0.055836
(Iteration 101 ) loss: 0.113398
(Iteration 121 ) loss: 0.007752
(Iteration 141 ) loss: 0.004393
(Iteration 161 ) loss: 0.092844
(Iteration 181 ) loss: 0.002686
(Iteration 201 ) loss: 0.015954
(Iteration 221 ) loss: 0.015450
(Iteration 241 ) loss: 0.003760
(Iteration 261 ) loss: 0.002787
(Iteration 281 ) loss: 0.020971
(Iteration 301 ) loss: 0.029542
(Iteration 321 ) loss: 0.008987
(Iteration 341 ) loss: 0.012790
(Iteration 361 ) loss: 0.031296
(Iteration 381 ) loss: 0.018132
(Iteration 401 ) loss: 0.029178
(Iteration 421 ) loss: 0.030788
(Iteration 441 ) loss: 0.013267
(Iteration 461 ) loss: 0.002697
(Iteration 481 ) loss: 0.005245
(Iteration 501 ) loss: 0.022484
(Iteration 521 ) loss: 0.005968
(Iteration 541 ) loss: 0.006795
(Iteration 561 ) loss: 0.016525
(Iteration 581 ) loss: 0.070810
(Iteration 601 ) loss: 0.003838
(Iteration 621 ) loss: 0.009014
(Iteration 641 ) loss: 0.046716
(Iteration 661 ) loss: 0.007672
(Iteration 681 ) loss: 0.022010
(Iteration 701 ) loss: 0.030076
(Iteration 721 ) loss: 0.061138
(Iteration 741 ) loss: 0.038293
(Iteration 761 ) loss: 0.011826
(Iteration 781 ) loss: 0.010210
(Iteration 801 ) loss: 0.022478
(Iteration 821 ) loss: 0.002491
(Iteration 841 ) loss: 0.021258
(Iteration 861 ) loss: 0.037198
(Iteration 881 ) loss: 0.050996
(Iteration 901 ) loss: 0.014466
(Iteration 921 ) loss: 0.074653
(Iteration 941 ) loss: 0.030115
(Iteration 961 ) loss: 0.021249
(Iteration 981 ) loss: 0.022463
(Epoch 10 % 100) train loss: 0.015992239838516994, eval loss: 0.017593316000709056
(Iteration 1 ) loss: 0.007136
(Iteration 21 ) loss: 0.009092
(Iteration 41 ) loss: 0.022603
(Iteration 61 ) loss: 0.007356
(Iteration 81 ) loss: 0.013749
(Iteration 101 ) loss: 0.003372
(Iteration 121 ) loss: 0.011632
(Iteration 141 ) loss: 0.028955
(Iteration 161 ) loss: 0.004602
(Iteration 181 ) loss: 0.011971
(Iteration 201 ) loss: 0.004482
(Iteration 221 ) loss: 0.008502
(Iteration 241 ) loss: 0.002515
(Iteration 261 ) loss: 0.040856
(Iteration 281 ) loss: 0.011568
(Iteration 301 ) loss: 0.003277
(Iteration 321 ) loss: 0.002759
(Iteration 341 ) loss: 0.047587
(Iteration 361 ) loss: 0.077845
(Iteration 381 ) loss: 0.017202
(Iteration 401 ) loss: 0.034091
(Iteration 421 ) loss: 0.029505
(Iteration 441 ) loss: 0.046207
(Iteration 461 ) loss: 0.006269
(Iteration 481 ) loss: 0.003457
(Iteration 501 ) loss: 0.016643
(Iteration 521 ) loss: 0.007391
(Iteration 541 ) loss: 0.034116
(Iteration 561 ) loss: 0.036329
(Iteration 581 ) loss: 0.005779
(Iteration 601 ) loss: 0.004560
(Iteration 621 ) loss: 0.014428
(Iteration 641 ) loss: 0.011163
(Iteration 661 ) loss: 0.006674
(Iteration 681 ) loss: 0.002736
(Iteration 701 ) loss: 0.029573
(Iteration 721 ) loss: 0.004946
(Iteration 741 ) loss: 0.009838
(Iteration 761 ) loss: 0.012546
(Iteration 781 ) loss: 0.002229
(Iteration 801 ) loss: 0.009051
(Iteration 821 ) loss: 0.029940
(Iteration 841 ) loss: 0.001122
(Iteration 861 ) loss: 0.019823
(Iteration 881 ) loss: 0.005468
(Iteration 901 ) loss: 0.054539
(Iteration 921 ) loss: 0.011760
(Iteration 941 ) loss: 0.012914
(Iteration 961 ) loss: 0.005325
(Iteration 981 ) loss: 0.013241
(Epoch 11 % 100) train loss: 0.014274938608486278, eval loss: 0.015573927268999855
(Iteration 1 ) loss: 0.020410
(Iteration 21 ) loss: 0.005249
(Iteration 41 ) loss: 0.050499
(Iteration 61 ) loss: 0.009396
(Iteration 81 ) loss: 0.010740
(Iteration 101 ) loss: 0.007253
(Iteration 121 ) loss: 0.056809
(Iteration 141 ) loss: 0.001372
(Iteration 161 ) loss: 0.030277
(Iteration 181 ) loss: 0.024289
(Iteration 201 ) loss: 0.017263
(Iteration 221 ) loss: 0.013422
(Iteration 241 ) loss: 0.004880
(Iteration 261 ) loss: 0.014179
(Iteration 281 ) loss: 0.033438
(Iteration 301 ) loss: 0.011695
(Iteration 321 ) loss: 0.009145
(Iteration 341 ) loss: 0.002700
(Iteration 361 ) loss: 0.003843
(Iteration 381 ) loss: 0.080081
(Iteration 401 ) loss: 0.019464
(Iteration 421 ) loss: 0.026600
(Iteration 441 ) loss: 0.040846
(Iteration 461 ) loss: 0.000987
(Iteration 481 ) loss: 0.060246
(Iteration 501 ) loss: 0.009123
(Iteration 521 ) loss: 0.018468
(Iteration 541 ) loss: 0.011216
(Iteration 561 ) loss: 0.003083
(Iteration 581 ) loss: 0.005758
(Iteration 601 ) loss: 0.003105
(Iteration 621 ) loss: 0.045999
(Iteration 641 ) loss: 0.106863
(Iteration 661 ) loss: 0.017498
(Iteration 681 ) loss: 0.006937
(Iteration 701 ) loss: 0.011742
(Iteration 721 ) loss: 0.008486
(Iteration 741 ) loss: 0.001582
(Iteration 761 ) loss: 0.005987
(Iteration 781 ) loss: 0.006812
(Iteration 801 ) loss: 0.044753
(Iteration 821 ) loss: 0.003063
(Iteration 841 ) loss: 0.003843
(Iteration 861 ) loss: 0.024490
(Iteration 881 ) loss: 0.026856
(Iteration 901 ) loss: 0.039576
(Iteration 921 ) loss: 0.008873
(Iteration 941 ) loss: 0.017211
(Iteration 961 ) loss: 0.020317
(Iteration 981 ) loss: 0.007996
(Epoch 12 % 100) train loss: 0.012816226062873682, eval loss: 0.013901819857310977
(Iteration 1 ) loss: 0.034141
(Iteration 21 ) loss: 0.007430
(Iteration 41 ) loss: 0.033328
(Iteration 61 ) loss: 0.003824
(Iteration 81 ) loss: 0.007347
(Iteration 101 ) loss: 0.011711
(Iteration 121 ) loss: 0.021290
(Iteration 141 ) loss: 0.032023
(Iteration 161 ) loss: 0.009613
(Iteration 181 ) loss: 0.019006
(Iteration 201 ) loss: 0.011166
(Iteration 221 ) loss: 0.034668
(Iteration 241 ) loss: 0.016793
(Iteration 261 ) loss: 0.005295
(Iteration 281 ) loss: 0.011799
(Iteration 301 ) loss: 0.004394
(Iteration 321 ) loss: 0.038244
(Iteration 341 ) loss: 0.030165
(Iteration 361 ) loss: 0.002133
(Iteration 381 ) loss: 0.008154
(Iteration 401 ) loss: 0.019404
(Iteration 421 ) loss: 0.004476
(Iteration 441 ) loss: 0.003728
(Iteration 461 ) loss: 0.009462
(Iteration 481 ) loss: 0.019093
(Iteration 501 ) loss: 0.022495
(Iteration 521 ) loss: 0.011501
(Iteration 541 ) loss: 0.003748
(Iteration 561 ) loss: 0.008292
(Iteration 581 ) loss: 0.016742
(Iteration 601 ) loss: 0.006037
(Iteration 621 ) loss: 0.028892
(Iteration 641 ) loss: 0.013507
(Iteration 661 ) loss: 0.013561
(Iteration 681 ) loss: 0.039248
(Iteration 701 ) loss: 0.001236
(Iteration 721 ) loss: 0.008224
(Iteration 741 ) loss: 0.027685
(Iteration 761 ) loss: 0.005781
(Iteration 781 ) loss: 0.008757
(Iteration 801 ) loss: 0.001474
(Iteration 821 ) loss: 0.013951
(Iteration 841 ) loss: 0.009275
(Iteration 861 ) loss: 0.005843
(Iteration 881 ) loss: 0.017677
(Iteration 901 ) loss: 0.006054
(Iteration 921 ) loss: 0.015164
(Iteration 941 ) loss: 0.006859
(Iteration 961 ) loss: 0.008527
(Iteration 981 ) loss: 0.005726
(Epoch 13 % 100) train loss: 0.012178819255246057, eval loss: 0.0145570266947051
(Iteration 1 ) loss: 0.004448
(Iteration 21 ) loss: 0.022362
(Iteration 41 ) loss: 0.009002
(Iteration 61 ) loss: 0.010526
(Iteration 81 ) loss: 0.038677
(Iteration 101 ) loss: 0.018359
(Iteration 121 ) loss: 0.006778
(Iteration 141 ) loss: 0.019387
(Iteration 161 ) loss: 0.002322
(Iteration 181 ) loss: 0.005210
(Iteration 201 ) loss: 0.003505
(Iteration 221 ) loss: 0.018092
(Iteration 241 ) loss: 0.013693
(Iteration 261 ) loss: 0.007279
(Iteration 281 ) loss: 0.005625
(Iteration 301 ) loss: 0.003734
(Iteration 321 ) loss: 0.001718
(Iteration 341 ) loss: 0.026230
(Iteration 361 ) loss: 0.003624
(Iteration 381 ) loss: 0.020188
(Iteration 401 ) loss: 0.001204
(Iteration 421 ) loss: 0.009198
(Iteration 441 ) loss: 0.028671
(Iteration 461 ) loss: 0.002556
(Iteration 481 ) loss: 0.014754
(Iteration 501 ) loss: 0.006561
(Iteration 521 ) loss: 0.049880
(Iteration 541 ) loss: 0.001275
(Iteration 561 ) loss: 0.004144
(Iteration 581 ) loss: 0.002426
(Iteration 601 ) loss: 0.003531
(Iteration 621 ) loss: 0.014195
(Iteration 641 ) loss: 0.013991
(Iteration 661 ) loss: 0.024933
(Iteration 681 ) loss: 0.029933
(Iteration 701 ) loss: 0.002139
(Iteration 721 ) loss: 0.004537
(Iteration 741 ) loss: 0.021591
(Iteration 761 ) loss: 0.000737
(Iteration 781 ) loss: 0.001723
(Iteration 801 ) loss: 0.018072
(Iteration 821 ) loss: 0.009949
(Iteration 841 ) loss: 0.020040
(Iteration 861 ) loss: 0.018054
(Iteration 881 ) loss: 0.008430
(Iteration 901 ) loss: 0.004925
(Iteration 921 ) loss: 0.028884
(Iteration 941 ) loss: 0.010268
(Iteration 961 ) loss: 0.004777
(Iteration 981 ) loss: 0.000813
(Epoch 14 % 100) train loss: 0.01188217274811596, eval loss: 0.010927181496211724
(Iteration 1 ) loss: 0.002945
(Iteration 21 ) loss: 0.006186
(Iteration 41 ) loss: 0.020257
(Iteration 61 ) loss: 0.010335
(Iteration 81 ) loss: 0.008577
(Iteration 101 ) loss: 0.013035
(Iteration 121 ) loss: 0.001980
(Iteration 141 ) loss: 0.017569
(Iteration 161 ) loss: 0.008955
(Iteration 181 ) loss: 0.000884
(Iteration 201 ) loss: 0.000328
(Iteration 221 ) loss: 0.000771
(Iteration 241 ) loss: 0.002910
(Iteration 261 ) loss: 0.012808
(Iteration 281 ) loss: 0.002162
(Iteration 301 ) loss: 0.000955
(Iteration 321 ) loss: 0.001785
(Iteration 341 ) loss: 0.018170
(Iteration 361 ) loss: 0.005000
(Iteration 381 ) loss: 0.003426
(Iteration 401 ) loss: 0.005738
(Iteration 421 ) loss: 0.025552
(Iteration 441 ) loss: 0.062477
(Iteration 461 ) loss: 0.008494
(Iteration 481 ) loss: 0.005946
(Iteration 501 ) loss: 0.001509
(Iteration 521 ) loss: 0.027227
(Iteration 541 ) loss: 0.007300
(Iteration 561 ) loss: 0.010379
(Iteration 581 ) loss: 0.003108
(Iteration 601 ) loss: 0.005200
(Iteration 621 ) loss: 0.025722
(Iteration 641 ) loss: 0.034743
(Iteration 661 ) loss: 0.018820
(Iteration 681 ) loss: 0.005211
(Iteration 701 ) loss: 0.002646
(Iteration 721 ) loss: 0.009362
(Iteration 741 ) loss: 0.009776
(Iteration 761 ) loss: 0.045476
(Iteration 781 ) loss: 0.024296
(Iteration 801 ) loss: 0.008473
(Iteration 821 ) loss: 0.038206
(Iteration 841 ) loss: 0.009276
(Iteration 861 ) loss: 0.004891
(Iteration 881 ) loss: 0.005379
(Iteration 901 ) loss: 0.001969
(Iteration 921 ) loss: 0.013299
(Iteration 941 ) loss: 0.027616
(Iteration 961 ) loss: 0.007020
(Iteration 981 ) loss: 0.022090
(Epoch 15 % 100) train loss: 0.008152088040403169, eval loss: 0.00837495192085705
(Iteration 1 ) loss: 0.005631
(Iteration 21 ) loss: 0.000363
(Iteration 41 ) loss: 0.003130
(Iteration 61 ) loss: 0.001756
(Iteration 81 ) loss: 0.018516
(Iteration 101 ) loss: 0.001816
(Iteration 121 ) loss: 0.004689
(Iteration 141 ) loss: 0.022305
(Iteration 161 ) loss: 0.006934
(Iteration 181 ) loss: 0.018616
(Iteration 201 ) loss: 0.008913
(Iteration 221 ) loss: 0.022780
(Iteration 241 ) loss: 0.005120
(Iteration 261 ) loss: 0.008744
(Iteration 281 ) loss: 0.010615
(Iteration 301 ) loss: 0.012237
(Iteration 321 ) loss: 0.006270
(Iteration 341 ) loss: 0.006517
(Iteration 361 ) loss: 0.003519
(Iteration 381 ) loss: 0.000721
(Iteration 401 ) loss: 0.000838
(Iteration 421 ) loss: 0.007039
(Iteration 441 ) loss: 0.001038
(Iteration 461 ) loss: 0.027299
(Iteration 481 ) loss: 0.007793
(Iteration 501 ) loss: 0.002526
(Iteration 521 ) loss: 0.010310
(Iteration 541 ) loss: 0.001514
(Iteration 561 ) loss: 0.018320
(Iteration 581 ) loss: 0.003210
(Iteration 601 ) loss: 0.014223
(Iteration 621 ) loss: 0.038888
(Iteration 641 ) loss: 0.008673
(Iteration 661 ) loss: 0.002382
(Iteration 681 ) loss: 0.003466
(Iteration 701 ) loss: 0.002108
(Iteration 721 ) loss: 0.005748
(Iteration 741 ) loss: 0.015705
(Iteration 761 ) loss: 0.011897
(Iteration 781 ) loss: 0.005537
(Iteration 801 ) loss: 0.037635
(Iteration 821 ) loss: 0.003618
(Iteration 841 ) loss: 0.005646
(Iteration 861 ) loss: 0.048442
(Iteration 881 ) loss: 0.044629
(Iteration 901 ) loss: 0.014255
(Iteration 921 ) loss: 0.001189
(Iteration 941 ) loss: 0.001817
(Iteration 961 ) loss: 0.003752
(Iteration 981 ) loss: 0.016461
(Epoch 16 % 100) train loss: 0.011871514528577931, eval loss: 0.011129731470987548
(Iteration 1 ) loss: 0.010889
(Iteration 21 ) loss: 0.000294
(Iteration 41 ) loss: 0.004710
(Iteration 61 ) loss: 0.002489
(Iteration 81 ) loss: 0.010268
(Iteration 101 ) loss: 0.013845
(Iteration 121 ) loss: 0.009608
(Iteration 141 ) loss: 0.014730
(Iteration 161 ) loss: 0.010835
(Iteration 181 ) loss: 0.012726
(Iteration 201 ) loss: 0.007163
(Iteration 221 ) loss: 0.015435
(Iteration 241 ) loss: 0.006020
(Iteration 261 ) loss: 0.002920
(Iteration 281 ) loss: 0.007835
(Iteration 301 ) loss: 0.005127
(Iteration 321 ) loss: 0.001538
(Iteration 341 ) loss: 0.004815
(Iteration 361 ) loss: 0.003606
(Iteration 381 ) loss: 0.004809
(Iteration 401 ) loss: 0.005504
(Iteration 421 ) loss: 0.003086
(Iteration 441 ) loss: 0.035732
(Iteration 461 ) loss: 0.001097
(Iteration 481 ) loss: 0.009091
(Iteration 501 ) loss: 0.025129
(Iteration 521 ) loss: 0.003807
(Iteration 541 ) loss: 0.008998
(Iteration 561 ) loss: 0.003755
(Iteration 581 ) loss: 0.004067
(Iteration 601 ) loss: 0.000736
(Iteration 621 ) loss: 0.008221
(Iteration 641 ) loss: 0.003502
(Iteration 661 ) loss: 0.009933
(Iteration 681 ) loss: 0.004638
(Iteration 701 ) loss: 0.006266
(Iteration 721 ) loss: 0.005282
(Iteration 741 ) loss: 0.015462
(Iteration 761 ) loss: 0.007498
(Iteration 781 ) loss: 0.015994
(Iteration 801 ) loss: 0.006436
(Iteration 821 ) loss: 0.001904
(Iteration 841 ) loss: 0.005463
(Iteration 861 ) loss: 0.002488
(Iteration 881 ) loss: 0.039425
(Iteration 901 ) loss: 0.012170
(Iteration 921 ) loss: 0.002597
(Iteration 941 ) loss: 0.002669
(Iteration 961 ) loss: 0.002220
(Iteration 981 ) loss: 0.004690
(Epoch 17 % 100) train loss: 0.007668426473569688, eval loss: 0.007755303004986208
(Iteration 1 ) loss: 0.033728
(Iteration 21 ) loss: 0.017826
(Iteration 41 ) loss: 0.007597
(Iteration 61 ) loss: 0.003509
(Iteration 81 ) loss: 0.042463
(Iteration 101 ) loss: 0.001494
(Iteration 121 ) loss: 0.004560
(Iteration 141 ) loss: 0.002116
(Iteration 161 ) loss: 0.001844
(Iteration 181 ) loss: 0.030975
(Iteration 201 ) loss: 0.009627
(Iteration 221 ) loss: 0.003202
(Iteration 241 ) loss: 0.001530
(Iteration 261 ) loss: 0.016532
(Iteration 281 ) loss: 0.023044
(Iteration 301 ) loss: 0.005268
(Iteration 321 ) loss: 0.005500
(Iteration 341 ) loss: 0.004185
(Iteration 361 ) loss: 0.001390
(Iteration 381 ) loss: 0.010801
(Iteration 401 ) loss: 0.001824
(Iteration 421 ) loss: 0.008968
(Iteration 441 ) loss: 0.020878
(Iteration 461 ) loss: 0.005608
(Iteration 481 ) loss: 0.024530
(Iteration 501 ) loss: 0.008444
(Iteration 521 ) loss: 0.020577
(Iteration 541 ) loss: 0.009423
(Iteration 561 ) loss: 0.000603
(Iteration 581 ) loss: 0.021019
(Iteration 601 ) loss: 0.007024
(Iteration 621 ) loss: 0.022298
(Iteration 641 ) loss: 0.007431
(Iteration 661 ) loss: 0.009385
(Iteration 681 ) loss: 0.013209
(Iteration 701 ) loss: 0.014406
(Iteration 721 ) loss: 0.003066
(Iteration 741 ) loss: 0.000892
(Iteration 761 ) loss: 0.009752
(Iteration 781 ) loss: 0.001515
(Iteration 801 ) loss: 0.002684
(Iteration 821 ) loss: 0.002536
(Iteration 841 ) loss: 0.031759
(Iteration 861 ) loss: 0.010092
(Iteration 881 ) loss: 0.006776
(Iteration 901 ) loss: 0.006985
(Iteration 921 ) loss: 0.012043
(Iteration 941 ) loss: 0.002314
(Iteration 961 ) loss: 0.040826
(Iteration 981 ) loss: 0.002768
(Epoch 18 % 100) train loss: 0.0074588474477322204, eval loss: 0.007428020044353014
(Iteration 1 ) loss: 0.009687
(Iteration 21 ) loss: 0.029441
(Iteration 41 ) loss: 0.011551
(Iteration 61 ) loss: 0.007695
(Iteration 81 ) loss: 0.008607
(Iteration 101 ) loss: 0.011600
(Iteration 121 ) loss: 0.013178
(Iteration 141 ) loss: 0.004956
(Iteration 161 ) loss: 0.013299
(Iteration 181 ) loss: 0.031996
(Iteration 201 ) loss: 0.001798
(Iteration 221 ) loss: 0.003278
(Iteration 241 ) loss: 0.000979
(Iteration 261 ) loss: 0.008083
(Iteration 281 ) loss: 0.014309
(Iteration 301 ) loss: 0.005196
(Iteration 321 ) loss: 0.036449
(Iteration 341 ) loss: 0.008202
(Iteration 361 ) loss: 0.001554
(Iteration 381 ) loss: 0.004674
(Iteration 401 ) loss: 0.001886
(Iteration 421 ) loss: 0.002095
(Iteration 441 ) loss: 0.000697
(Iteration 461 ) loss: 0.010570
(Iteration 481 ) loss: 0.002097
(Iteration 501 ) loss: 0.006819
(Iteration 521 ) loss: 0.014015
(Iteration 541 ) loss: 0.004876
(Iteration 561 ) loss: 0.003848
(Iteration 581 ) loss: 0.000451
(Iteration 601 ) loss: 0.004672
(Iteration 621 ) loss: 0.041617
(Iteration 641 ) loss: 0.006041
(Iteration 661 ) loss: 0.016465
(Iteration 681 ) loss: 0.002495
(Iteration 701 ) loss: 0.002534
(Iteration 721 ) loss: 0.003963
(Iteration 741 ) loss: 0.005900
(Iteration 761 ) loss: 0.006546
(Iteration 781 ) loss: 0.030864
(Iteration 801 ) loss: 0.000719
(Iteration 821 ) loss: 0.005822
(Iteration 841 ) loss: 0.003492
(Iteration 861 ) loss: 0.018408
(Iteration 881 ) loss: 0.000819
(Iteration 901 ) loss: 0.000462
(Iteration 921 ) loss: 0.015061
(Iteration 941 ) loss: 0.002952
(Iteration 961 ) loss: 0.020394
(Iteration 981 ) loss: 0.003211
(Epoch 19 % 100) train loss: 0.007877434839107491, eval loss: 0.007358848360190294
(Iteration 1 ) loss: 0.014677
(Iteration 21 ) loss: 0.020001
(Iteration 41 ) loss: 0.017476
(Iteration 61 ) loss: 0.002948
(Iteration 81 ) loss: 0.001177
(Iteration 101 ) loss: 0.001961
(Iteration 121 ) loss: 0.001703
(Iteration 141 ) loss: 0.000881
(Iteration 161 ) loss: 0.002716
(Iteration 181 ) loss: 0.001108
(Iteration 201 ) loss: 0.003127
(Iteration 221 ) loss: 0.012197
(Iteration 241 ) loss: 0.007141
(Iteration 261 ) loss: 0.006316
(Iteration 281 ) loss: 0.001370
(Iteration 301 ) loss: 0.008178
(Iteration 321 ) loss: 0.005788
(Iteration 341 ) loss: 0.002562
(Iteration 361 ) loss: 0.005108
(Iteration 381 ) loss: 0.001314
(Iteration 401 ) loss: 0.001169
(Iteration 421 ) loss: 0.004902
(Iteration 441 ) loss: 0.002858
(Iteration 461 ) loss: 0.019183
(Iteration 481 ) loss: 0.003719
(Iteration 501 ) loss: 0.001189
(Iteration 521 ) loss: 0.013265
(Iteration 541 ) loss: 0.009149
(Iteration 561 ) loss: 0.010015
(Iteration 581 ) loss: 0.005249
(Iteration 601 ) loss: 0.001685
(Iteration 621 ) loss: 0.004086
(Iteration 641 ) loss: 0.001070
(Iteration 661 ) loss: 0.024275
(Iteration 681 ) loss: 0.003275
(Iteration 701 ) loss: 0.006244
(Iteration 721 ) loss: 0.008821
(Iteration 741 ) loss: 0.005687
(Iteration 761 ) loss: 0.002309
(Iteration 781 ) loss: 0.000558
(Iteration 801 ) loss: 0.004416
(Iteration 821 ) loss: 0.008121
(Iteration 841 ) loss: 0.003579
(Iteration 861 ) loss: 0.003889
(Iteration 881 ) loss: 0.004982
(Iteration 901 ) loss: 0.014589
(Iteration 921 ) loss: 0.005469
(Iteration 941 ) loss: 0.006243
(Iteration 961 ) loss: 0.007936
(Iteration 981 ) loss: 0.001334
(Epoch 20 % 100) train loss: 0.005375664497568225, eval loss: 0.004959230327989027
(Iteration 1 ) loss: 0.004650
(Iteration 21 ) loss: 0.004363
(Iteration 41 ) loss: 0.003490
(Iteration 61 ) loss: 0.011425
(Iteration 81 ) loss: 0.003033
(Iteration 101 ) loss: 0.020261
(Iteration 121 ) loss: 0.002765
(Iteration 141 ) loss: 0.007800
(Iteration 161 ) loss: 0.006589
(Iteration 181 ) loss: 0.003404
(Iteration 201 ) loss: 0.005572
(Iteration 221 ) loss: 0.002223
(Iteration 241 ) loss: 0.010883
(Iteration 261 ) loss: 0.017738
(Iteration 281 ) loss: 0.010178
(Iteration 301 ) loss: 0.000663
(Iteration 321 ) loss: 0.004219
(Iteration 341 ) loss: 0.005690
(Iteration 361 ) loss: 0.014247
(Iteration 381 ) loss: 0.003672
(Iteration 401 ) loss: 0.004246
(Iteration 421 ) loss: 0.000521
(Iteration 441 ) loss: 0.001625
(Iteration 461 ) loss: 0.016786
(Iteration 481 ) loss: 0.000461
(Iteration 501 ) loss: 0.001261
(Iteration 521 ) loss: 0.021237
(Iteration 541 ) loss: 0.018510
(Iteration 561 ) loss: 0.006582
(Iteration 581 ) loss: 0.012137
(Iteration 601 ) loss: 0.012606
(Iteration 621 ) loss: 0.018317
(Iteration 641 ) loss: 0.002914
(Iteration 661 ) loss: 0.011717
(Iteration 681 ) loss: 0.005033
(Iteration 701 ) loss: 0.003156
(Iteration 721 ) loss: 0.000191
(Iteration 741 ) loss: 0.010559
(Iteration 761 ) loss: 0.003577
(Iteration 781 ) loss: 0.000530
(Iteration 801 ) loss: 0.003738
(Iteration 821 ) loss: 0.017522
(Iteration 841 ) loss: 0.006712
(Iteration 861 ) loss: 0.003676
(Iteration 881 ) loss: 0.000503
(Iteration 901 ) loss: 0.006062
(Iteration 921 ) loss: 0.016698
(Iteration 941 ) loss: 0.001724
(Iteration 961 ) loss: 0.001990
(Iteration 981 ) loss: 0.003464
(Epoch 21 % 100) train loss: 0.0060321754181730984, eval loss: 0.006074146465832684
(Iteration 1 ) loss: 0.011370
(Iteration 21 ) loss: 0.005311
(Iteration 41 ) loss: 0.001495
(Iteration 61 ) loss: 0.000250
(Iteration 81 ) loss: 0.001149
(Iteration 101 ) loss: 0.016889
(Iteration 121 ) loss: 0.005640
(Iteration 141 ) loss: 0.066677
(Iteration 161 ) loss: 0.016717
(Iteration 181 ) loss: 0.012202
(Iteration 201 ) loss: 0.002366
(Iteration 221 ) loss: 0.000769
(Iteration 241 ) loss: 0.002910
(Iteration 261 ) loss: 0.009175
(Iteration 281 ) loss: 0.003921
(Iteration 301 ) loss: 0.001744
(Iteration 321 ) loss: 0.003239
(Iteration 341 ) loss: 0.010372
(Iteration 361 ) loss: 0.020137
(Iteration 381 ) loss: 0.002703
(Iteration 401 ) loss: 0.012888
(Iteration 421 ) loss: 0.009755
(Iteration 441 ) loss: 0.007308
(Iteration 461 ) loss: 0.017444
(Iteration 481 ) loss: 0.002870
(Iteration 501 ) loss: 0.002536
(Iteration 521 ) loss: 0.001312
(Iteration 541 ) loss: 0.001083
(Iteration 561 ) loss: 0.000612
(Iteration 581 ) loss: 0.004545
(Iteration 601 ) loss: 0.002076
(Iteration 621 ) loss: 0.011764
(Iteration 641 ) loss: 0.002574
(Iteration 661 ) loss: 0.004920
(Iteration 681 ) loss: 0.003340
(Iteration 701 ) loss: 0.010120
(Iteration 721 ) loss: 0.005088
(Iteration 741 ) loss: 0.012726
(Iteration 761 ) loss: 0.007012
(Iteration 781 ) loss: 0.006788
(Iteration 801 ) loss: 0.010351
(Iteration 821 ) loss: 0.000716
(Iteration 841 ) loss: 0.002658
(Iteration 861 ) loss: 0.001771
(Iteration 881 ) loss: 0.007709
(Iteration 901 ) loss: 0.005162
(Iteration 921 ) loss: 0.004469
(Iteration 941 ) loss: 0.014930
(Iteration 961 ) loss: 0.006776
(Iteration 981 ) loss: 0.000586
(Epoch 22 % 100) train loss: 0.005782514504220757, eval loss: 0.0061317886401424755
(Iteration 1 ) loss: 0.010195
(Iteration 21 ) loss: 0.001045
(Iteration 41 ) loss: 0.010313
(Iteration 61 ) loss: 0.003449
(Iteration 81 ) loss: 0.005598
(Iteration 101 ) loss: 0.003688
(Iteration 121 ) loss: 0.001977
(Iteration 141 ) loss: 0.002123
(Iteration 161 ) loss: 0.001168
(Iteration 181 ) loss: 0.002316
(Iteration 201 ) loss: 0.001078
(Iteration 221 ) loss: 0.024373
(Iteration 241 ) loss: 0.002033
(Iteration 261 ) loss: 0.006070
(Iteration 281 ) loss: 0.006965
(Iteration 301 ) loss: 0.004598
(Iteration 321 ) loss: 0.012808
(Iteration 341 ) loss: 0.025337
(Iteration 361 ) loss: 0.004208
(Iteration 381 ) loss: 0.001215
(Iteration 401 ) loss: 0.003682
(Iteration 421 ) loss: 0.005941
(Iteration 441 ) loss: 0.000546
(Iteration 461 ) loss: 0.007057
(Iteration 481 ) loss: 0.003968
(Iteration 501 ) loss: 0.005978
(Iteration 521 ) loss: 0.004408
(Iteration 541 ) loss: 0.005017
(Iteration 561 ) loss: 0.003527
(Iteration 581 ) loss: 0.001487
(Iteration 601 ) loss: 0.007015
(Iteration 621 ) loss: 0.012660
(Iteration 641 ) loss: 0.001375
(Iteration 661 ) loss: 0.001483
(Iteration 681 ) loss: 0.002512
(Iteration 701 ) loss: 0.002893
(Iteration 721 ) loss: 0.010219
(Iteration 741 ) loss: 0.007933
(Iteration 761 ) loss: 0.002390
(Iteration 781 ) loss: 0.000810
(Iteration 801 ) loss: 0.008602
(Iteration 821 ) loss: 0.009331
(Iteration 841 ) loss: 0.004153
(Iteration 861 ) loss: 0.003094
(Iteration 881 ) loss: 0.005467
(Iteration 901 ) loss: 0.001729
(Iteration 921 ) loss: 0.007808
(Iteration 941 ) loss: 0.009760
(Iteration 961 ) loss: 0.007014
(Iteration 981 ) loss: 0.000404
(Epoch 23 % 100) train loss: 0.004259272424585898, eval loss: 0.004251047413611806
(Iteration 1 ) loss: 0.006719
(Iteration 21 ) loss: 0.003510
(Iteration 41 ) loss: 0.003798
(Iteration 61 ) loss: 0.004628
(Iteration 81 ) loss: 0.015683
(Iteration 101 ) loss: 0.003467
(Iteration 121 ) loss: 0.002060
(Iteration 141 ) loss: 0.000804
(Iteration 161 ) loss: 0.016082
(Iteration 181 ) loss: 0.004568
(Iteration 201 ) loss: 0.001324
(Iteration 221 ) loss: 0.002887
(Iteration 241 ) loss: 0.006001
(Iteration 261 ) loss: 0.002661
(Iteration 281 ) loss: 0.009706
(Iteration 301 ) loss: 0.006361
(Iteration 321 ) loss: 0.006923
(Iteration 341 ) loss: 0.007753
(Iteration 361 ) loss: 0.004847
(Iteration 381 ) loss: 0.002490
(Iteration 401 ) loss: 0.002881
(Iteration 421 ) loss: 0.002163
(Iteration 441 ) loss: 0.017560
(Iteration 461 ) loss: 0.003117
(Iteration 481 ) loss: 0.003455
(Iteration 501 ) loss: 0.003447
(Iteration 521 ) loss: 0.002013
(Iteration 541 ) loss: 0.011136
(Iteration 561 ) loss: 0.002063
(Iteration 581 ) loss: 0.001103
(Iteration 601 ) loss: 0.003712
(Iteration 621 ) loss: 0.005641
(Iteration 641 ) loss: 0.000694
(Iteration 661 ) loss: 0.001531
(Iteration 681 ) loss: 0.000258
(Iteration 701 ) loss: 0.001837
(Iteration 721 ) loss: 0.007829
(Iteration 741 ) loss: 0.003279
(Iteration 761 ) loss: 0.005770
(Iteration 781 ) loss: 0.005999
(Iteration 801 ) loss: 0.000961
(Iteration 821 ) loss: 0.001261
(Iteration 841 ) loss: 0.006737
(Iteration 861 ) loss: 0.001164
(Iteration 881 ) loss: 0.000712
(Iteration 901 ) loss: 0.002795
(Iteration 921 ) loss: 0.006756
(Iteration 941 ) loss: 0.000986
(Iteration 961 ) loss: 0.010041
(Iteration 981 ) loss: 0.007983
(Epoch 24 % 100) train loss: 0.003704242216645566, eval loss: 0.003285127990194421
(Iteration 1 ) loss: 0.000962
(Iteration 21 ) loss: 0.001400
(Iteration 41 ) loss: 0.005408
(Iteration 61 ) loss: 0.001135
(Iteration 81 ) loss: 0.010506
(Iteration 101 ) loss: 0.004498
(Iteration 121 ) loss: 0.009440
(Iteration 141 ) loss: 0.001315
(Iteration 161 ) loss: 0.002600
(Iteration 181 ) loss: 0.003377
(Iteration 201 ) loss: 0.002466
(Iteration 221 ) loss: 0.002864
(Iteration 241 ) loss: 0.005246
(Iteration 261 ) loss: 0.001856
(Iteration 281 ) loss: 0.002345
(Iteration 301 ) loss: 0.005412
(Iteration 321 ) loss: 0.001184
(Iteration 341 ) loss: 0.004137
(Iteration 361 ) loss: 0.003165
(Iteration 381 ) loss: 0.010967
(Iteration 401 ) loss: 0.000779
(Iteration 421 ) loss: 0.001696
(Iteration 441 ) loss: 0.003204
(Iteration 461 ) loss: 0.001707
(Iteration 481 ) loss: 0.002521
(Iteration 501 ) loss: 0.001890
(Iteration 521 ) loss: 0.008899
(Iteration 541 ) loss: 0.002407
(Iteration 561 ) loss: 0.005465
(Iteration 581 ) loss: 0.009185
(Iteration 601 ) loss: 0.001987
(Iteration 621 ) loss: 0.009103
(Iteration 641 ) loss: 0.005361
(Iteration 661 ) loss: 0.004314
(Iteration 681 ) loss: 0.032413
(Iteration 701 ) loss: 0.004163
(Iteration 721 ) loss: 0.002267
(Iteration 741 ) loss: 0.001948
(Iteration 761 ) loss: 0.001930
(Iteration 781 ) loss: 0.008032
(Iteration 801 ) loss: 0.009796
(Iteration 821 ) loss: 0.009700
(Iteration 841 ) loss: 0.001536
(Iteration 861 ) loss: 0.002023
(Iteration 881 ) loss: 0.004583
(Iteration 901 ) loss: 0.004207
(Iteration 921 ) loss: 0.000814
(Iteration 941 ) loss: 0.001789
(Iteration 961 ) loss: 0.000305
(Iteration 981 ) loss: 0.001691
(Epoch 25 % 100) train loss: 0.002439389928881435, eval loss: 0.002446739581220237
(Iteration 1 ) loss: 0.000397
(Iteration 21 ) loss: 0.006929
(Iteration 41 ) loss: 0.001533
(Iteration 61 ) loss: 0.003361
(Iteration 81 ) loss: 0.003602
(Iteration 101 ) loss: 0.001231
(Iteration 121 ) loss: 0.001009
(Iteration 141 ) loss: 0.000252
(Iteration 161 ) loss: 0.002748
(Iteration 181 ) loss: 0.001273
(Iteration 201 ) loss: 0.004118
(Iteration 221 ) loss: 0.003733
(Iteration 241 ) loss: 0.002535
(Iteration 261 ) loss: 0.013733
(Iteration 281 ) loss: 0.001311
(Iteration 301 ) loss: 0.002710
(Iteration 321 ) loss: 0.000810
(Iteration 341 ) loss: 0.004859
(Iteration 361 ) loss: 0.002299
(Iteration 381 ) loss: 0.002317
(Iteration 401 ) loss: 0.004491
(Iteration 421 ) loss: 0.006438
(Iteration 441 ) loss: 0.000816
(Iteration 461 ) loss: 0.002604
(Iteration 481 ) loss: 0.002376
(Iteration 501 ) loss: 0.003038
(Iteration 521 ) loss: 0.005526
(Iteration 541 ) loss: 0.011240
(Iteration 561 ) loss: 0.003468
(Iteration 581 ) loss: 0.000943
(Iteration 601 ) loss: 0.000817
(Iteration 621 ) loss: 0.000808
(Iteration 641 ) loss: 0.004345
(Iteration 661 ) loss: 0.003854
(Iteration 681 ) loss: 0.006253
(Iteration 701 ) loss: 0.005743
(Iteration 721 ) loss: 0.010991
(Iteration 741 ) loss: 0.002523
(Iteration 761 ) loss: 0.004865
(Iteration 781 ) loss: 0.000141
(Iteration 801 ) loss: 0.000437
(Iteration 821 ) loss: 0.000478
(Iteration 841 ) loss: 0.001958
(Iteration 861 ) loss: 0.000351
(Iteration 881 ) loss: 0.006066
(Iteration 901 ) loss: 0.001346
(Iteration 921 ) loss: 0.006944
(Iteration 941 ) loss: 0.003545
(Iteration 961 ) loss: 0.000583
(Iteration 981 ) loss: 0.000964
(Epoch 26 % 100) train loss: 0.0034635512041738875, eval loss: 0.0034528950114799725
(Iteration 1 ) loss: 0.007699
(Iteration 21 ) loss: 0.004315
(Iteration 41 ) loss: 0.004986
(Iteration 61 ) loss: 0.002430
(Iteration 81 ) loss: 0.001341
(Iteration 101 ) loss: 0.010991
(Iteration 121 ) loss: 0.004252
(Iteration 141 ) loss: 0.025799
(Iteration 161 ) loss: 0.000647
(Iteration 181 ) loss: 0.000616
(Iteration 201 ) loss: 0.002761
(Iteration 221 ) loss: 0.001767
(Iteration 241 ) loss: 0.003754
(Iteration 261 ) loss: 0.002732
(Iteration 281 ) loss: 0.008456
(Iteration 301 ) loss: 0.001689
(Iteration 321 ) loss: 0.003503
(Iteration 341 ) loss: 0.001542
(Iteration 361 ) loss: 0.004462
(Iteration 381 ) loss: 0.004494
(Iteration 401 ) loss: 0.002989
(Iteration 421 ) loss: 0.001281
(Iteration 441 ) loss: 0.011054
(Iteration 461 ) loss: 0.004248
(Iteration 481 ) loss: 0.005600
(Iteration 501 ) loss: 0.004184
(Iteration 521 ) loss: 0.003755
(Iteration 541 ) loss: 0.001197
(Iteration 561 ) loss: 0.002065
(Iteration 581 ) loss: 0.001493
(Iteration 601 ) loss: 0.001169
(Iteration 621 ) loss: 0.002007
(Iteration 641 ) loss: 0.002166
(Iteration 661 ) loss: 0.001693
(Iteration 681 ) loss: 0.004727
(Iteration 701 ) loss: 0.004143
(Iteration 721 ) loss: 0.008337
(Iteration 741 ) loss: 0.008152
(Iteration 761 ) loss: 0.000689
(Iteration 781 ) loss: 0.010935
(Iteration 801 ) loss: 0.004788
(Iteration 821 ) loss: 0.001372
(Iteration 841 ) loss: 0.006313
(Iteration 861 ) loss: 0.006932
(Iteration 881 ) loss: 0.003912
(Iteration 901 ) loss: 0.001486
(Iteration 921 ) loss: 0.001509
(Iteration 941 ) loss: 0.002525
(Iteration 961 ) loss: 0.000378
(Iteration 981 ) loss: 0.003828
(Epoch 27 % 100) train loss: 0.002371550071493139, eval loss: 0.002105917211592063
(Iteration 1 ) loss: 0.001476
(Iteration 21 ) loss: 0.001593
(Iteration 41 ) loss: 0.004388
(Iteration 61 ) loss: 0.003914
(Iteration 81 ) loss: 0.004868
(Iteration 101 ) loss: 0.003667
(Iteration 121 ) loss: 0.003097
(Iteration 141 ) loss: 0.008107
(Iteration 161 ) loss: 0.009714
(Iteration 181 ) loss: 0.003279
(Iteration 201 ) loss: 0.004255
(Iteration 221 ) loss: 0.003739
(Iteration 241 ) loss: 0.000803
(Iteration 261 ) loss: 0.001108
(Iteration 281 ) loss: 0.001647
(Iteration 301 ) loss: 0.001502
(Iteration 321 ) loss: 0.002706
(Iteration 341 ) loss: 0.010177
(Iteration 361 ) loss: 0.003859
(Iteration 381 ) loss: 0.000497
(Iteration 401 ) loss: 0.002282
(Iteration 421 ) loss: 0.001121
(Iteration 441 ) loss: 0.004690
(Iteration 461 ) loss: 0.001762
(Iteration 481 ) loss: 0.002737
(Iteration 501 ) loss: 0.004178
(Iteration 521 ) loss: 0.001769
(Iteration 541 ) loss: 0.006664
(Iteration 561 ) loss: 0.021260
(Iteration 581 ) loss: 0.002807
(Iteration 601 ) loss: 0.004380
(Iteration 621 ) loss: 0.001009
(Iteration 641 ) loss: 0.000371
(Iteration 661 ) loss: 0.006347
(Iteration 681 ) loss: 0.001045
(Iteration 701 ) loss: 0.001239
(Iteration 721 ) loss: 0.001817
(Iteration 741 ) loss: 0.000479
(Iteration 761 ) loss: 0.004056
(Iteration 781 ) loss: 0.002159
(Iteration 801 ) loss: 0.001830
(Iteration 821 ) loss: 0.006226
(Iteration 841 ) loss: 0.003447
(Iteration 861 ) loss: 0.002775
(Iteration 881 ) loss: 0.003664
(Iteration 901 ) loss: 0.002286
(Iteration 921 ) loss: 0.002916
(Iteration 941 ) loss: 0.001444
(Iteration 961 ) loss: 0.002020
(Iteration 981 ) loss: 0.006343
(Epoch 28 % 100) train loss: 0.006109077636116085, eval loss: 0.005770535726113323
(Iteration 1 ) loss: 0.005131
(Iteration 21 ) loss: 0.001836
(Iteration 41 ) loss: 0.004023
(Iteration 61 ) loss: 0.005790
(Iteration 81 ) loss: 0.004076
(Iteration 101 ) loss: 0.014989
(Iteration 121 ) loss: 0.000262
(Iteration 141 ) loss: 0.001739
(Iteration 161 ) loss: 0.001818
(Iteration 181 ) loss: 0.004984
(Iteration 201 ) loss: 0.022088
(Iteration 221 ) loss: 0.003730
(Iteration 241 ) loss: 0.001566
(Iteration 261 ) loss: 0.000760
(Iteration 281 ) loss: 0.009573
(Iteration 301 ) loss: 0.000512
(Iteration 321 ) loss: 0.022830
(Iteration 341 ) loss: 0.000970
(Iteration 361 ) loss: 0.003785
(Iteration 381 ) loss: 0.005531
(Iteration 401 ) loss: 0.001016
(Iteration 421 ) loss: 0.004370
(Iteration 441 ) loss: 0.001889
(Iteration 461 ) loss: 0.001500
(Iteration 481 ) loss: 0.001395
(Iteration 501 ) loss: 0.001731
(Iteration 521 ) loss: 0.000292
(Iteration 541 ) loss: 0.004561
(Iteration 561 ) loss: 0.011756
(Iteration 581 ) loss: 0.000838
(Iteration 601 ) loss: 0.006059
(Iteration 621 ) loss: 0.002622
(Iteration 641 ) loss: 0.009076
(Iteration 661 ) loss: 0.002950
(Iteration 681 ) loss: 0.004859
(Iteration 701 ) loss: 0.002074
(Iteration 721 ) loss: 0.005450
(Iteration 741 ) loss: 0.002889
(Iteration 761 ) loss: 0.003056
(Iteration 781 ) loss: 0.001172
(Iteration 801 ) loss: 0.001997
(Iteration 821 ) loss: 0.002361
(Iteration 841 ) loss: 0.001842
(Iteration 861 ) loss: 0.000701
(Iteration 881 ) loss: 0.001033
(Iteration 901 ) loss: 0.002363
(Iteration 921 ) loss: 0.000235
(Iteration 941 ) loss: 0.001078
(Iteration 961 ) loss: 0.022871
(Iteration 981 ) loss: 0.000096
(Epoch 29 % 100) train loss: 0.001490746542349866, eval loss: 0.0017510606962597057
(Iteration 1 ) loss: 0.000703
(Iteration 21 ) loss: 0.000506
(Iteration 41 ) loss: 0.008817
(Iteration 61 ) loss: 0.002233
(Iteration 81 ) loss: 0.001003
(Iteration 101 ) loss: 0.001427
(Iteration 121 ) loss: 0.000139
(Iteration 141 ) loss: 0.002652
(Iteration 161 ) loss: 0.004158
(Iteration 181 ) loss: 0.013787
(Iteration 201 ) loss: 0.003825
(Iteration 221 ) loss: 0.001381
(Iteration 241 ) loss: 0.004664
(Iteration 261 ) loss: 0.001201
(Iteration 281 ) loss: 0.006157
(Iteration 301 ) loss: 0.002450
(Iteration 321 ) loss: 0.010122
(Iteration 341 ) loss: 0.001384
(Iteration 361 ) loss: 0.001824
(Iteration 381 ) loss: 0.008156
(Iteration 401 ) loss: 0.000459
(Iteration 421 ) loss: 0.002376
(Iteration 441 ) loss: 0.005053
(Iteration 461 ) loss: 0.002071
(Iteration 481 ) loss: 0.004019
(Iteration 501 ) loss: 0.000125
(Iteration 521 ) loss: 0.001012
(Iteration 541 ) loss: 0.001074
(Iteration 561 ) loss: 0.002385
(Iteration 581 ) loss: 0.005531
(Iteration 601 ) loss: 0.004871
(Iteration 621 ) loss: 0.009005
(Iteration 641 ) loss: 0.002519
(Iteration 661 ) loss: 0.004769
(Iteration 681 ) loss: 0.002406
(Iteration 701 ) loss: 0.006605
(Iteration 721 ) loss: 0.003272
(Iteration 741 ) loss: 0.000382
(Iteration 761 ) loss: 0.003038
(Iteration 781 ) loss: 0.002051
(Iteration 801 ) loss: 0.002626
(Iteration 821 ) loss: 0.005861
(Iteration 841 ) loss: 0.002332
(Iteration 861 ) loss: 0.001179
(Iteration 881 ) loss: 0.000378
(Iteration 901 ) loss: 0.002534
(Iteration 921 ) loss: 0.000206
(Iteration 941 ) loss: 0.001830
(Iteration 961 ) loss: 0.000350
(Iteration 981 ) loss: 0.008513
(Epoch 30 % 100) train loss: 0.0031982956179673135, eval loss: 0.0030311737799235587
(Iteration 1 ) loss: 0.002130
(Iteration 21 ) loss: 0.001557
(Iteration 41 ) loss: 0.001391
(Iteration 61 ) loss: 0.002657
(Iteration 81 ) loss: 0.000710
(Iteration 101 ) loss: 0.006870
(Iteration 121 ) loss: 0.001822
(Iteration 141 ) loss: 0.001123
(Iteration 161 ) loss: 0.001178
(Iteration 181 ) loss: 0.000998
(Iteration 201 ) loss: 0.000791
(Iteration 221 ) loss: 0.002630
(Iteration 241 ) loss: 0.010314
(Iteration 261 ) loss: 0.001047
(Iteration 281 ) loss: 0.000682
(Iteration 301 ) loss: 0.001700
(Iteration 321 ) loss: 0.002704
(Iteration 341 ) loss: 0.003329
(Iteration 361 ) loss: 0.004442
(Iteration 381 ) loss: 0.000806
(Iteration 401 ) loss: 0.000535
(Iteration 421 ) loss: 0.002857
(Iteration 441 ) loss: 0.002484
(Iteration 461 ) loss: 0.001337
(Iteration 481 ) loss: 0.000482
(Iteration 501 ) loss: 0.004857
(Iteration 521 ) loss: 0.000812
(Iteration 541 ) loss: 0.000198
(Iteration 561 ) loss: 0.001253
(Iteration 581 ) loss: 0.005626
(Iteration 601 ) loss: 0.014117
(Iteration 621 ) loss: 0.002591
(Iteration 641 ) loss: 0.004046
(Iteration 661 ) loss: 0.008758
(Iteration 681 ) loss: 0.001583
(Iteration 701 ) loss: 0.000567
(Iteration 721 ) loss: 0.000618
(Iteration 741 ) loss: 0.013910
(Iteration 761 ) loss: 0.001324
(Iteration 781 ) loss: 0.002263
(Iteration 801 ) loss: 0.002394
(Iteration 821 ) loss: 0.000841
(Iteration 841 ) loss: 0.001269
(Iteration 861 ) loss: 0.003759
(Iteration 881 ) loss: 0.004516
(Iteration 901 ) loss: 0.000703
(Iteration 921 ) loss: 0.001229
(Iteration 941 ) loss: 0.003616
(Iteration 961 ) loss: 0.001643
(Iteration 981 ) loss: 0.000469
(Epoch 31 % 100) train loss: 0.0030734900469697843, eval loss: 0.0030916524071225044
(Iteration 1 ) loss: 0.002617
(Iteration 21 ) loss: 0.003068
(Iteration 41 ) loss: 0.001341
(Iteration 61 ) loss: 0.002385
(Iteration 81 ) loss: 0.001994
(Iteration 101 ) loss: 0.001855
(Iteration 121 ) loss: 0.000981
(Iteration 141 ) loss: 0.006804
(Iteration 161 ) loss: 0.002139
(Iteration 181 ) loss: 0.026168
(Iteration 201 ) loss: 0.020555
(Iteration 221 ) loss: 0.002206
(Iteration 241 ) loss: 0.001588
(Iteration 261 ) loss: 0.001872
(Iteration 281 ) loss: 0.004401
(Iteration 301 ) loss: 0.002331
(Iteration 321 ) loss: 0.001449
(Iteration 341 ) loss: 0.004389
(Iteration 361 ) loss: 0.004767
(Iteration 381 ) loss: 0.006826
(Iteration 401 ) loss: 0.000541
(Iteration 421 ) loss: 0.000777
(Iteration 441 ) loss: 0.004057
(Iteration 461 ) loss: 0.001901
(Iteration 481 ) loss: 0.001089
(Iteration 501 ) loss: 0.003690
(Iteration 521 ) loss: 0.000800
(Iteration 541 ) loss: 0.001193
(Iteration 561 ) loss: 0.003437
(Iteration 581 ) loss: 0.001701
(Iteration 601 ) loss: 0.006955
(Iteration 621 ) loss: 0.001311
(Iteration 641 ) loss: 0.001372
(Iteration 661 ) loss: 0.002886
(Iteration 681 ) loss: 0.001421
(Iteration 701 ) loss: 0.002056
(Iteration 721 ) loss: 0.003889
(Iteration 741 ) loss: 0.003851
(Iteration 761 ) loss: 0.006815
(Iteration 781 ) loss: 0.002810
(Iteration 801 ) loss: 0.001984
(Iteration 821 ) loss: 0.006336
(Iteration 841 ) loss: 0.002969
(Iteration 861 ) loss: 0.002518
(Iteration 881 ) loss: 0.002355
(Iteration 901 ) loss: 0.001184
(Iteration 921 ) loss: 0.000402
(Iteration 941 ) loss: 0.001382
(Iteration 961 ) loss: 0.000182
(Iteration 981 ) loss: 0.001271
(Epoch 32 % 100) train loss: 0.0012932503419395374, eval loss: 0.0012221476771155453
(Iteration 1 ) loss: 0.000656
(Iteration 21 ) loss: 0.001959
(Iteration 41 ) loss: 0.001163
(Iteration 61 ) loss: 0.000654
(Iteration 81 ) loss: 0.000975
(Iteration 101 ) loss: 0.001164
(Iteration 121 ) loss: 0.001980
(Iteration 141 ) loss: 0.000276
(Iteration 161 ) loss: 0.002032
(Iteration 181 ) loss: 0.001778
(Iteration 201 ) loss: 0.006694
(Iteration 221 ) loss: 0.004572
(Iteration 241 ) loss: 0.001969
(Iteration 261 ) loss: 0.011664
(Iteration 281 ) loss: 0.004095
(Iteration 301 ) loss: 0.004966
(Iteration 321 ) loss: 0.000849
(Iteration 341 ) loss: 0.004457
(Iteration 361 ) loss: 0.005877
(Iteration 381 ) loss: 0.001915
(Iteration 401 ) loss: 0.000809
(Iteration 421 ) loss: 0.000481
(Iteration 441 ) loss: 0.001827
(Iteration 461 ) loss: 0.000293
(Iteration 481 ) loss: 0.000403
(Iteration 501 ) loss: 0.001543
(Iteration 521 ) loss: 0.002081
(Iteration 541 ) loss: 0.003522
(Iteration 561 ) loss: 0.002933
(Iteration 581 ) loss: 0.004330
(Iteration 601 ) loss: 0.008377
(Iteration 621 ) loss: 0.002004
(Iteration 641 ) loss: 0.005179
(Iteration 661 ) loss: 0.001156
(Iteration 681 ) loss: 0.003648
(Iteration 701 ) loss: 0.004784
(Iteration 721 ) loss: 0.003869
(Iteration 741 ) loss: 0.002559
(Iteration 761 ) loss: 0.001030
(Iteration 781 ) loss: 0.000231
(Iteration 801 ) loss: 0.003875
(Iteration 821 ) loss: 0.000787
(Iteration 841 ) loss: 0.001442
(Iteration 861 ) loss: 0.001403
(Iteration 881 ) loss: 0.001971
(Iteration 901 ) loss: 0.001900
(Iteration 921 ) loss: 0.007253
(Iteration 941 ) loss: 0.006930
(Iteration 961 ) loss: 0.010999
(Iteration 981 ) loss: 0.001976
(Epoch 33 % 100) train loss: 0.0035691205894931937, eval loss: 0.003731194067849786
(Iteration 1 ) loss: 0.001387
(Iteration 21 ) loss: 0.000871
(Iteration 41 ) loss: 0.004851
(Iteration 61 ) loss: 0.003412
(Iteration 81 ) loss: 0.004556
(Iteration 101 ) loss: 0.000593
(Iteration 121 ) loss: 0.000322
(Iteration 141 ) loss: 0.000572
(Iteration 161 ) loss: 0.002816
(Iteration 181 ) loss: 0.003911
(Iteration 201 ) loss: 0.000730
(Iteration 221 ) loss: 0.000758
(Iteration 241 ) loss: 0.001904
(Iteration 261 ) loss: 0.001201
(Iteration 281 ) loss: 0.001165
(Iteration 301 ) loss: 0.000870
(Iteration 321 ) loss: 0.002852
(Iteration 341 ) loss: 0.003258
(Iteration 361 ) loss: 0.001541
(Iteration 381 ) loss: 0.002518
(Iteration 401 ) loss: 0.008488
(Iteration 421 ) loss: 0.002321
(Iteration 441 ) loss: 0.000894
(Iteration 461 ) loss: 0.000597
(Iteration 481 ) loss: 0.002112
(Iteration 501 ) loss: 0.003238
(Iteration 521 ) loss: 0.000451
(Iteration 541 ) loss: 0.001396
(Iteration 561 ) loss: 0.000300
(Iteration 581 ) loss: 0.001516
(Iteration 601 ) loss: 0.001043
(Iteration 621 ) loss: 0.001517
(Iteration 641 ) loss: 0.001748
(Iteration 661 ) loss: 0.000203
(Iteration 681 ) loss: 0.003621
(Iteration 701 ) loss: 0.001844
(Iteration 721 ) loss: 0.004505
(Iteration 741 ) loss: 0.001521
(Iteration 761 ) loss: 0.000874
(Iteration 781 ) loss: 0.004001
(Iteration 801 ) loss: 0.001774
(Iteration 821 ) loss: 0.001753
(Iteration 841 ) loss: 0.003491
(Iteration 861 ) loss: 0.002606
(Iteration 881 ) loss: 0.001618
(Iteration 901 ) loss: 0.000110
(Iteration 921 ) loss: 0.002602
(Iteration 941 ) loss: 0.004176
(Iteration 961 ) loss: 0.003221
(Iteration 981 ) loss: 0.004884
(Epoch 34 % 100) train loss: 0.0028557956832968552, eval loss: 0.002901399839185681
(Iteration 1 ) loss: 0.004708
(Iteration 21 ) loss: 0.000498
(Iteration 41 ) loss: 0.001792
(Iteration 61 ) loss: 0.000974
(Iteration 81 ) loss: 0.003022
(Iteration 101 ) loss: 0.000368
(Iteration 121 ) loss: 0.000913
(Iteration 141 ) loss: 0.001209
(Iteration 161 ) loss: 0.000410
(Iteration 181 ) loss: 0.002297
(Iteration 201 ) loss: 0.002207
(Iteration 221 ) loss: 0.000766
(Iteration 241 ) loss: 0.002504
(Iteration 261 ) loss: 0.003285
(Iteration 281 ) loss: 0.003720
(Iteration 301 ) loss: 0.002716
(Iteration 321 ) loss: 0.000796
(Iteration 341 ) loss: 0.003208
(Iteration 361 ) loss: 0.000429
(Iteration 381 ) loss: 0.001731
(Iteration 401 ) loss: 0.001083
(Iteration 421 ) loss: 0.003253
(Iteration 441 ) loss: 0.000928
(Iteration 461 ) loss: 0.004513
(Iteration 481 ) loss: 0.002368
(Iteration 501 ) loss: 0.000884
(Iteration 521 ) loss: 0.000716
(Iteration 541 ) loss: 0.001150
(Iteration 561 ) loss: 0.001571
(Iteration 581 ) loss: 0.002463
(Iteration 601 ) loss: 0.002813
(Iteration 621 ) loss: 0.001002
(Iteration 641 ) loss: 0.001020
(Iteration 661 ) loss: 0.000664
(Iteration 681 ) loss: 0.002258
(Iteration 701 ) loss: 0.005012
(Iteration 721 ) loss: 0.002809
(Iteration 741 ) loss: 0.001970
(Iteration 761 ) loss: 0.002324
(Iteration 781 ) loss: 0.002669
(Iteration 801 ) loss: 0.004632
(Iteration 821 ) loss: 0.001607
(Iteration 841 ) loss: 0.001155
(Iteration 861 ) loss: 0.003098
(Iteration 881 ) loss: 0.001104
(Iteration 901 ) loss: 0.000837
(Iteration 921 ) loss: 0.005136
(Iteration 941 ) loss: 0.001224
(Iteration 961 ) loss: 0.005475
(Iteration 981 ) loss: 0.020632
(Epoch 35 % 100) train loss: 0.001631402761982267, eval loss: 0.0014982971553171894
(Iteration 1 ) loss: 0.001661
(Iteration 21 ) loss: 0.001549
(Iteration 41 ) loss: 0.007364
(Iteration 61 ) loss: 0.001164
(Iteration 81 ) loss: 0.002104
(Iteration 101 ) loss: 0.007416
(Iteration 121 ) loss: 0.005560
(Iteration 141 ) loss: 0.001569
(Iteration 161 ) loss: 0.004391
(Iteration 181 ) loss: 0.005569
(Iteration 201 ) loss: 0.000915
(Iteration 221 ) loss: 0.000388
(Iteration 241 ) loss: 0.000418
(Iteration 261 ) loss: 0.001094
(Iteration 281 ) loss: 0.001216
(Iteration 301 ) loss: 0.005085
(Iteration 321 ) loss: 0.005485
(Iteration 341 ) loss: 0.001502
(Iteration 361 ) loss: 0.001072
(Iteration 381 ) loss: 0.000787
(Iteration 401 ) loss: 0.001612
(Iteration 421 ) loss: 0.000550
(Iteration 441 ) loss: 0.003471
(Iteration 461 ) loss: 0.004009
(Iteration 481 ) loss: 0.003328
(Iteration 501 ) loss: 0.003750
(Iteration 521 ) loss: 0.002540
(Iteration 541 ) loss: 0.001420
(Iteration 561 ) loss: 0.002892
(Iteration 581 ) loss: 0.001225
(Iteration 601 ) loss: 0.000108
(Iteration 621 ) loss: 0.000792
(Iteration 641 ) loss: 0.004276
(Iteration 661 ) loss: 0.000886
(Iteration 681 ) loss: 0.000516
(Iteration 701 ) loss: 0.003417
(Iteration 721 ) loss: 0.002289
(Iteration 741 ) loss: 0.000450
(Iteration 761 ) loss: 0.002520
(Iteration 781 ) loss: 0.000790
(Iteration 801 ) loss: 0.000846
(Iteration 821 ) loss: 0.000937
(Iteration 841 ) loss: 0.001238
(Iteration 861 ) loss: 0.000651
(Iteration 881 ) loss: 0.000654
(Iteration 901 ) loss: 0.000623
(Iteration 921 ) loss: 0.002008
(Iteration 941 ) loss: 0.001517
(Iteration 961 ) loss: 0.001124
(Iteration 981 ) loss: 0.000097
(Epoch 36 % 100) train loss: 0.0018240897982580875, eval loss: 0.001749994672804227
(Iteration 1 ) loss: 0.003507
(Iteration 21 ) loss: 0.002277
(Iteration 41 ) loss: 0.004854
(Iteration 61 ) loss: 0.000936
(Iteration 81 ) loss: 0.002228
(Iteration 101 ) loss: 0.000302
(Iteration 121 ) loss: 0.001227
(Iteration 141 ) loss: 0.001672
(Iteration 161 ) loss: 0.000295
(Iteration 181 ) loss: 0.001478
(Iteration 201 ) loss: 0.007855
(Iteration 221 ) loss: 0.008935
(Iteration 241 ) loss: 0.001548
(Iteration 261 ) loss: 0.002498
(Iteration 281 ) loss: 0.002559
(Iteration 301 ) loss: 0.000545
(Iteration 321 ) loss: 0.002773
(Iteration 341 ) loss: 0.001133
(Iteration 361 ) loss: 0.000695
(Iteration 381 ) loss: 0.000367
(Iteration 401 ) loss: 0.003908
(Iteration 421 ) loss: 0.003233
(Iteration 441 ) loss: 0.002941
(Iteration 461 ) loss: 0.008333
(Iteration 481 ) loss: 0.002437
(Iteration 501 ) loss: 0.003712
(Iteration 521 ) loss: 0.000630
(Iteration 541 ) loss: 0.001684
(Iteration 561 ) loss: 0.000186
(Iteration 581 ) loss: 0.001309
(Iteration 601 ) loss: 0.001579
(Iteration 621 ) loss: 0.001025
(Iteration 641 ) loss: 0.003686
(Iteration 661 ) loss: 0.001449
(Iteration 681 ) loss: 0.002549
(Iteration 701 ) loss: 0.001631
(Iteration 721 ) loss: 0.004618
(Iteration 741 ) loss: 0.000071
(Iteration 761 ) loss: 0.001222
(Iteration 781 ) loss: 0.000842
(Iteration 801 ) loss: 0.000056
(Iteration 821 ) loss: 0.002105
(Iteration 841 ) loss: 0.010329
(Iteration 861 ) loss: 0.001667
(Iteration 881 ) loss: 0.003280
(Iteration 901 ) loss: 0.000699
(Iteration 921 ) loss: 0.008881
(Iteration 941 ) loss: 0.002246
(Iteration 961 ) loss: 0.005404
(Iteration 981 ) loss: 0.000380
(Epoch 37 % 100) train loss: 0.0011813046257957, eval loss: 0.0010556919325931562
(Iteration 1 ) loss: 0.002265
(Iteration 21 ) loss: 0.000487
(Iteration 41 ) loss: 0.001662
(Iteration 61 ) loss: 0.009390
(Iteration 81 ) loss: 0.005759
(Iteration 101 ) loss: 0.000704
(Iteration 121 ) loss: 0.002816
(Iteration 141 ) loss: 0.001032
(Iteration 161 ) loss: 0.001033
(Iteration 181 ) loss: 0.000531
(Iteration 201 ) loss: 0.000103
(Iteration 221 ) loss: 0.001787
(Iteration 241 ) loss: 0.000213
(Iteration 261 ) loss: 0.000795
(Iteration 281 ) loss: 0.008428
(Iteration 301 ) loss: 0.002581
(Iteration 321 ) loss: 0.000397
(Iteration 341 ) loss: 0.000478
(Iteration 361 ) loss: 0.000724
(Iteration 381 ) loss: 0.002092
(Iteration 401 ) loss: 0.001023
(Iteration 421 ) loss: 0.003575
(Iteration 441 ) loss: 0.002207
(Iteration 461 ) loss: 0.002740
(Iteration 481 ) loss: 0.000415
(Iteration 501 ) loss: 0.000385
(Iteration 521 ) loss: 0.001109
(Iteration 541 ) loss: 0.002948
(Iteration 561 ) loss: 0.005201
(Iteration 581 ) loss: 0.014004
(Iteration 601 ) loss: 0.000270
(Iteration 621 ) loss: 0.003789
(Iteration 641 ) loss: 0.002636
(Iteration 661 ) loss: 0.001187
(Iteration 681 ) loss: 0.000583
(Iteration 701 ) loss: 0.001695
(Iteration 721 ) loss: 0.005459
(Iteration 741 ) loss: 0.002271
(Iteration 761 ) loss: 0.006670
(Iteration 781 ) loss: 0.000473
(Iteration 801 ) loss: 0.001697
(Iteration 821 ) loss: 0.000479
(Iteration 841 ) loss: 0.001182
(Iteration 861 ) loss: 0.000668
(Iteration 881 ) loss: 0.000534
(Iteration 901 ) loss: 0.001511
(Iteration 921 ) loss: 0.001017
(Iteration 941 ) loss: 0.000561
(Iteration 961 ) loss: 0.000550
(Iteration 981 ) loss: 0.005986
(Epoch 38 % 100) train loss: 0.0009149752666156786, eval loss: 0.0009489347905553505
(Iteration 1 ) loss: 0.000631
(Iteration 21 ) loss: 0.001314
(Iteration 41 ) loss: 0.000395
(Iteration 61 ) loss: 0.000126
(Iteration 81 ) loss: 0.001516
(Iteration 101 ) loss: 0.000612
(Iteration 121 ) loss: 0.008761
(Iteration 141 ) loss: 0.007026
(Iteration 161 ) loss: 0.003141
(Iteration 181 ) loss: 0.001065
(Iteration 201 ) loss: 0.000488
(Iteration 221 ) loss: 0.001098
(Iteration 241 ) loss: 0.007822
(Iteration 261 ) loss: 0.005849
(Iteration 281 ) loss: 0.000615
(Iteration 301 ) loss: 0.000434
(Iteration 321 ) loss: 0.001284
(Iteration 341 ) loss: 0.000921
(Iteration 361 ) loss: 0.000826
(Iteration 381 ) loss: 0.004010
(Iteration 401 ) loss: 0.001175
(Iteration 421 ) loss: 0.000545
(Iteration 441 ) loss: 0.003237
(Iteration 461 ) loss: 0.001124
(Iteration 481 ) loss: 0.000421
(Iteration 501 ) loss: 0.000488
(Iteration 521 ) loss: 0.001196
(Iteration 541 ) loss: 0.004027
(Iteration 561 ) loss: 0.007148
(Iteration 581 ) loss: 0.004086
(Iteration 601 ) loss: 0.002467
(Iteration 621 ) loss: 0.002175
(Iteration 641 ) loss: 0.002928
(Iteration 661 ) loss: 0.000386
(Iteration 681 ) loss: 0.003799
(Iteration 701 ) loss: 0.000763
(Iteration 721 ) loss: 0.000508
(Iteration 741 ) loss: 0.005859
(Iteration 761 ) loss: 0.002087
(Iteration 781 ) loss: 0.038904
(Iteration 801 ) loss: 0.000496
(Iteration 821 ) loss: 0.000715
(Iteration 841 ) loss: 0.000819
(Iteration 861 ) loss: 0.000829
(Iteration 881 ) loss: 0.003148
(Iteration 901 ) loss: 0.006709
(Iteration 921 ) loss: 0.004080
(Iteration 941 ) loss: 0.000671
(Iteration 961 ) loss: 0.000437
(Iteration 981 ) loss: 0.000291
(Epoch 39 % 100) train loss: 0.0010227296278134354, eval loss: 0.0009828428992321812
(Iteration 1 ) loss: 0.000451
(Iteration 21 ) loss: 0.001117
(Iteration 41 ) loss: 0.004143
(Iteration 61 ) loss: 0.002499
(Iteration 81 ) loss: 0.000768
(Iteration 101 ) loss: 0.000751
(Iteration 121 ) loss: 0.000746
(Iteration 141 ) loss: 0.002776
(Iteration 161 ) loss: 0.000535
(Iteration 181 ) loss: 0.003349
(Iteration 201 ) loss: 0.003028
(Iteration 221 ) loss: 0.000126
(Iteration 241 ) loss: 0.000860
(Iteration 261 ) loss: 0.000582
(Iteration 281 ) loss: 0.016589
(Iteration 301 ) loss: 0.002639
(Iteration 321 ) loss: 0.001467
(Iteration 341 ) loss: 0.000759
(Iteration 361 ) loss: 0.002531
(Iteration 381 ) loss: 0.003285
(Iteration 401 ) loss: 0.003629
(Iteration 421 ) loss: 0.005382
(Iteration 441 ) loss: 0.000477
(Iteration 461 ) loss: 0.004519
(Iteration 481 ) loss: 0.000714
(Iteration 501 ) loss: 0.000512
(Iteration 521 ) loss: 0.000567
(Iteration 541 ) loss: 0.001500
(Iteration 561 ) loss: 0.002034
(Iteration 581 ) loss: 0.002120
(Iteration 601 ) loss: 0.000128
(Iteration 621 ) loss: 0.000782
(Iteration 641 ) loss: 0.001672
(Iteration 661 ) loss: 0.000585
(Iteration 681 ) loss: 0.007303
(Iteration 701 ) loss: 0.001345
(Iteration 721 ) loss: 0.001097
(Iteration 741 ) loss: 0.005153
(Iteration 761 ) loss: 0.006942
(Iteration 781 ) loss: 0.007502
(Iteration 801 ) loss: 0.000956
(Iteration 821 ) loss: 0.000670
(Iteration 841 ) loss: 0.003646
(Iteration 861 ) loss: 0.000779
(Iteration 881 ) loss: 0.003201
(Iteration 901 ) loss: 0.000916
(Iteration 921 ) loss: 0.001879
(Iteration 941 ) loss: 0.002303
(Iteration 961 ) loss: 0.002045
(Iteration 981 ) loss: 0.001782
(Epoch 40 % 100) train loss: 0.0011044534515232947, eval loss: 0.0010998382996540565
(Iteration 1 ) loss: 0.000659
(Iteration 21 ) loss: 0.004459
(Iteration 41 ) loss: 0.002601
(Iteration 61 ) loss: 0.000747
(Iteration 81 ) loss: 0.003221
(Iteration 101 ) loss: 0.001846
(Iteration 121 ) loss: 0.001174
(Iteration 141 ) loss: 0.011000
(Iteration 161 ) loss: 0.008335
(Iteration 181 ) loss: 0.004537
(Iteration 201 ) loss: 0.000707
(Iteration 221 ) loss: 0.000133
(Iteration 241 ) loss: 0.006638
(Iteration 261 ) loss: 0.001228
(Iteration 281 ) loss: 0.006184
(Iteration 301 ) loss: 0.002100
(Iteration 321 ) loss: 0.003947
(Iteration 341 ) loss: 0.003035
(Iteration 361 ) loss: 0.000193
(Iteration 381 ) loss: 0.005257
(Iteration 401 ) loss: 0.005824
(Iteration 421 ) loss: 0.011563
(Iteration 441 ) loss: 0.002691
(Iteration 461 ) loss: 0.002180
(Iteration 481 ) loss: 0.001785
(Iteration 501 ) loss: 0.002091
(Iteration 521 ) loss: 0.002769
(Iteration 541 ) loss: 0.001995
(Iteration 561 ) loss: 0.000618
(Iteration 581 ) loss: 0.000317
(Iteration 601 ) loss: 0.001204
(Iteration 621 ) loss: 0.000298
(Iteration 641 ) loss: 0.001309
(Iteration 661 ) loss: 0.004520
(Iteration 681 ) loss: 0.006989
(Iteration 701 ) loss: 0.000182
(Iteration 721 ) loss: 0.001312
(Iteration 741 ) loss: 0.000570
(Iteration 761 ) loss: 0.002143
(Iteration 781 ) loss: 0.000506
(Iteration 801 ) loss: 0.002193
(Iteration 821 ) loss: 0.000739
(Iteration 841 ) loss: 0.000759
(Iteration 861 ) loss: 0.000898
(Iteration 881 ) loss: 0.000957
(Iteration 901 ) loss: 0.000656
(Iteration 921 ) loss: 0.000965
(Iteration 941 ) loss: 0.000730
(Iteration 961 ) loss: 0.003738
(Iteration 981 ) loss: 0.001864
(Epoch 41 % 100) train loss: 0.0010089846034224204, eval loss: 0.0009905298848478564
(Iteration 1 ) loss: 0.001844
(Iteration 21 ) loss: 0.000135
(Iteration 41 ) loss: 0.001397
(Iteration 61 ) loss: 0.001176
(Iteration 81 ) loss: 0.001142
(Iteration 101 ) loss: 0.000750
(Iteration 121 ) loss: 0.000223
(Iteration 141 ) loss: 0.004684
(Iteration 161 ) loss: 0.000814
(Iteration 181 ) loss: 0.002037
(Iteration 201 ) loss: 0.000772
(Iteration 221 ) loss: 0.001788
(Iteration 241 ) loss: 0.001439
(Iteration 261 ) loss: 0.000805
(Iteration 281 ) loss: 0.000355
(Iteration 301 ) loss: 0.003219
(Iteration 321 ) loss: 0.002900
(Iteration 341 ) loss: 0.004706
(Iteration 361 ) loss: 0.000686
(Iteration 381 ) loss: 0.000468
(Iteration 401 ) loss: 0.000958
(Iteration 421 ) loss: 0.000783
(Iteration 441 ) loss: 0.000552
(Iteration 461 ) loss: 0.001917
(Iteration 481 ) loss: 0.001844
(Iteration 501 ) loss: 0.000657
(Iteration 521 ) loss: 0.010075
(Iteration 541 ) loss: 0.001466
(Iteration 561 ) loss: 0.002058
(Iteration 581 ) loss: 0.000847
(Iteration 601 ) loss: 0.000974
(Iteration 621 ) loss: 0.004101
(Iteration 641 ) loss: 0.000621
(Iteration 661 ) loss: 0.000534
(Iteration 681 ) loss: 0.000997
(Iteration 701 ) loss: 0.000568
(Iteration 721 ) loss: 0.000964
(Iteration 741 ) loss: 0.004259
(Iteration 761 ) loss: 0.002412
(Iteration 781 ) loss: 0.000096
(Iteration 801 ) loss: 0.009822
(Iteration 821 ) loss: 0.002957
(Iteration 841 ) loss: 0.001313
(Iteration 861 ) loss: 0.001272
(Iteration 881 ) loss: 0.001191
(Iteration 901 ) loss: 0.003175
(Iteration 921 ) loss: 0.002119
(Iteration 941 ) loss: 0.001030
(Iteration 961 ) loss: 0.000468
(Iteration 981 ) loss: 0.001265
(Epoch 42 % 100) train loss: 0.0012543578850202622, eval loss: 0.001278437960911087
(Iteration 1 ) loss: 0.000610
(Iteration 21 ) loss: 0.007359
(Iteration 41 ) loss: 0.001408
(Iteration 61 ) loss: 0.000073
(Iteration 81 ) loss: 0.000929
(Iteration 101 ) loss: 0.002645
(Iteration 121 ) loss: 0.017192
(Iteration 141 ) loss: 0.003208
(Iteration 161 ) loss: 0.019197
(Iteration 181 ) loss: 0.001073
(Iteration 201 ) loss: 0.007476
(Iteration 221 ) loss: 0.002974
(Iteration 241 ) loss: 0.001438
(Iteration 261 ) loss: 0.001719
(Iteration 281 ) loss: 0.000655
(Iteration 301 ) loss: 0.001342
(Iteration 321 ) loss: 0.001232
(Iteration 341 ) loss: 0.000716
(Iteration 361 ) loss: 0.005710
(Iteration 381 ) loss: 0.002276
(Iteration 401 ) loss: 0.000948
(Iteration 421 ) loss: 0.002231
(Iteration 441 ) loss: 0.003157
(Iteration 461 ) loss: 0.001032
(Iteration 481 ) loss: 0.003182
(Iteration 501 ) loss: 0.000766
(Iteration 521 ) loss: 0.008420
(Iteration 541 ) loss: 0.003148
(Iteration 561 ) loss: 0.000352
(Iteration 581 ) loss: 0.001966
(Iteration 601 ) loss: 0.002551
(Iteration 621 ) loss: 0.001290
(Iteration 641 ) loss: 0.000547
(Iteration 661 ) loss: 0.001134
(Iteration 681 ) loss: 0.006318
(Iteration 701 ) loss: 0.000850
(Iteration 721 ) loss: 0.000786
(Iteration 741 ) loss: 0.002829
(Iteration 761 ) loss: 0.000854
(Iteration 781 ) loss: 0.001701
(Iteration 801 ) loss: 0.001228
(Iteration 821 ) loss: 0.003362
(Iteration 841 ) loss: 0.000493
(Iteration 861 ) loss: 0.001619
(Iteration 881 ) loss: 0.000526
(Iteration 901 ) loss: 0.001266
(Iteration 921 ) loss: 0.000430
(Iteration 941 ) loss: 0.002858
(Iteration 961 ) loss: 0.000841
(Iteration 981 ) loss: 0.001088
(Epoch 43 % 100) train loss: 0.0007871310776214726, eval loss: 0.0008273628660148596
(Iteration 1 ) loss: 0.000447
(Iteration 21 ) loss: 0.001422
(Iteration 41 ) loss: 0.000395
(Iteration 61 ) loss: 0.000401
(Iteration 81 ) loss: 0.000694
(Iteration 101 ) loss: 0.000518
(Iteration 121 ) loss: 0.000318
(Iteration 141 ) loss: 0.001072
(Iteration 161 ) loss: 0.011018
(Iteration 181 ) loss: 0.002763
(Iteration 201 ) loss: 0.001272
(Iteration 221 ) loss: 0.002647
(Iteration 241 ) loss: 0.004927
(Iteration 261 ) loss: 0.000217
(Iteration 281 ) loss: 0.001024
(Iteration 301 ) loss: 0.001353
(Iteration 321 ) loss: 0.000176
(Iteration 341 ) loss: 0.001787
(Iteration 361 ) loss: 0.001834
(Iteration 381 ) loss: 0.004798
(Iteration 401 ) loss: 0.001644
(Iteration 421 ) loss: 0.001501
(Iteration 441 ) loss: 0.000603
(Iteration 461 ) loss: 0.011154
(Iteration 481 ) loss: 0.002348
(Iteration 501 ) loss: 0.001680
(Iteration 521 ) loss: 0.000970
(Iteration 541 ) loss: 0.001580
(Iteration 561 ) loss: 0.008494
(Iteration 581 ) loss: 0.001773
(Iteration 601 ) loss: 0.001040
(Iteration 621 ) loss: 0.002980
(Iteration 641 ) loss: 0.001013
(Iteration 661 ) loss: 0.002588
(Iteration 681 ) loss: 0.001284
(Iteration 701 ) loss: 0.002763
(Iteration 721 ) loss: 0.000863
(Iteration 741 ) loss: 0.004057
(Iteration 761 ) loss: 0.001861
(Iteration 781 ) loss: 0.001511
(Iteration 801 ) loss: 0.000445
(Iteration 821 ) loss: 0.001854
(Iteration 841 ) loss: 0.005998
(Iteration 861 ) loss: 0.001291
(Iteration 881 ) loss: 0.000614
(Iteration 901 ) loss: 0.003573
(Iteration 921 ) loss: 0.009242
(Iteration 941 ) loss: 0.000765
(Iteration 961 ) loss: 0.001853
(Iteration 981 ) loss: 0.000693
(Epoch 44 % 100) train loss: 0.0010511735516659123, eval loss: 0.001020844355934745
(Iteration 1 ) loss: 0.001089
(Iteration 21 ) loss: 0.004817
(Iteration 41 ) loss: 0.000813
(Iteration 61 ) loss: 0.000214
(Iteration 81 ) loss: 0.001765
(Iteration 101 ) loss: 0.000897
(Iteration 121 ) loss: 0.006393
(Iteration 141 ) loss: 0.001664
(Iteration 161 ) loss: 0.000653
(Iteration 181 ) loss: 0.001273
(Iteration 201 ) loss: 0.000719
(Iteration 221 ) loss: 0.000827
(Iteration 241 ) loss: 0.000367
(Iteration 261 ) loss: 0.000784
(Iteration 281 ) loss: 0.002758
(Iteration 301 ) loss: 0.000901
(Iteration 321 ) loss: 0.000196
(Iteration 341 ) loss: 0.000892
(Iteration 361 ) loss: 0.000857
(Iteration 381 ) loss: 0.001268
(Iteration 401 ) loss: 0.000770
(Iteration 421 ) loss: 0.002729
(Iteration 441 ) loss: 0.001048
(Iteration 461 ) loss: 0.003018
(Iteration 481 ) loss: 0.000919
(Iteration 501 ) loss: 0.001788
(Iteration 521 ) loss: 0.000851
(Iteration 541 ) loss: 0.001140
(Iteration 561 ) loss: 0.001804
(Iteration 581 ) loss: 0.000709
(Iteration 601 ) loss: 0.000709
(Iteration 621 ) loss: 0.001516
(Iteration 641 ) loss: 0.001143
(Iteration 661 ) loss: 0.000970
(Iteration 681 ) loss: 0.008452
(Iteration 701 ) loss: 0.000399
(Iteration 721 ) loss: 0.000733
(Iteration 741 ) loss: 0.003691
(Iteration 761 ) loss: 0.001565
(Iteration 781 ) loss: 0.001336
(Iteration 801 ) loss: 0.003055
(Iteration 821 ) loss: 0.000869
(Iteration 841 ) loss: 0.003285
(Iteration 861 ) loss: 0.000924
(Iteration 881 ) loss: 0.001355
(Iteration 901 ) loss: 0.001208
(Iteration 921 ) loss: 0.002041
(Iteration 941 ) loss: 0.000207
(Iteration 961 ) loss: 0.001599
(Iteration 981 ) loss: 0.005164
(Epoch 45 % 100) train loss: 0.0023443660962482265, eval loss: 0.0024054749109674793
(Iteration 1 ) loss: 0.002495
(Iteration 21 ) loss: 0.000580
(Iteration 41 ) loss: 0.003614
(Iteration 61 ) loss: 0.000371
(Iteration 81 ) loss: 0.001307
(Iteration 101 ) loss: 0.001532
(Iteration 121 ) loss: 0.003143
(Iteration 141 ) loss: 0.001723
(Iteration 161 ) loss: 0.004550
(Iteration 181 ) loss: 0.002237
(Iteration 201 ) loss: 0.001642
(Iteration 221 ) loss: 0.000469
(Iteration 241 ) loss: 0.001113
(Iteration 261 ) loss: 0.001384
(Iteration 281 ) loss: 0.000312
(Iteration 301 ) loss: 0.000852
(Iteration 321 ) loss: 0.000775
(Iteration 341 ) loss: 0.003612
(Iteration 361 ) loss: 0.004588
(Iteration 381 ) loss: 0.001530
(Iteration 401 ) loss: 0.003349
(Iteration 421 ) loss: 0.001521
(Iteration 441 ) loss: 0.001189
(Iteration 461 ) loss: 0.002128
(Iteration 481 ) loss: 0.002140
(Iteration 501 ) loss: 0.000962
(Iteration 521 ) loss: 0.005598
(Iteration 541 ) loss: 0.004323
(Iteration 561 ) loss: 0.001298
(Iteration 581 ) loss: 0.004227
(Iteration 601 ) loss: 0.002721
(Iteration 621 ) loss: 0.002117
(Iteration 641 ) loss: 0.001566
(Iteration 661 ) loss: 0.002149
(Iteration 681 ) loss: 0.000979
(Iteration 701 ) loss: 0.000250
(Iteration 721 ) loss: 0.004650
(Iteration 741 ) loss: 0.003666
(Iteration 761 ) loss: 0.000956
(Iteration 781 ) loss: 0.000464
(Iteration 801 ) loss: 0.000149
(Iteration 821 ) loss: 0.001673
(Iteration 841 ) loss: 0.000701
(Iteration 861 ) loss: 0.001630
(Iteration 881 ) loss: 0.000989
(Iteration 901 ) loss: 0.000479
(Iteration 921 ) loss: 0.002476
(Iteration 941 ) loss: 0.001028
(Iteration 961 ) loss: 0.000709
(Iteration 981 ) loss: 0.000333
(Epoch 46 % 100) train loss: 0.0009295368174302467, eval loss: 0.0009488313091795693
(Iteration 1 ) loss: 0.000678
(Iteration 21 ) loss: 0.000511
(Iteration 41 ) loss: 0.001137
(Iteration 61 ) loss: 0.007634
(Iteration 81 ) loss: 0.000155
(Iteration 101 ) loss: 0.001446
(Iteration 121 ) loss: 0.001823
(Iteration 141 ) loss: 0.002720
(Iteration 161 ) loss: 0.000469
(Iteration 181 ) loss: 0.001741
(Iteration 201 ) loss: 0.004115
(Iteration 221 ) loss: 0.006936
(Iteration 241 ) loss: 0.001953
(Iteration 261 ) loss: 0.001894
(Iteration 281 ) loss: 0.000425
(Iteration 301 ) loss: 0.001350
(Iteration 321 ) loss: 0.001836
(Iteration 341 ) loss: 0.000371
(Iteration 361 ) loss: 0.000408
(Iteration 381 ) loss: 0.001782
(Iteration 401 ) loss: 0.000184
(Iteration 421 ) loss: 0.003433
(Iteration 441 ) loss: 0.001719
(Iteration 461 ) loss: 0.000859
(Iteration 481 ) loss: 0.000701
(Iteration 501 ) loss: 0.000349
(Iteration 521 ) loss: 0.001739
(Iteration 541 ) loss: 0.002384
(Iteration 561 ) loss: 0.001097
(Iteration 581 ) loss: 0.000858
(Iteration 601 ) loss: 0.002963
(Iteration 621 ) loss: 0.001464
(Iteration 641 ) loss: 0.001994
(Iteration 661 ) loss: 0.001287
(Iteration 681 ) loss: 0.000601
(Iteration 701 ) loss: 0.002332
(Iteration 721 ) loss: 0.001143
(Iteration 741 ) loss: 0.002201
(Iteration 761 ) loss: 0.000919
(Iteration 781 ) loss: 0.000928
(Iteration 801 ) loss: 0.001311
(Iteration 821 ) loss: 0.000630
(Iteration 841 ) loss: 0.001317
(Iteration 861 ) loss: 0.001492
(Iteration 881 ) loss: 0.001274
(Iteration 901 ) loss: 0.000234
(Iteration 921 ) loss: 0.001752
(Iteration 941 ) loss: 0.002520
(Iteration 961 ) loss: 0.000892
(Iteration 981 ) loss: 0.001499
(Epoch 47 % 100) train loss: 0.004275143130112573, eval loss: 0.004240978460338235
(Iteration 1 ) loss: 0.005210
(Iteration 21 ) loss: 0.000177
(Iteration 41 ) loss: 0.002282
(Iteration 61 ) loss: 0.000740
(Iteration 81 ) loss: 0.000571
(Iteration 101 ) loss: 0.003378
(Iteration 121 ) loss: 0.000548
(Iteration 141 ) loss: 0.001725
(Iteration 161 ) loss: 0.000221
(Iteration 181 ) loss: 0.000644
(Iteration 201 ) loss: 0.001954
(Iteration 221 ) loss: 0.004578
(Iteration 241 ) loss: 0.005977
(Iteration 261 ) loss: 0.001298
(Iteration 281 ) loss: 0.002881
(Iteration 301 ) loss: 0.001385
(Iteration 321 ) loss: 0.001382
(Iteration 341 ) loss: 0.001376
(Iteration 361 ) loss: 0.000688
(Iteration 381 ) loss: 0.003329
(Iteration 401 ) loss: 0.005141
(Iteration 421 ) loss: 0.003884
(Iteration 441 ) loss: 0.003740
(Iteration 461 ) loss: 0.003641
(Iteration 481 ) loss: 0.004090
(Iteration 501 ) loss: 0.000377
(Iteration 521 ) loss: 0.001507
(Iteration 541 ) loss: 0.002028
(Iteration 561 ) loss: 0.001161
(Iteration 581 ) loss: 0.001677
(Iteration 601 ) loss: 0.003015
(Iteration 621 ) loss: 0.001087
(Iteration 641 ) loss: 0.001638
(Iteration 661 ) loss: 0.001978
(Iteration 681 ) loss: 0.000539
(Iteration 701 ) loss: 0.001178
(Iteration 721 ) loss: 0.001045
(Iteration 741 ) loss: 0.003505
(Iteration 761 ) loss: 0.003491
(Iteration 781 ) loss: 0.001013
(Iteration 801 ) loss: 0.002243
(Iteration 821 ) loss: 0.001622
(Iteration 841 ) loss: 0.005067
(Iteration 861 ) loss: 0.000992
(Iteration 881 ) loss: 0.002922
(Iteration 901 ) loss: 0.002495
(Iteration 921 ) loss: 0.000948
(Iteration 941 ) loss: 0.000935
(Iteration 961 ) loss: 0.002236
(Iteration 981 ) loss: 0.002740
(Epoch 48 % 100) train loss: 0.0026756683789463703, eval loss: 0.0028536395169731607
(Iteration 1 ) loss: 0.000073
(Iteration 21 ) loss: 0.001650
(Iteration 41 ) loss: 0.001297
(Iteration 61 ) loss: 0.000414
(Iteration 81 ) loss: 0.000913
(Iteration 101 ) loss: 0.000586
(Iteration 121 ) loss: 0.000213
(Iteration 141 ) loss: 0.001270
(Iteration 161 ) loss: 0.001194
(Iteration 181 ) loss: 0.000790
(Iteration 201 ) loss: 0.004617
(Iteration 221 ) loss: 0.002343
(Iteration 241 ) loss: 0.000274
(Iteration 261 ) loss: 0.001769
(Iteration 281 ) loss: 0.000508
(Iteration 301 ) loss: 0.002364
(Iteration 321 ) loss: 0.000410
(Iteration 341 ) loss: 0.000580
(Iteration 361 ) loss: 0.001191
(Iteration 381 ) loss: 0.002315
(Iteration 401 ) loss: 0.000974
(Iteration 421 ) loss: 0.000295
(Iteration 441 ) loss: 0.001711
(Iteration 461 ) loss: 0.001350
(Iteration 481 ) loss: 0.000364
(Iteration 501 ) loss: 0.001197
(Iteration 521 ) loss: 0.002195
(Iteration 541 ) loss: 0.003649
(Iteration 561 ) loss: 0.000674
(Iteration 581 ) loss: 0.001339
(Iteration 601 ) loss: 0.000430
(Iteration 621 ) loss: 0.002491
(Iteration 641 ) loss: 0.005136
(Iteration 661 ) loss: 0.001588
(Iteration 681 ) loss: 0.002564
(Iteration 701 ) loss: 0.000702
(Iteration 721 ) loss: 0.002542
(Iteration 741 ) loss: 0.000350
(Iteration 761 ) loss: 0.001656
(Iteration 781 ) loss: 0.001241
(Iteration 801 ) loss: 0.000544
(Iteration 821 ) loss: 0.001279
(Iteration 841 ) loss: 0.001499
(Iteration 861 ) loss: 0.001681
(Iteration 881 ) loss: 0.004363
(Iteration 901 ) loss: 0.001190
(Iteration 921 ) loss: 0.000790
(Iteration 941 ) loss: 0.000528
(Iteration 961 ) loss: 0.000397
(Iteration 981 ) loss: 0.000653
(Epoch 49 % 100) train loss: 0.0010255290285625706, eval loss: 0.0011148147652869519
(Iteration 1 ) loss: 0.000778
(Iteration 21 ) loss: 0.001121
(Iteration 41 ) loss: 0.001397
(Iteration 61 ) loss: 0.000361
(Iteration 81 ) loss: 0.007349
(Iteration 101 ) loss: 0.000805
(Iteration 121 ) loss: 0.001438
(Iteration 141 ) loss: 0.000974
(Iteration 161 ) loss: 0.000759
(Iteration 181 ) loss: 0.000744
(Iteration 201 ) loss: 0.000394
(Iteration 221 ) loss: 0.000881
(Iteration 241 ) loss: 0.000474
(Iteration 261 ) loss: 0.001465
(Iteration 281 ) loss: 0.000845
(Iteration 301 ) loss: 0.000120
(Iteration 321 ) loss: 0.005953
(Iteration 341 ) loss: 0.001003
(Iteration 361 ) loss: 0.000798
(Iteration 381 ) loss: 0.002810
(Iteration 401 ) loss: 0.003785
(Iteration 421 ) loss: 0.001232
(Iteration 441 ) loss: 0.001882
(Iteration 461 ) loss: 0.000367
(Iteration 481 ) loss: 0.000199
(Iteration 501 ) loss: 0.000220
(Iteration 521 ) loss: 0.003208
(Iteration 541 ) loss: 0.002488
(Iteration 561 ) loss: 0.000256
(Iteration 581 ) loss: 0.001868
(Iteration 601 ) loss: 0.000983
(Iteration 621 ) loss: 0.000790
(Iteration 641 ) loss: 0.001316
(Iteration 661 ) loss: 0.000885
(Iteration 681 ) loss: 0.000885
(Iteration 701 ) loss: 0.001695
(Iteration 721 ) loss: 0.000989
(Iteration 741 ) loss: 0.002702
(Iteration 761 ) loss: 0.001024
(Iteration 781 ) loss: 0.001054
(Iteration 801 ) loss: 0.000899
(Iteration 821 ) loss: 0.001225
(Iteration 841 ) loss: 0.000244
(Iteration 861 ) loss: 0.001713
(Iteration 881 ) loss: 0.000189
(Iteration 901 ) loss: 0.000830
(Iteration 921 ) loss: 0.001350
(Iteration 941 ) loss: 0.000789
(Iteration 961 ) loss: 0.000091
(Iteration 981 ) loss: 0.003509
(Epoch 50 % 100) train loss: 0.002144859729202844, eval loss: 0.0021869840562503615
(Iteration 1 ) loss: 0.002962
(Iteration 21 ) loss: 0.000418
(Iteration 41 ) loss: 0.005016
(Iteration 61 ) loss: 0.000391
(Iteration 81 ) loss: 0.002298
(Iteration 101 ) loss: 0.001025
(Iteration 121 ) loss: 0.000415
(Iteration 141 ) loss: 0.000264
(Iteration 161 ) loss: 0.004228
(Iteration 181 ) loss: 0.001361
(Iteration 201 ) loss: 0.001329
(Iteration 221 ) loss: 0.003061
(Iteration 241 ) loss: 0.001286
(Iteration 261 ) loss: 0.001637
(Iteration 281 ) loss: 0.000626
(Iteration 301 ) loss: 0.004986
(Iteration 321 ) loss: 0.001877
(Iteration 341 ) loss: 0.001583
(Iteration 361 ) loss: 0.000192
(Iteration 381 ) loss: 0.000914
(Iteration 401 ) loss: 0.001804
(Iteration 421 ) loss: 0.001766
(Iteration 441 ) loss: 0.004263
(Iteration 461 ) loss: 0.001201
(Iteration 481 ) loss: 0.003037
(Iteration 501 ) loss: 0.001975
(Iteration 521 ) loss: 0.000206
(Iteration 541 ) loss: 0.001760
(Iteration 561 ) loss: 0.001351
(Iteration 581 ) loss: 0.000974
(Iteration 601 ) loss: 0.007385
(Iteration 621 ) loss: 0.003381
(Iteration 641 ) loss: 0.001310
(Iteration 661 ) loss: 0.000484
(Iteration 681 ) loss: 0.001588
(Iteration 701 ) loss: 0.000478
(Iteration 721 ) loss: 0.000827
(Iteration 741 ) loss: 0.001824
(Iteration 761 ) loss: 0.001371
(Iteration 781 ) loss: 0.000504
(Iteration 801 ) loss: 0.000489
(Iteration 821 ) loss: 0.001300
(Iteration 841 ) loss: 0.000733
(Iteration 861 ) loss: 0.001125
(Iteration 881 ) loss: 0.000559
(Iteration 901 ) loss: 0.000621
(Iteration 921 ) loss: 0.001330
(Iteration 941 ) loss: 0.001828
(Iteration 961 ) loss: 0.000274
(Iteration 981 ) loss: 0.002148
(Epoch 51 % 100) train loss: 0.0013665793107989974, eval loss: 0.0012699918384224804
(Iteration 1 ) loss: 0.000619
(Iteration 21 ) loss: 0.003907
(Iteration 41 ) loss: 0.000898
(Iteration 61 ) loss: 0.006138
(Iteration 81 ) loss: 0.004321
(Iteration 101 ) loss: 0.001014
(Iteration 121 ) loss: 0.004091
(Iteration 141 ) loss: 0.000681
(Iteration 161 ) loss: 0.000191
(Iteration 181 ) loss: 0.000424
(Iteration 201 ) loss: 0.000420
(Iteration 221 ) loss: 0.001172
(Iteration 241 ) loss: 0.002067
(Iteration 261 ) loss: 0.001089
(Iteration 281 ) loss: 0.000054
(Iteration 301 ) loss: 0.001327
(Iteration 321 ) loss: 0.000376
(Iteration 341 ) loss: 0.000282
(Iteration 361 ) loss: 0.000246
(Iteration 381 ) loss: 0.000783
(Iteration 401 ) loss: 0.000426
(Iteration 421 ) loss: 0.000702
(Iteration 441 ) loss: 0.002379
(Iteration 461 ) loss: 0.003251
(Iteration 481 ) loss: 0.002415
(Iteration 501 ) loss: 0.001558
(Iteration 521 ) loss: 0.001531
(Iteration 541 ) loss: 0.001874
(Iteration 561 ) loss: 0.000929
(Iteration 581 ) loss: 0.009048
(Iteration 601 ) loss: 0.000482
(Iteration 621 ) loss: 0.003023
(Iteration 641 ) loss: 0.001499
(Iteration 661 ) loss: 0.001070
(Iteration 681 ) loss: 0.001948
(Iteration 701 ) loss: 0.001138
(Iteration 721 ) loss: 0.001125
(Iteration 741 ) loss: 0.001325
(Iteration 761 ) loss: 0.000385
(Iteration 781 ) loss: 0.000925
(Iteration 801 ) loss: 0.000227
(Iteration 821 ) loss: 0.001936
(Iteration 841 ) loss: 0.000677
(Iteration 861 ) loss: 0.001018
(Iteration 881 ) loss: 0.000672
(Iteration 901 ) loss: 0.001301
(Iteration 921 ) loss: 0.001223
(Iteration 941 ) loss: 0.003081
(Iteration 961 ) loss: 0.001708
(Iteration 981 ) loss: 0.000431
(Epoch 52 % 100) train loss: 0.0011838212838959983, eval loss: 0.001131466365988812
(Iteration 1 ) loss: 0.001614
(Iteration 21 ) loss: 0.002335
(Iteration 41 ) loss: 0.001296
(Iteration 61 ) loss: 0.003820
(Iteration 81 ) loss: 0.002530
(Iteration 101 ) loss: 0.000575
(Iteration 121 ) loss: 0.000768
(Iteration 141 ) loss: 0.001035
(Iteration 161 ) loss: 0.001248
(Iteration 181 ) loss: 0.000829
(Iteration 201 ) loss: 0.000429
(Iteration 221 ) loss: 0.001455
(Iteration 241 ) loss: 0.001865
(Iteration 261 ) loss: 0.001402
(Iteration 281 ) loss: 0.000207
(Iteration 301 ) loss: 0.001309
(Iteration 321 ) loss: 0.000905
(Iteration 341 ) loss: 0.001210
(Iteration 361 ) loss: 0.000478
(Iteration 381 ) loss: 0.000690
(Iteration 401 ) loss: 0.000395
(Iteration 421 ) loss: 0.001394
(Iteration 441 ) loss: 0.000521
(Iteration 461 ) loss: 0.000934
(Iteration 481 ) loss: 0.000563
(Iteration 501 ) loss: 0.004761
(Iteration 521 ) loss: 0.010176
(Iteration 541 ) loss: 0.000682
(Iteration 561 ) loss: 0.001022
(Iteration 581 ) loss: 0.006464
(Iteration 601 ) loss: 0.001319
(Iteration 621 ) loss: 0.001863
(Iteration 641 ) loss: 0.000234
(Iteration 661 ) loss: 0.000982
(Iteration 681 ) loss: 0.001745
(Iteration 701 ) loss: 0.001248
(Iteration 721 ) loss: 0.000093
(Iteration 741 ) loss: 0.002516
(Iteration 761 ) loss: 0.007200
(Iteration 781 ) loss: 0.006349
(Iteration 801 ) loss: 0.000274
(Iteration 821 ) loss: 0.000785
(Iteration 841 ) loss: 0.000669
(Iteration 861 ) loss: 0.000165
(Iteration 881 ) loss: 0.001786
(Iteration 901 ) loss: 0.000195
(Iteration 921 ) loss: 0.005426
(Iteration 941 ) loss: 0.001684
(Iteration 961 ) loss: 0.001529
(Iteration 981 ) loss: 0.000365
(Epoch 53 % 100) train loss: 0.001617326520305195, eval loss: 0.0015687287843804854
(Iteration 1 ) loss: 0.000906
(Iteration 21 ) loss: 0.000911
(Iteration 41 ) loss: 0.000811
(Iteration 61 ) loss: 0.000527
(Iteration 81 ) loss: 0.000323
(Iteration 101 ) loss: 0.000357
(Iteration 121 ) loss: 0.001377
(Iteration 141 ) loss: 0.000436
(Iteration 161 ) loss: 0.001777
(Iteration 181 ) loss: 0.001939
(Iteration 201 ) loss: 0.000426
(Iteration 221 ) loss: 0.002722
(Iteration 241 ) loss: 0.001125
(Iteration 261 ) loss: 0.000387
(Iteration 281 ) loss: 0.000780
(Iteration 301 ) loss: 0.001401
(Iteration 321 ) loss: 0.002485
(Iteration 341 ) loss: 0.000467
(Iteration 361 ) loss: 0.000055
(Iteration 381 ) loss: 0.002409
(Iteration 401 ) loss: 0.000118
(Iteration 421 ) loss: 0.001399
(Iteration 441 ) loss: 0.000683
(Iteration 461 ) loss: 0.000820
(Iteration 481 ) loss: 0.001633
(Iteration 501 ) loss: 0.000654
(Iteration 521 ) loss: 0.003611
(Iteration 541 ) loss: 0.001360
(Iteration 561 ) loss: 0.000118
(Iteration 581 ) loss: 0.001596
(Iteration 601 ) loss: 0.001196
(Iteration 621 ) loss: 0.002821
(Iteration 641 ) loss: 0.002264
(Iteration 661 ) loss: 0.001402
(Iteration 681 ) loss: 0.000149
(Iteration 701 ) loss: 0.002123
(Iteration 721 ) loss: 0.000665
(Iteration 741 ) loss: 0.000691
(Iteration 761 ) loss: 0.002144
(Iteration 781 ) loss: 0.001956
(Iteration 801 ) loss: 0.001411
(Iteration 821 ) loss: 0.000654
(Iteration 841 ) loss: 0.001835
(Iteration 861 ) loss: 0.003857
(Iteration 881 ) loss: 0.000555
(Iteration 901 ) loss: 0.000510
(Iteration 921 ) loss: 0.000857
(Iteration 941 ) loss: 0.000345
(Iteration 961 ) loss: 0.000804
(Iteration 981 ) loss: 0.001635
(Epoch 54 % 100) train loss: 0.00209078441496033, eval loss: 0.002067239896961187
(Iteration 1 ) loss: 0.001190
(Iteration 21 ) loss: 0.002798
(Iteration 41 ) loss: 0.000242
(Iteration 61 ) loss: 0.000785
(Iteration 81 ) loss: 0.000632
(Iteration 101 ) loss: 0.000351
(Iteration 121 ) loss: 0.000562
(Iteration 141 ) loss: 0.000156
(Iteration 161 ) loss: 0.000754
(Iteration 181 ) loss: 0.001339
(Iteration 201 ) loss: 0.001664
(Iteration 221 ) loss: 0.001809
(Iteration 241 ) loss: 0.000738
(Iteration 261 ) loss: 0.000330
(Iteration 281 ) loss: 0.002079
(Iteration 301 ) loss: 0.000314
(Iteration 321 ) loss: 0.005061
(Iteration 341 ) loss: 0.007602
(Iteration 361 ) loss: 0.000948
(Iteration 381 ) loss: 0.003374
(Iteration 401 ) loss: 0.002645
(Iteration 421 ) loss: 0.000745
(Iteration 441 ) loss: 0.000425
(Iteration 461 ) loss: 0.000675
(Iteration 481 ) loss: 0.001318
(Iteration 501 ) loss: 0.000598
(Iteration 521 ) loss: 0.001393
(Iteration 541 ) loss: 0.003761
(Iteration 561 ) loss: 0.001626
(Iteration 581 ) loss: 0.000324
(Iteration 601 ) loss: 0.000258
(Iteration 621 ) loss: 0.001602
(Iteration 641 ) loss: 0.001095
(Iteration 661 ) loss: 0.000068
(Iteration 681 ) loss: 0.000693
(Iteration 701 ) loss: 0.000409
(Iteration 721 ) loss: 0.001654
(Iteration 741 ) loss: 0.000769
(Iteration 761 ) loss: 0.000798
(Iteration 781 ) loss: 0.000643
(Iteration 801 ) loss: 0.000575
(Iteration 821 ) loss: 0.000505
(Iteration 841 ) loss: 0.000449
(Iteration 861 ) loss: 0.000381
(Iteration 881 ) loss: 0.004324
(Iteration 901 ) loss: 0.007844
(Iteration 921 ) loss: 0.001065
(Iteration 941 ) loss: 0.000426
(Iteration 961 ) loss: 0.001947
(Iteration 981 ) loss: 0.000667
(Epoch 55 % 100) train loss: 0.002613545968900823, eval loss: 0.002632273653268447
(Iteration 1 ) loss: 0.002639
(Iteration 21 ) loss: 0.000389
(Iteration 41 ) loss: 0.001021
(Iteration 61 ) loss: 0.001430
(Iteration 81 ) loss: 0.000476
(Iteration 101 ) loss: 0.000205
(Iteration 121 ) loss: 0.000164
(Iteration 141 ) loss: 0.001668
(Iteration 161 ) loss: 0.000732
(Iteration 181 ) loss: 0.000580
(Iteration 201 ) loss: 0.002400
(Iteration 221 ) loss: 0.000344
(Iteration 241 ) loss: 0.000312
(Iteration 261 ) loss: 0.000524
(Iteration 281 ) loss: 0.000415
(Iteration 301 ) loss: 0.000740
(Iteration 321 ) loss: 0.000431
(Iteration 341 ) loss: 0.001911
(Iteration 361 ) loss: 0.001063
(Iteration 381 ) loss: 0.000647
(Iteration 401 ) loss: 0.002703
(Iteration 421 ) loss: 0.009842
(Iteration 441 ) loss: 0.004205
(Iteration 461 ) loss: 0.002726
(Iteration 481 ) loss: 0.002193
(Iteration 501 ) loss: 0.001591
(Iteration 521 ) loss: 0.000601
(Iteration 541 ) loss: 0.003246
(Iteration 561 ) loss: 0.000648
(Iteration 581 ) loss: 0.001085
(Iteration 601 ) loss: 0.000144
(Iteration 621 ) loss: 0.001596
(Iteration 641 ) loss: 0.000224
(Iteration 661 ) loss: 0.001382
(Iteration 681 ) loss: 0.001125
(Iteration 701 ) loss: 0.000376
(Iteration 721 ) loss: 0.000691
(Iteration 741 ) loss: 0.001781
(Iteration 761 ) loss: 0.001432
(Iteration 781 ) loss: 0.000962
(Iteration 801 ) loss: 0.004483
(Iteration 821 ) loss: 0.001984
(Iteration 841 ) loss: 0.005091
(Iteration 861 ) loss: 0.002735
(Iteration 881 ) loss: 0.001866
(Iteration 901 ) loss: 0.001470
(Iteration 921 ) loss: 0.002214
(Iteration 941 ) loss: 0.000221
(Iteration 961 ) loss: 0.002206
(Iteration 981 ) loss: 0.004713
(Epoch 56 % 100) train loss: 0.0007630819432195816, eval loss: 0.0007805821238593182
(Iteration 1 ) loss: 0.004166
(Iteration 21 ) loss: 0.000563
(Iteration 41 ) loss: 0.000899
(Iteration 61 ) loss: 0.000486
(Iteration 81 ) loss: 0.000587
(Iteration 101 ) loss: 0.000283
(Iteration 121 ) loss: 0.001493
(Iteration 141 ) loss: 0.000260
(Iteration 161 ) loss: 0.001133
(Iteration 181 ) loss: 0.000821
(Iteration 201 ) loss: 0.000258
(Iteration 221 ) loss: 0.001357
(Iteration 241 ) loss: 0.001009
(Iteration 261 ) loss: 0.002859
(Iteration 281 ) loss: 0.001836
(Iteration 301 ) loss: 0.000870
(Iteration 321 ) loss: 0.000971
(Iteration 341 ) loss: 0.000690
(Iteration 361 ) loss: 0.002488
(Iteration 381 ) loss: 0.001178
(Iteration 401 ) loss: 0.001406
(Iteration 421 ) loss: 0.000251
(Iteration 441 ) loss: 0.000237
(Iteration 461 ) loss: 0.000259
(Iteration 481 ) loss: 0.000624
(Iteration 501 ) loss: 0.000978
(Iteration 521 ) loss: 0.003069
(Iteration 541 ) loss: 0.000816
(Iteration 561 ) loss: 0.003176
(Iteration 581 ) loss: 0.002218
(Iteration 601 ) loss: 0.000420
(Iteration 621 ) loss: 0.000528
(Iteration 641 ) loss: 0.001690
(Iteration 661 ) loss: 0.002481
(Iteration 681 ) loss: 0.001388
(Iteration 701 ) loss: 0.001041
(Iteration 721 ) loss: 0.001241
(Iteration 741 ) loss: 0.002731
(Iteration 761 ) loss: 0.000700
(Iteration 781 ) loss: 0.000224
(Iteration 801 ) loss: 0.000934
(Iteration 821 ) loss: 0.000830
(Iteration 841 ) loss: 0.002896
(Iteration 861 ) loss: 0.000015
(Iteration 881 ) loss: 0.008630
(Iteration 901 ) loss: 0.000957
(Iteration 921 ) loss: 0.007237
(Iteration 941 ) loss: 0.001299
(Iteration 961 ) loss: 0.004095
(Iteration 981 ) loss: 0.002357
(Epoch 57 % 100) train loss: 0.0006760774538603449, eval loss: 0.0006676932798331223
(Iteration 1 ) loss: 0.000455
(Iteration 21 ) loss: 0.000416
(Iteration 41 ) loss: 0.001138
(Iteration 61 ) loss: 0.000181
(Iteration 81 ) loss: 0.002680
(Iteration 101 ) loss: 0.008375
(Iteration 121 ) loss: 0.000108
(Iteration 141 ) loss: 0.001264
(Iteration 161 ) loss: 0.000222
(Iteration 181 ) loss: 0.000236
(Iteration 201 ) loss: 0.007445
(Iteration 221 ) loss: 0.000268
(Iteration 241 ) loss: 0.000328
(Iteration 261 ) loss: 0.000894
(Iteration 281 ) loss: 0.000727
(Iteration 301 ) loss: 0.000451
(Iteration 321 ) loss: 0.006095
(Iteration 341 ) loss: 0.001148
(Iteration 361 ) loss: 0.000633
(Iteration 381 ) loss: 0.001052
(Iteration 401 ) loss: 0.000490
(Iteration 421 ) loss: 0.003254
(Iteration 441 ) loss: 0.000357
(Iteration 461 ) loss: 0.001491
(Iteration 481 ) loss: 0.002299
(Iteration 501 ) loss: 0.001558
(Iteration 521 ) loss: 0.001738
(Iteration 541 ) loss: 0.001469
(Iteration 561 ) loss: 0.001115
(Iteration 581 ) loss: 0.000766
(Iteration 601 ) loss: 0.000717
(Iteration 621 ) loss: 0.002330
(Iteration 641 ) loss: 0.000235
(Iteration 661 ) loss: 0.000188
(Iteration 681 ) loss: 0.008107
(Iteration 701 ) loss: 0.001475
(Iteration 721 ) loss: 0.000802
(Iteration 741 ) loss: 0.000255
(Iteration 761 ) loss: 0.000820
(Iteration 781 ) loss: 0.001496
(Iteration 801 ) loss: 0.001994
(Iteration 821 ) loss: 0.002164
(Iteration 841 ) loss: 0.002362
(Iteration 861 ) loss: 0.001514
(Iteration 881 ) loss: 0.001131
(Iteration 901 ) loss: 0.000842
(Iteration 921 ) loss: 0.001148
(Iteration 941 ) loss: 0.001842
(Iteration 961 ) loss: 0.000405
(Iteration 981 ) loss: 0.000282
(Epoch 58 % 100) train loss: 0.0012848106857475776, eval loss: 0.0013171245344259157
(Iteration 1 ) loss: 0.000828
(Iteration 21 ) loss: 0.005530
(Iteration 41 ) loss: 0.001263
(Iteration 61 ) loss: 0.000303
(Iteration 81 ) loss: 0.001475
(Iteration 101 ) loss: 0.000560
(Iteration 121 ) loss: 0.001643
(Iteration 141 ) loss: 0.003186
(Iteration 161 ) loss: 0.002015
(Iteration 181 ) loss: 0.002026
(Iteration 201 ) loss: 0.001433
(Iteration 221 ) loss: 0.000821
(Iteration 241 ) loss: 0.001716
(Iteration 261 ) loss: 0.000497
(Iteration 281 ) loss: 0.000612
(Iteration 301 ) loss: 0.001041
(Iteration 321 ) loss: 0.000455
(Iteration 341 ) loss: 0.001094
(Iteration 361 ) loss: 0.001717
(Iteration 381 ) loss: 0.000338
(Iteration 401 ) loss: 0.000602
(Iteration 421 ) loss: 0.000816
(Iteration 441 ) loss: 0.000949
(Iteration 461 ) loss: 0.000320
(Iteration 481 ) loss: 0.000550
(Iteration 501 ) loss: 0.003316
(Iteration 521 ) loss: 0.001393
(Iteration 541 ) loss: 0.000814
(Iteration 561 ) loss: 0.000109
(Iteration 581 ) loss: 0.000504
(Iteration 601 ) loss: 0.001276
(Iteration 621 ) loss: 0.001680
(Iteration 641 ) loss: 0.003579
(Iteration 661 ) loss: 0.001989
(Iteration 681 ) loss: 0.000950
(Iteration 701 ) loss: 0.001722
(Iteration 721 ) loss: 0.000134
(Iteration 741 ) loss: 0.000236
(Iteration 761 ) loss: 0.001734
(Iteration 781 ) loss: 0.004810
(Iteration 801 ) loss: 0.001099
(Iteration 821 ) loss: 0.001171
(Iteration 841 ) loss: 0.001841
(Iteration 861 ) loss: 0.001153
(Iteration 881 ) loss: 0.000225
(Iteration 901 ) loss: 0.000497
(Iteration 921 ) loss: 0.001726
(Iteration 941 ) loss: 0.001637
(Iteration 961 ) loss: 0.001442
(Iteration 981 ) loss: 0.001648
(Epoch 59 % 100) train loss: 0.0009068789165767315, eval loss: 0.0009611191889180191
(Iteration 1 ) loss: 0.000213
(Iteration 21 ) loss: 0.000691
(Iteration 41 ) loss: 0.000259
(Iteration 61 ) loss: 0.001915
(Iteration 81 ) loss: 0.005376
(Iteration 101 ) loss: 0.000126
(Iteration 121 ) loss: 0.000261
(Iteration 141 ) loss: 0.004891
(Iteration 161 ) loss: 0.000405
(Iteration 181 ) loss: 0.000759
(Iteration 201 ) loss: 0.000563
(Iteration 221 ) loss: 0.003290
(Iteration 241 ) loss: 0.002798
(Iteration 261 ) loss: 0.001489
(Iteration 281 ) loss: 0.001509
(Iteration 301 ) loss: 0.000218
(Iteration 321 ) loss: 0.001115
(Iteration 341 ) loss: 0.000510
(Iteration 361 ) loss: 0.000931
(Iteration 381 ) loss: 0.000962
(Iteration 401 ) loss: 0.000727
(Iteration 421 ) loss: 0.001531
(Iteration 441 ) loss: 0.001352
(Iteration 461 ) loss: 0.002363
(Iteration 481 ) loss: 0.000840
(Iteration 501 ) loss: 0.000966
(Iteration 521 ) loss: 0.000295
(Iteration 541 ) loss: 0.000614
(Iteration 561 ) loss: 0.001053
(Iteration 581 ) loss: 0.000438
(Iteration 601 ) loss: 0.000454
(Iteration 621 ) loss: 0.002491
(Iteration 641 ) loss: 0.000685
(Iteration 661 ) loss: 0.000798
(Iteration 681 ) loss: 0.000936
(Iteration 701 ) loss: 0.001553
(Iteration 721 ) loss: 0.001371
(Iteration 741 ) loss: 0.000569
(Iteration 761 ) loss: 0.005373
(Iteration 781 ) loss: 0.003033
(Iteration 801 ) loss: 0.001541
(Iteration 821 ) loss: 0.000780
(Iteration 841 ) loss: 0.000944
(Iteration 861 ) loss: 0.000604
(Iteration 881 ) loss: 0.000805
(Iteration 901 ) loss: 0.000930
(Iteration 921 ) loss: 0.000878
(Iteration 941 ) loss: 0.000978
(Iteration 961 ) loss: 0.003048
(Iteration 981 ) loss: 0.000944
(Epoch 60 % 100) train loss: 0.0015401964383412391, eval loss: 0.0015713928438530042
(Iteration 1 ) loss: 0.001230
(Iteration 21 ) loss: 0.002524
(Iteration 41 ) loss: 0.003421
(Iteration 61 ) loss: 0.000661
(Iteration 81 ) loss: 0.000608
(Iteration 101 ) loss: 0.000238
(Iteration 121 ) loss: 0.000913
(Iteration 141 ) loss: 0.000937
(Iteration 161 ) loss: 0.001877
(Iteration 181 ) loss: 0.001650
(Iteration 201 ) loss: 0.000432
(Iteration 221 ) loss: 0.001825
(Iteration 241 ) loss: 0.000889
(Iteration 261 ) loss: 0.002063
(Iteration 281 ) loss: 0.001456
(Iteration 301 ) loss: 0.000214
(Iteration 321 ) loss: 0.001603
(Iteration 341 ) loss: 0.001724
(Iteration 361 ) loss: 0.000182
(Iteration 381 ) loss: 0.000724
(Iteration 401 ) loss: 0.000425
(Iteration 421 ) loss: 0.000965
(Iteration 441 ) loss: 0.000852
(Iteration 461 ) loss: 0.005973
(Iteration 481 ) loss: 0.001823
(Iteration 501 ) loss: 0.000602
(Iteration 521 ) loss: 0.001656
(Iteration 541 ) loss: 0.000473
(Iteration 561 ) loss: 0.002674
(Iteration 581 ) loss: 0.001212
(Iteration 601 ) loss: 0.000045
(Iteration 621 ) loss: 0.003444
(Iteration 641 ) loss: 0.001302
(Iteration 661 ) loss: 0.000542
(Iteration 681 ) loss: 0.001239
(Iteration 701 ) loss: 0.000762
(Iteration 721 ) loss: 0.000434
(Iteration 741 ) loss: 0.002299
(Iteration 761 ) loss: 0.000430
(Iteration 781 ) loss: 0.000188
(Iteration 801 ) loss: 0.000150
(Iteration 821 ) loss: 0.001773
(Iteration 841 ) loss: 0.003883
(Iteration 861 ) loss: 0.002700
(Iteration 881 ) loss: 0.003823
(Iteration 901 ) loss: 0.000738
(Iteration 921 ) loss: 0.000842
(Iteration 941 ) loss: 0.002052
(Iteration 961 ) loss: 0.001931
(Iteration 981 ) loss: 0.001079
(Epoch 61 % 100) train loss: 0.0013104682355850757, eval loss: 0.0013444346868581552
(Iteration 1 ) loss: 0.000872
(Iteration 21 ) loss: 0.000262
(Iteration 41 ) loss: 0.001482
(Iteration 61 ) loss: 0.001422
(Iteration 81 ) loss: 0.001572
(Iteration 101 ) loss: 0.000994
(Iteration 121 ) loss: 0.002302
(Iteration 141 ) loss: 0.000771
(Iteration 161 ) loss: 0.002227
(Iteration 181 ) loss: 0.000406
(Iteration 201 ) loss: 0.001069
(Iteration 221 ) loss: 0.000766
(Iteration 241 ) loss: 0.001898
(Iteration 261 ) loss: 0.000392
(Iteration 281 ) loss: 0.000478
(Iteration 301 ) loss: 0.000884
(Iteration 321 ) loss: 0.000188
(Iteration 341 ) loss: 0.000630
(Iteration 361 ) loss: 0.000491
(Iteration 381 ) loss: 0.001166
(Iteration 401 ) loss: 0.000550
(Iteration 421 ) loss: 0.000394
(Iteration 441 ) loss: 0.001480
(Iteration 461 ) loss: 0.000891
(Iteration 481 ) loss: 0.000451
(Iteration 501 ) loss: 0.000530
(Iteration 521 ) loss: 0.000527
(Iteration 541 ) loss: 0.001649
(Iteration 561 ) loss: 0.000544
(Iteration 581 ) loss: 0.000397
(Iteration 601 ) loss: 0.002052
(Iteration 621 ) loss: 0.000627
(Iteration 641 ) loss: 0.001188
(Iteration 661 ) loss: 0.004269
(Iteration 681 ) loss: 0.000702
(Iteration 701 ) loss: 0.000648
(Iteration 721 ) loss: 0.000498
(Iteration 741 ) loss: 0.000256
(Iteration 761 ) loss: 0.000892
(Iteration 781 ) loss: 0.000211
(Iteration 801 ) loss: 0.000322
(Iteration 821 ) loss: 0.000710
(Iteration 841 ) loss: 0.002764
(Iteration 861 ) loss: 0.002458
(Iteration 881 ) loss: 0.004372
(Iteration 901 ) loss: 0.002640
(Iteration 921 ) loss: 0.000619
(Iteration 941 ) loss: 0.001585
(Iteration 961 ) loss: 0.002795
(Iteration 981 ) loss: 0.000890
(Epoch 62 % 100) train loss: 0.0010384419291026097, eval loss: 0.001143649740306977
(Iteration 1 ) loss: 0.001084
(Iteration 21 ) loss: 0.005100
(Iteration 41 ) loss: 0.001138
(Iteration 61 ) loss: 0.000585
(Iteration 81 ) loss: 0.000756
(Iteration 101 ) loss: 0.000423
(Iteration 121 ) loss: 0.001158
(Iteration 141 ) loss: 0.000236
(Iteration 161 ) loss: 0.002763
(Iteration 181 ) loss: 0.000846
(Iteration 201 ) loss: 0.000840
(Iteration 221 ) loss: 0.000701
(Iteration 241 ) loss: 0.000735
(Iteration 261 ) loss: 0.001008
(Iteration 281 ) loss: 0.000774
(Iteration 301 ) loss: 0.000484
(Iteration 321 ) loss: 0.001414
(Iteration 341 ) loss: 0.000453
(Iteration 361 ) loss: 0.002538
(Iteration 381 ) loss: 0.001567
(Iteration 401 ) loss: 0.000255
(Iteration 421 ) loss: 0.003465
(Iteration 441 ) loss: 0.000123
(Iteration 461 ) loss: 0.001671
(Iteration 481 ) loss: 0.000892
(Iteration 501 ) loss: 0.000817
(Iteration 521 ) loss: 0.000691
(Iteration 541 ) loss: 0.001089
(Iteration 561 ) loss: 0.002674
(Iteration 581 ) loss: 0.001679
(Iteration 601 ) loss: 0.000897
(Iteration 621 ) loss: 0.001703
(Iteration 641 ) loss: 0.001388
(Iteration 661 ) loss: 0.000957
(Iteration 681 ) loss: 0.001636
(Iteration 701 ) loss: 0.000338
(Iteration 721 ) loss: 0.000499
(Iteration 741 ) loss: 0.000212
(Iteration 761 ) loss: 0.004170
(Iteration 781 ) loss: 0.001424
(Iteration 801 ) loss: 0.003656
(Iteration 821 ) loss: 0.000829
(Iteration 841 ) loss: 0.000512
(Iteration 861 ) loss: 0.001161
(Iteration 881 ) loss: 0.003047
(Iteration 901 ) loss: 0.000577
(Iteration 921 ) loss: 0.006037
(Iteration 941 ) loss: 0.005848
(Iteration 961 ) loss: 0.003493
(Iteration 981 ) loss: 0.001394
(Epoch 63 % 100) train loss: 0.0010850486171807728, eval loss: 0.001073767316604145
(Iteration 1 ) loss: 0.000830
(Iteration 21 ) loss: 0.000567
(Iteration 41 ) loss: 0.000111
(Iteration 61 ) loss: 0.000675
(Iteration 81 ) loss: 0.000767
(Iteration 101 ) loss: 0.000503
(Iteration 121 ) loss: 0.002998
(Iteration 141 ) loss: 0.004456
(Iteration 161 ) loss: 0.001245
(Iteration 181 ) loss: 0.000809
(Iteration 201 ) loss: 0.000504
(Iteration 221 ) loss: 0.001741
(Iteration 241 ) loss: 0.000618
(Iteration 261 ) loss: 0.000430
(Iteration 281 ) loss: 0.001884
(Iteration 301 ) loss: 0.000497
(Iteration 321 ) loss: 0.000102
(Iteration 341 ) loss: 0.001267
(Iteration 361 ) loss: 0.000360
(Iteration 381 ) loss: 0.000662
(Iteration 401 ) loss: 0.001327
(Iteration 421 ) loss: 0.000290
(Iteration 441 ) loss: 0.001396
(Iteration 461 ) loss: 0.001667
(Iteration 481 ) loss: 0.000527
(Iteration 501 ) loss: 0.000847
(Iteration 521 ) loss: 0.002053
(Iteration 541 ) loss: 0.003636
(Iteration 561 ) loss: 0.000779
(Iteration 581 ) loss: 0.000631
(Iteration 601 ) loss: 0.000890
(Iteration 621 ) loss: 0.001070
(Iteration 641 ) loss: 0.002161
(Iteration 661 ) loss: 0.000733
(Iteration 681 ) loss: 0.000839
(Iteration 701 ) loss: 0.000432
(Iteration 721 ) loss: 0.000329
(Iteration 741 ) loss: 0.001087
(Iteration 761 ) loss: 0.001244
(Iteration 781 ) loss: 0.000620
(Iteration 801 ) loss: 0.001003
(Iteration 821 ) loss: 0.001927
(Iteration 841 ) loss: 0.001617
(Iteration 861 ) loss: 0.000705
(Iteration 881 ) loss: 0.000684
(Iteration 901 ) loss: 0.000874
(Iteration 921 ) loss: 0.001264
(Iteration 941 ) loss: 0.001883
(Iteration 961 ) loss: 0.000527
(Iteration 981 ) loss: 0.000458
(Epoch 64 % 100) train loss: 0.0008178406235626421, eval loss: 0.0008932149638694497
(Iteration 1 ) loss: 0.001197
(Iteration 21 ) loss: 0.000361
(Iteration 41 ) loss: 0.001285
(Iteration 61 ) loss: 0.000481
(Iteration 81 ) loss: 0.002062
(Iteration 101 ) loss: 0.000916
(Iteration 121 ) loss: 0.000828
(Iteration 141 ) loss: 0.001324
(Iteration 161 ) loss: 0.000965
(Iteration 181 ) loss: 0.002744
(Iteration 201 ) loss: 0.000927
(Iteration 221 ) loss: 0.000368
(Iteration 241 ) loss: 0.000586
(Iteration 261 ) loss: 0.000655
(Iteration 281 ) loss: 0.000536
(Iteration 301 ) loss: 0.001961
(Iteration 321 ) loss: 0.000664
(Iteration 341 ) loss: 0.001203
(Iteration 361 ) loss: 0.002300
(Iteration 381 ) loss: 0.000921
(Iteration 401 ) loss: 0.000730
(Iteration 421 ) loss: 0.002463
(Iteration 441 ) loss: 0.000358
(Iteration 461 ) loss: 0.001103
(Iteration 481 ) loss: 0.000745
(Iteration 501 ) loss: 0.000374
(Iteration 521 ) loss: 0.000293
(Iteration 541 ) loss: 0.000428
(Iteration 561 ) loss: 0.000796
(Iteration 581 ) loss: 0.000840
(Iteration 601 ) loss: 0.000169
(Iteration 621 ) loss: 0.000497
(Iteration 641 ) loss: 0.000256
(Iteration 661 ) loss: 0.000692
(Iteration 681 ) loss: 0.000812
(Iteration 701 ) loss: 0.000548
(Iteration 721 ) loss: 0.000572
(Iteration 741 ) loss: 0.000814
(Iteration 761 ) loss: 0.001506
(Iteration 781 ) loss: 0.000986
(Iteration 801 ) loss: 0.000452
(Iteration 821 ) loss: 0.000540
(Iteration 841 ) loss: 0.000185
(Iteration 861 ) loss: 0.001623
(Iteration 881 ) loss: 0.004135
(Iteration 901 ) loss: 0.000691
(Iteration 921 ) loss: 0.001558
(Iteration 941 ) loss: 0.001044
(Iteration 961 ) loss: 0.004420
(Iteration 981 ) loss: 0.001511
(Epoch 65 % 100) train loss: 0.001229673963138562, eval loss: 0.0011854766047692767
(Iteration 1 ) loss: 0.000266
(Iteration 21 ) loss: 0.000075
(Iteration 41 ) loss: 0.002207
(Iteration 61 ) loss: 0.000825
(Iteration 81 ) loss: 0.002278
(Iteration 101 ) loss: 0.000546
(Iteration 121 ) loss: 0.000578
(Iteration 141 ) loss: 0.001267
(Iteration 161 ) loss: 0.001121
(Iteration 181 ) loss: 0.001626
(Iteration 201 ) loss: 0.000092
(Iteration 221 ) loss: 0.000462
(Iteration 241 ) loss: 0.000153
(Iteration 261 ) loss: 0.000714
(Iteration 281 ) loss: 0.001931
(Iteration 301 ) loss: 0.000557
(Iteration 321 ) loss: 0.001015
(Iteration 341 ) loss: 0.003984
(Iteration 361 ) loss: 0.001557
(Iteration 381 ) loss: 0.008202
(Iteration 401 ) loss: 0.002460
(Iteration 421 ) loss: 0.002270
(Iteration 441 ) loss: 0.004969
(Iteration 461 ) loss: 0.000858
(Iteration 481 ) loss: 0.000300
(Iteration 501 ) loss: 0.000669
(Iteration 521 ) loss: 0.000687
(Iteration 541 ) loss: 0.000784
(Iteration 561 ) loss: 0.001258
(Iteration 581 ) loss: 0.001710
(Iteration 601 ) loss: 0.000119
(Iteration 621 ) loss: 0.000362
(Iteration 641 ) loss: 0.000885
(Iteration 661 ) loss: 0.000547
(Iteration 681 ) loss: 0.000418
(Iteration 701 ) loss: 0.001747
(Iteration 721 ) loss: 0.003939
(Iteration 741 ) loss: 0.002357
(Iteration 761 ) loss: 0.000556
(Iteration 781 ) loss: 0.004231
(Iteration 801 ) loss: 0.005623
(Iteration 821 ) loss: 0.007260
(Iteration 841 ) loss: 0.000604
(Iteration 861 ) loss: 0.001335
(Iteration 881 ) loss: 0.000206
(Iteration 901 ) loss: 0.002041
(Iteration 921 ) loss: 0.000160
(Iteration 941 ) loss: 0.000839
(Iteration 961 ) loss: 0.000866
(Iteration 981 ) loss: 0.001037
(Epoch 66 % 100) train loss: 0.005409725943538243, eval loss: 0.005769600060645062
(Iteration 1 ) loss: 0.004110
(Iteration 21 ) loss: 0.001317
(Iteration 41 ) loss: 0.000678
(Iteration 61 ) loss: 0.000860
(Iteration 81 ) loss: 0.000839
(Iteration 101 ) loss: 0.002291
(Iteration 121 ) loss: 0.003369
(Iteration 141 ) loss: 0.001705
(Iteration 161 ) loss: 0.000896
(Iteration 181 ) loss: 0.001648
(Iteration 201 ) loss: 0.003495
(Iteration 221 ) loss: 0.002548
(Iteration 241 ) loss: 0.000422
(Iteration 261 ) loss: 0.000337
(Iteration 281 ) loss: 0.001946
(Iteration 301 ) loss: 0.000653
(Iteration 321 ) loss: 0.000052
(Iteration 341 ) loss: 0.000958
(Iteration 361 ) loss: 0.000402
(Iteration 381 ) loss: 0.000312
(Iteration 401 ) loss: 0.000393
(Iteration 421 ) loss: 0.000148
(Iteration 441 ) loss: 0.000532
(Iteration 461 ) loss: 0.000852
(Iteration 481 ) loss: 0.000540
(Iteration 501 ) loss: 0.001665
(Iteration 521 ) loss: 0.000242
(Iteration 541 ) loss: 0.002117
(Iteration 561 ) loss: 0.001406
(Iteration 581 ) loss: 0.000190
(Iteration 601 ) loss: 0.000407
(Iteration 621 ) loss: 0.000660
(Iteration 641 ) loss: 0.000476
(Iteration 661 ) loss: 0.001542
(Iteration 681 ) loss: 0.001083
(Iteration 701 ) loss: 0.001707
(Iteration 721 ) loss: 0.000449
(Iteration 741 ) loss: 0.000560
(Iteration 761 ) loss: 0.001856
(Iteration 781 ) loss: 0.004658
(Iteration 801 ) loss: 0.000236
(Iteration 821 ) loss: 0.002292
(Iteration 841 ) loss: 0.002426
(Iteration 861 ) loss: 0.002018
(Iteration 881 ) loss: 0.000049
(Iteration 901 ) loss: 0.001403
(Iteration 921 ) loss: 0.000604
(Iteration 941 ) loss: 0.000687
(Iteration 961 ) loss: 0.000787
(Iteration 981 ) loss: 0.001599
(Epoch 67 % 100) train loss: 0.002547470265931857, eval loss: 0.0025189965605269577
(Iteration 1 ) loss: 0.001369
(Iteration 21 ) loss: 0.000483
(Iteration 41 ) loss: 0.000523
(Iteration 61 ) loss: 0.000192
(Iteration 81 ) loss: 0.000625
(Iteration 101 ) loss: 0.001866
(Iteration 121 ) loss: 0.000580
(Iteration 141 ) loss: 0.000343
(Iteration 161 ) loss: 0.000658
(Iteration 181 ) loss: 0.000371
(Iteration 201 ) loss: 0.000534
(Iteration 221 ) loss: 0.000364
(Iteration 241 ) loss: 0.001173
(Iteration 261 ) loss: 0.001748
(Iteration 281 ) loss: 0.000441
(Iteration 301 ) loss: 0.000474
(Iteration 321 ) loss: 0.001855
(Iteration 341 ) loss: 0.001655
(Iteration 361 ) loss: 0.001373
(Iteration 381 ) loss: 0.000210
(Iteration 401 ) loss: 0.000593
(Iteration 421 ) loss: 0.001069
(Iteration 441 ) loss: 0.000659
(Iteration 461 ) loss: 0.000254
(Iteration 481 ) loss: 0.000719
(Iteration 501 ) loss: 0.001917
(Iteration 521 ) loss: 0.000509
(Iteration 541 ) loss: 0.002190
(Iteration 561 ) loss: 0.001454
(Iteration 581 ) loss: 0.000735
(Iteration 601 ) loss: 0.000620
(Iteration 621 ) loss: 0.000773
(Iteration 641 ) loss: 0.000278
(Iteration 661 ) loss: 0.000608
(Iteration 681 ) loss: 0.001708
(Iteration 701 ) loss: 0.001940
(Iteration 721 ) loss: 0.000554
(Iteration 741 ) loss: 0.001252
(Iteration 761 ) loss: 0.000295
(Iteration 781 ) loss: 0.000502
(Iteration 801 ) loss: 0.000541
(Iteration 821 ) loss: 0.000147
(Iteration 841 ) loss: 0.004837
(Iteration 861 ) loss: 0.001507
(Iteration 881 ) loss: 0.000597
(Iteration 901 ) loss: 0.002377
(Iteration 921 ) loss: 0.000142
(Iteration 941 ) loss: 0.000654
(Iteration 961 ) loss: 0.002788
(Iteration 981 ) loss: 0.002434
(Epoch 68 % 100) train loss: 0.0031086756972050103, eval loss: 0.00303741251374153
(Iteration 1 ) loss: 0.001456
(Iteration 21 ) loss: 0.003820
(Iteration 41 ) loss: 0.007290
(Iteration 61 ) loss: 0.009225
(Iteration 81 ) loss: 0.001026
(Iteration 101 ) loss: 0.001469
(Iteration 121 ) loss: 0.000844
(Iteration 141 ) loss: 0.000346
(Iteration 161 ) loss: 0.000212
(Iteration 181 ) loss: 0.000800
(Iteration 201 ) loss: 0.001507
(Iteration 221 ) loss: 0.001540
(Iteration 241 ) loss: 0.002611
(Iteration 261 ) loss: 0.000340
(Iteration 281 ) loss: 0.000377
(Iteration 301 ) loss: 0.000552
(Iteration 321 ) loss: 0.001971
(Iteration 341 ) loss: 0.001768
(Iteration 361 ) loss: 0.001297
(Iteration 381 ) loss: 0.001282
(Iteration 401 ) loss: 0.005155
(Iteration 421 ) loss: 0.000203
(Iteration 441 ) loss: 0.000162
(Iteration 461 ) loss: 0.000759
(Iteration 481 ) loss: 0.001230
(Iteration 501 ) loss: 0.001178
(Iteration 521 ) loss: 0.001205
(Iteration 541 ) loss: 0.000078
(Iteration 561 ) loss: 0.000244
(Iteration 581 ) loss: 0.001013
(Iteration 601 ) loss: 0.000370
(Iteration 621 ) loss: 0.000787
(Iteration 641 ) loss: 0.000257
(Iteration 661 ) loss: 0.000679
(Iteration 681 ) loss: 0.000539
(Iteration 701 ) loss: 0.000088
(Iteration 721 ) loss: 0.000515
(Iteration 741 ) loss: 0.000624
(Iteration 761 ) loss: 0.000212
(Iteration 781 ) loss: 0.000408
(Iteration 801 ) loss: 0.000470
(Iteration 821 ) loss: 0.000270
(Iteration 841 ) loss: 0.001421
(Iteration 861 ) loss: 0.000746
(Iteration 881 ) loss: 0.000583
(Iteration 901 ) loss: 0.000337
(Iteration 921 ) loss: 0.000815
(Iteration 941 ) loss: 0.000292
(Iteration 961 ) loss: 0.002781
(Iteration 981 ) loss: 0.000389
(Epoch 69 % 100) train loss: 0.0006812943778027713, eval loss: 0.0007140863349282397
(Iteration 1 ) loss: 0.000536
(Iteration 21 ) loss: 0.002621
(Iteration 41 ) loss: 0.000596
(Iteration 61 ) loss: 0.005587
(Iteration 81 ) loss: 0.000544
(Iteration 101 ) loss: 0.002780
(Iteration 121 ) loss: 0.001022
(Iteration 141 ) loss: 0.001292
(Iteration 161 ) loss: 0.000068
(Iteration 181 ) loss: 0.000826
(Iteration 201 ) loss: 0.000810
(Iteration 221 ) loss: 0.000146
(Iteration 241 ) loss: 0.001740
(Iteration 261 ) loss: 0.000183
(Iteration 281 ) loss: 0.001324
(Iteration 301 ) loss: 0.000170
(Iteration 321 ) loss: 0.001544
(Iteration 341 ) loss: 0.003047
(Iteration 361 ) loss: 0.001686
(Iteration 381 ) loss: 0.001649
(Iteration 401 ) loss: 0.000405
(Iteration 421 ) loss: 0.000861
(Iteration 441 ) loss: 0.000269
(Iteration 461 ) loss: 0.000201
(Iteration 481 ) loss: 0.000360
(Iteration 501 ) loss: 0.001066
(Iteration 521 ) loss: 0.001025
(Iteration 541 ) loss: 0.000274
(Iteration 561 ) loss: 0.001256
(Iteration 581 ) loss: 0.001599
(Iteration 601 ) loss: 0.000475
(Iteration 621 ) loss: 0.001728
(Iteration 641 ) loss: 0.000330
(Iteration 661 ) loss: 0.000165
(Iteration 681 ) loss: 0.001278
(Iteration 701 ) loss: 0.000515
(Iteration 721 ) loss: 0.000365
(Iteration 741 ) loss: 0.001169
(Iteration 761 ) loss: 0.003525
(Iteration 781 ) loss: 0.000704
(Iteration 801 ) loss: 0.001763
(Iteration 821 ) loss: 0.000466
(Iteration 841 ) loss: 0.000720
(Iteration 861 ) loss: 0.001145
(Iteration 881 ) loss: 0.000740
(Iteration 901 ) loss: 0.001728
(Iteration 921 ) loss: 0.001010
(Iteration 941 ) loss: 0.000534
(Iteration 961 ) loss: 0.003757
(Iteration 981 ) loss: 0.000994
(Epoch 70 % 100) train loss: 0.0032472794989372973, eval loss: 0.0028862957915911174
(Iteration 1 ) loss: 0.002062
(Iteration 21 ) loss: 0.000758
(Iteration 41 ) loss: 0.001247
(Iteration 61 ) loss: 0.000807
(Iteration 81 ) loss: 0.000726
(Iteration 101 ) loss: 0.001121
(Iteration 121 ) loss: 0.001352
(Iteration 141 ) loss: 0.000385
(Iteration 161 ) loss: 0.001130
(Iteration 181 ) loss: 0.001154
(Iteration 201 ) loss: 0.000081
(Iteration 221 ) loss: 0.001571
(Iteration 241 ) loss: 0.000407
(Iteration 261 ) loss: 0.002807
(Iteration 281 ) loss: 0.001942
(Iteration 301 ) loss: 0.000196
(Iteration 321 ) loss: 0.000727
(Iteration 341 ) loss: 0.000352
(Iteration 361 ) loss: 0.000307
(Iteration 381 ) loss: 0.001428
(Iteration 401 ) loss: 0.000949
(Iteration 421 ) loss: 0.000096
(Iteration 441 ) loss: 0.000879
(Iteration 461 ) loss: 0.001025
(Iteration 481 ) loss: 0.000300
(Iteration 501 ) loss: 0.001055
(Iteration 521 ) loss: 0.001317
(Iteration 541 ) loss: 0.003261
(Iteration 561 ) loss: 0.002375
(Iteration 581 ) loss: 0.001644
(Iteration 601 ) loss: 0.000927
(Iteration 621 ) loss: 0.001036
(Iteration 641 ) loss: 0.000664
(Iteration 661 ) loss: 0.000500
(Iteration 681 ) loss: 0.000412
(Iteration 701 ) loss: 0.001491
(Iteration 721 ) loss: 0.001027
(Iteration 741 ) loss: 0.000334
(Iteration 761 ) loss: 0.000850
(Iteration 781 ) loss: 0.002093
(Iteration 801 ) loss: 0.000833
(Iteration 821 ) loss: 0.001545
(Iteration 841 ) loss: 0.000121
(Iteration 861 ) loss: 0.001187
(Iteration 881 ) loss: 0.000976
(Iteration 901 ) loss: 0.001115
(Iteration 921 ) loss: 0.001007
(Iteration 941 ) loss: 0.000042
(Iteration 961 ) loss: 0.003354
(Iteration 981 ) loss: 0.002370
(Epoch 71 % 100) train loss: 0.001239973420087071, eval loss: 0.0011361094121953752
(Iteration 1 ) loss: 0.001465
(Iteration 21 ) loss: 0.001254
(Iteration 41 ) loss: 0.001263
(Iteration 61 ) loss: 0.006561
(Iteration 81 ) loss: 0.000540
(Iteration 101 ) loss: 0.000531
(Iteration 121 ) loss: 0.000447
(Iteration 141 ) loss: 0.001087
(Iteration 161 ) loss: 0.000893
(Iteration 181 ) loss: 0.000803
(Iteration 201 ) loss: 0.001598
(Iteration 221 ) loss: 0.001484
(Iteration 241 ) loss: 0.000875
(Iteration 261 ) loss: 0.000369
(Iteration 281 ) loss: 0.000156
(Iteration 301 ) loss: 0.000411
(Iteration 321 ) loss: 0.000737
(Iteration 341 ) loss: 0.000320
(Iteration 361 ) loss: 0.000350
(Iteration 381 ) loss: 0.000365
(Iteration 401 ) loss: 0.000338
(Iteration 421 ) loss: 0.000423
(Iteration 441 ) loss: 0.000413
(Iteration 461 ) loss: 0.000319
(Iteration 481 ) loss: 0.001281
(Iteration 501 ) loss: 0.000404
(Iteration 521 ) loss: 0.000053
(Iteration 541 ) loss: 0.000831
(Iteration 561 ) loss: 0.001688
(Iteration 581 ) loss: 0.001933
(Iteration 601 ) loss: 0.001429
(Iteration 621 ) loss: 0.001239
(Iteration 641 ) loss: 0.001147
(Iteration 661 ) loss: 0.000525
(Iteration 681 ) loss: 0.003053
(Iteration 701 ) loss: 0.000352
(Iteration 721 ) loss: 0.000252
(Iteration 741 ) loss: 0.000198
(Iteration 761 ) loss: 0.004924
(Iteration 781 ) loss: 0.001742
(Iteration 801 ) loss: 0.000400
(Iteration 821 ) loss: 0.000229
(Iteration 841 ) loss: 0.000745
(Iteration 861 ) loss: 0.002020
(Iteration 881 ) loss: 0.001273
(Iteration 901 ) loss: 0.000691
(Iteration 921 ) loss: 0.000033
(Iteration 941 ) loss: 0.001959
(Iteration 961 ) loss: 0.003356
(Iteration 981 ) loss: 0.000373
(Epoch 72 % 100) train loss: 0.0013643228268916828, eval loss: 0.001341938744976979
(Iteration 1 ) loss: 0.001001
(Iteration 21 ) loss: 0.001118
(Iteration 41 ) loss: 0.000612
(Iteration 61 ) loss: 0.001052
(Iteration 81 ) loss: 0.000210
(Iteration 101 ) loss: 0.000230
(Iteration 121 ) loss: 0.002080
(Iteration 141 ) loss: 0.000437
(Iteration 161 ) loss: 0.004683
(Iteration 181 ) loss: 0.000695
(Iteration 201 ) loss: 0.000134
(Iteration 221 ) loss: 0.000238
(Iteration 241 ) loss: 0.000609
(Iteration 261 ) loss: 0.000435
(Iteration 281 ) loss: 0.000488
(Iteration 301 ) loss: 0.003372
(Iteration 321 ) loss: 0.000372
(Iteration 341 ) loss: 0.000156
(Iteration 361 ) loss: 0.001438
(Iteration 381 ) loss: 0.000599
(Iteration 401 ) loss: 0.000409
(Iteration 421 ) loss: 0.000502
(Iteration 441 ) loss: 0.000181
(Iteration 461 ) loss: 0.005520
(Iteration 481 ) loss: 0.000326
(Iteration 501 ) loss: 0.000375
(Iteration 521 ) loss: 0.000252
(Iteration 541 ) loss: 0.000248
(Iteration 561 ) loss: 0.000495
(Iteration 581 ) loss: 0.001222
(Iteration 601 ) loss: 0.001209
(Iteration 621 ) loss: 0.001233
(Iteration 641 ) loss: 0.000747
(Iteration 661 ) loss: 0.000146
(Iteration 681 ) loss: 0.000206
(Iteration 721 ) loss: 0.001306
(Iteration 741 ) loss: 0.001740
(Iteration 761 ) loss: 0.000400
(Iteration 781 ) loss: 0.001268
(Iteration 801 ) loss: 0.001127
(Iteration 821 ) loss: 0.000527
(Iteration 841 ) loss: 0.000437
(Iteration 861 ) loss: 0.000093
(Iteration 881 ) loss: 0.000411
(Iteration 901 ) loss: 0.000475
(Iteration 921 ) loss: 0.001104
(Iteration 941 ) loss: 0.000125
(Iteration 961 ) loss: 0.000182
(Iteration 981 ) loss: 0.000592
(Epoch 73 % 100) train loss: 0.0006801452435813438, eval loss: 0.0006481468940214466
(Iteration 1 ) loss: 0.000560
(Iteration 21 ) loss: 0.000312
(Iteration 41 ) loss: 0.001312
(Iteration 61 ) loss: 0.001491
(Iteration 81 ) loss: 0.001920
(Iteration 101 ) loss: 0.000442
(Iteration 121 ) loss: 0.001763
(Iteration 141 ) loss: 0.002303
(Iteration 161 ) loss: 0.001142
(Iteration 181 ) loss: 0.000083
(Iteration 201 ) loss: 0.001612
(Iteration 221 ) loss: 0.000474
(Iteration 241 ) loss: 0.000596
(Iteration 261 ) loss: 0.000981
(Iteration 281 ) loss: 0.000582
(Iteration 301 ) loss: 0.000214
(Iteration 321 ) loss: 0.000574
(Iteration 341 ) loss: 0.002288
(Iteration 361 ) loss: 0.001289
(Iteration 381 ) loss: 0.000968
(Iteration 401 ) loss: 0.000275
(Iteration 421 ) loss: 0.001559
(Iteration 441 ) loss: 0.001481
(Iteration 461 ) loss: 0.000298
(Iteration 481 ) loss: 0.001031
(Iteration 501 ) loss: 0.000957
(Iteration 521 ) loss: 0.001474
(Iteration 541 ) loss: 0.005636
(Iteration 561 ) loss: 0.001504
(Iteration 581 ) loss: 0.000630
(Iteration 601 ) loss: 0.000726
(Iteration 621 ) loss: 0.000575
(Iteration 641 ) loss: 0.001117
(Iteration 661 ) loss: 0.003498
(Iteration 681 ) loss: 0.000488
(Iteration 701 ) loss: 0.000290
(Iteration 721 ) loss: 0.000830
(Iteration 741 ) loss: 0.000238
(Iteration 761 ) loss: 0.001439
(Iteration 781 ) loss: 0.002679
(Iteration 801 ) loss: 0.000727
(Iteration 821 ) loss: 0.000476
(Iteration 841 ) loss: 0.001989
(Iteration 861 ) loss: 0.000241
(Iteration 881 ) loss: 0.001122
(Iteration 901 ) loss: 0.000272
(Iteration 921 ) loss: 0.000541
(Iteration 941 ) loss: 0.000552
(Iteration 961 ) loss: 0.001374
(Iteration 981 ) loss: 0.000173
(Epoch 74 % 100) train loss: 0.0007889338058721339, eval loss: 0.0009319393318779867
(Iteration 1 ) loss: 0.000765
(Iteration 21 ) loss: 0.000627
(Iteration 41 ) loss: 0.000497
(Iteration 61 ) loss: 0.001594
(Iteration 81 ) loss: 0.000113
(Iteration 101 ) loss: 0.000426
(Iteration 121 ) loss: 0.000616
(Iteration 141 ) loss: 0.000314
(Iteration 161 ) loss: 0.001551
(Iteration 181 ) loss: 0.003641
(Iteration 201 ) loss: 0.001111
(Iteration 221 ) loss: 0.000395
(Iteration 241 ) loss: 0.000341
(Iteration 261 ) loss: 0.001266
(Iteration 281 ) loss: 0.000172
(Iteration 301 ) loss: 0.001502
(Iteration 321 ) loss: 0.001362
(Iteration 341 ) loss: 0.000085
(Iteration 361 ) loss: 0.000245
(Iteration 381 ) loss: 0.000188
(Iteration 401 ) loss: 0.001207
(Iteration 421 ) loss: 0.000587
(Iteration 441 ) loss: 0.005729
(Iteration 461 ) loss: 0.001260
(Iteration 481 ) loss: 0.002627
(Iteration 501 ) loss: 0.004692
(Iteration 521 ) loss: 0.000537
(Iteration 541 ) loss: 0.000131
(Iteration 561 ) loss: 0.001050
(Iteration 581 ) loss: 0.001106
(Iteration 601 ) loss: 0.000677
(Iteration 621 ) loss: 0.001003
(Iteration 641 ) loss: 0.000015
(Iteration 661 ) loss: 0.001434
(Iteration 681 ) loss: 0.001214
(Iteration 701 ) loss: 0.000174
(Iteration 721 ) loss: 0.000652
(Iteration 741 ) loss: 0.000121
(Iteration 761 ) loss: 0.000390
(Iteration 781 ) loss: 0.001069
(Iteration 801 ) loss: 0.000290
(Iteration 821 ) loss: 0.001370
(Iteration 841 ) loss: 0.001564
(Iteration 861 ) loss: 0.000057
(Iteration 881 ) loss: 0.000346
(Iteration 901 ) loss: 0.000886
(Iteration 921 ) loss: 0.000955
(Iteration 941 ) loss: 0.000219
(Iteration 961 ) loss: 0.001028
(Iteration 981 ) loss: 0.000703
(Epoch 75 % 100) train loss: 0.0007340352163760047, eval loss: 0.0007413536392424984
(Iteration 1 ) loss: 0.001007
(Iteration 21 ) loss: 0.001155
(Iteration 41 ) loss: 0.000600
(Iteration 61 ) loss: 0.000875
(Iteration 81 ) loss: 0.000767
(Iteration 101 ) loss: 0.000335
(Iteration 121 ) loss: 0.000345
(Iteration 141 ) loss: 0.000252
(Iteration 161 ) loss: 0.002097
(Iteration 181 ) loss: 0.000174
(Iteration 201 ) loss: 0.000704
(Iteration 221 ) loss: 0.000828
(Iteration 241 ) loss: 0.001199
(Iteration 261 ) loss: 0.000958
(Iteration 281 ) loss: 0.000303
(Iteration 301 ) loss: 0.002222
(Iteration 321 ) loss: 0.000148
(Iteration 341 ) loss: 0.001473
(Iteration 361 ) loss: 0.000925
(Iteration 381 ) loss: 0.002316
(Iteration 401 ) loss: 0.000721
(Iteration 421 ) loss: 0.000554
(Iteration 441 ) loss: 0.001264
(Iteration 461 ) loss: 0.000892
(Iteration 481 ) loss: 0.000148
(Iteration 501 ) loss: 0.000075
(Iteration 521 ) loss: 0.001093
(Iteration 541 ) loss: 0.000845
(Iteration 561 ) loss: 0.003210
(Iteration 581 ) loss: 0.000079
(Iteration 601 ) loss: 0.000323
(Iteration 621 ) loss: 0.001643
(Iteration 641 ) loss: 0.001132
(Iteration 661 ) loss: 0.001198
(Iteration 681 ) loss: 0.000920
(Iteration 701 ) loss: 0.000436
(Iteration 721 ) loss: 0.002678
(Iteration 741 ) loss: 0.000918
(Iteration 761 ) loss: 0.002642
(Iteration 781 ) loss: 0.000368
(Iteration 801 ) loss: 0.000175
(Iteration 821 ) loss: 0.003580
(Iteration 841 ) loss: 0.000531
(Iteration 861 ) loss: 0.001169
(Iteration 881 ) loss: 0.000750
(Iteration 901 ) loss: 0.000440
(Iteration 921 ) loss: 0.007409
(Iteration 941 ) loss: 0.000354
(Iteration 961 ) loss: 0.000298
(Iteration 981 ) loss: 0.000094
(Epoch 76 % 100) train loss: 0.0015278697759411016, eval loss: 0.0015226875391078291
(Iteration 1 ) loss: 0.000159
(Iteration 21 ) loss: 0.001626
(Iteration 41 ) loss: 0.007851
(Iteration 61 ) loss: 0.004567
(Iteration 81 ) loss: 0.004234
(Iteration 101 ) loss: 0.002138
(Iteration 121 ) loss: 0.001037
(Iteration 141 ) loss: 0.000247
(Iteration 161 ) loss: 0.001418
(Iteration 181 ) loss: 0.004408
(Iteration 201 ) loss: 0.001013
(Iteration 221 ) loss: 0.000290
(Iteration 241 ) loss: 0.000360
(Iteration 261 ) loss: 0.001515
(Iteration 281 ) loss: 0.000690
(Iteration 301 ) loss: 0.000711
(Iteration 321 ) loss: 0.000896
(Iteration 341 ) loss: 0.000580
(Iteration 361 ) loss: 0.000133
(Iteration 381 ) loss: 0.000885
(Iteration 401 ) loss: 0.000236
(Iteration 421 ) loss: 0.002532
(Iteration 441 ) loss: 0.000670
(Iteration 461 ) loss: 0.000714
(Iteration 481 ) loss: 0.001043
(Iteration 501 ) loss: 0.000941
(Iteration 521 ) loss: 0.000311
(Iteration 541 ) loss: 0.000247
(Iteration 561 ) loss: 0.000333
(Iteration 581 ) loss: 0.001223
(Iteration 601 ) loss: 0.000867
(Iteration 621 ) loss: 0.000112
(Iteration 641 ) loss: 0.000432
(Iteration 661 ) loss: 0.000679
(Iteration 681 ) loss: 0.000802
(Iteration 701 ) loss: 0.000391
(Iteration 721 ) loss: 0.000858
(Iteration 741 ) loss: 0.000751
(Iteration 761 ) loss: 0.001653
(Iteration 781 ) loss: 0.001332
(Iteration 801 ) loss: 0.001276
(Iteration 821 ) loss: 0.000253
(Iteration 841 ) loss: 0.000618
(Iteration 861 ) loss: 0.000248
(Iteration 881 ) loss: 0.007012
(Iteration 901 ) loss: 0.000397
(Iteration 921 ) loss: 0.000403
(Iteration 941 ) loss: 0.000732
(Iteration 961 ) loss: 0.000379
(Iteration 981 ) loss: 0.000372
(Epoch 77 % 100) train loss: 0.00097878989960092, eval loss: 0.0008565416899352789
(Iteration 1 ) loss: 0.000141
(Iteration 21 ) loss: 0.000222
(Iteration 41 ) loss: 0.001656
(Iteration 61 ) loss: 0.000742
(Iteration 81 ) loss: 0.000336
(Iteration 101 ) loss: 0.000632
(Iteration 121 ) loss: 0.000132
(Iteration 141 ) loss: 0.000271
(Iteration 161 ) loss: 0.000578
(Iteration 181 ) loss: 0.000590
(Iteration 201 ) loss: 0.000562
(Iteration 221 ) loss: 0.000529
(Iteration 241 ) loss: 0.001058
(Iteration 261 ) loss: 0.000523
(Iteration 281 ) loss: 0.001265
(Iteration 301 ) loss: 0.002047
(Iteration 321 ) loss: 0.001187
(Iteration 341 ) loss: 0.000374
(Iteration 361 ) loss: 0.001377
(Iteration 381 ) loss: 0.001883
(Iteration 401 ) loss: 0.003403
(Iteration 421 ) loss: 0.000333
(Iteration 441 ) loss: 0.002387
(Iteration 461 ) loss: 0.001078
(Iteration 481 ) loss: 0.007764
(Iteration 501 ) loss: 0.004549
(Iteration 521 ) loss: 0.006697
(Iteration 541 ) loss: 0.000989
(Iteration 561 ) loss: 0.001360
(Iteration 581 ) loss: 0.001871
(Iteration 601 ) loss: 0.001768
(Iteration 621 ) loss: 0.000640
(Iteration 641 ) loss: 0.001269
(Iteration 661 ) loss: 0.000300
(Iteration 681 ) loss: 0.002083
(Iteration 701 ) loss: 0.000670
(Iteration 721 ) loss: 0.000316
(Iteration 741 ) loss: 0.000962
(Iteration 761 ) loss: 0.000450
(Iteration 781 ) loss: 0.000090
(Iteration 801 ) loss: 0.001222
(Iteration 821 ) loss: 0.000941
(Iteration 841 ) loss: 0.000933
(Iteration 861 ) loss: 0.000968
(Iteration 881 ) loss: 0.000212
(Iteration 901 ) loss: 0.000483
(Iteration 921 ) loss: 0.000304
(Iteration 941 ) loss: 0.000413
(Iteration 961 ) loss: 0.000247
(Iteration 981 ) loss: 0.000356
(Epoch 78 % 100) train loss: 0.0018586660129571526, eval loss: 0.0018730021871266615
(Iteration 1 ) loss: 0.001252
(Iteration 21 ) loss: 0.000428
(Iteration 41 ) loss: 0.001918
(Iteration 61 ) loss: 0.000963
(Iteration 81 ) loss: 0.000820
(Iteration 101 ) loss: 0.000826
(Iteration 121 ) loss: 0.000311
(Iteration 141 ) loss: 0.000847
(Iteration 161 ) loss: 0.000281
(Iteration 181 ) loss: 0.000482
(Iteration 201 ) loss: 0.001742
(Iteration 221 ) loss: 0.000875
(Iteration 241 ) loss: 0.000462
(Iteration 261 ) loss: 0.000609
(Iteration 281 ) loss: 0.002492
(Iteration 301 ) loss: 0.000190
(Iteration 321 ) loss: 0.000459
(Iteration 341 ) loss: 0.000402
(Iteration 361 ) loss: 0.000589
(Iteration 381 ) loss: 0.006808
(Iteration 401 ) loss: 0.000630
(Iteration 421 ) loss: 0.002629
(Iteration 441 ) loss: 0.000572
(Iteration 461 ) loss: 0.002184
(Iteration 481 ) loss: 0.000372
(Iteration 501 ) loss: 0.001080
(Iteration 521 ) loss: 0.000680
(Iteration 541 ) loss: 0.001284
(Iteration 561 ) loss: 0.000514
(Iteration 581 ) loss: 0.000181
(Iteration 601 ) loss: 0.000822
(Iteration 621 ) loss: 0.001708
(Iteration 641 ) loss: 0.000663
(Iteration 661 ) loss: 0.000669
(Iteration 681 ) loss: 0.000400
(Iteration 701 ) loss: 0.002488
(Iteration 721 ) loss: 0.001894
(Iteration 741 ) loss: 0.001590
(Iteration 761 ) loss: 0.001143
(Iteration 781 ) loss: 0.000460
(Iteration 801 ) loss: 0.000371
(Iteration 821 ) loss: 0.000011
(Iteration 841 ) loss: 0.001501
(Iteration 861 ) loss: 0.000483
(Iteration 881 ) loss: 0.000292
(Iteration 901 ) loss: 0.000396
(Iteration 921 ) loss: 0.000152
(Iteration 941 ) loss: 0.000762
(Iteration 961 ) loss: 0.000905
(Iteration 981 ) loss: 0.000492
(Epoch 79 % 100) train loss: 0.0008767711827115093, eval loss: 0.0008231140764097232
(Iteration 1 ) loss: 0.001020
(Iteration 21 ) loss: 0.001497
(Iteration 41 ) loss: 0.000683
(Iteration 61 ) loss: 0.000253
(Iteration 81 ) loss: 0.000251
(Iteration 101 ) loss: 0.002174
(Iteration 121 ) loss: 0.002790
(Iteration 141 ) loss: 0.000110
(Iteration 161 ) loss: 0.001434
(Iteration 181 ) loss: 0.000501
(Iteration 201 ) loss: 0.001067
(Iteration 221 ) loss: 0.000803
(Iteration 241 ) loss: 0.001290
(Iteration 261 ) loss: 0.000358
(Iteration 281 ) loss: 0.000190
(Iteration 301 ) loss: 0.000072
(Iteration 321 ) loss: 0.000405
(Iteration 341 ) loss: 0.002886
(Iteration 361 ) loss: 0.000231
(Iteration 381 ) loss: 0.002984
(Iteration 401 ) loss: 0.001411
(Iteration 421 ) loss: 0.004678
(Iteration 441 ) loss: 0.005880
(Iteration 461 ) loss: 0.001759
(Iteration 481 ) loss: 0.002082
(Iteration 501 ) loss: 0.000371
(Iteration 521 ) loss: 0.000582
(Iteration 541 ) loss: 0.001596
(Iteration 561 ) loss: 0.001748
(Iteration 581 ) loss: 0.000398
(Iteration 601 ) loss: 0.001404
(Iteration 621 ) loss: 0.000651
(Iteration 641 ) loss: 0.000383
(Iteration 661 ) loss: 0.000402
(Iteration 681 ) loss: 0.000746
(Iteration 701 ) loss: 0.000619
(Iteration 721 ) loss: 0.000112
(Iteration 741 ) loss: 0.000533
(Iteration 761 ) loss: 0.000186
(Iteration 781 ) loss: 0.000234
(Iteration 801 ) loss: 0.000972
(Iteration 821 ) loss: 0.000149
(Iteration 841 ) loss: 0.001467
(Iteration 861 ) loss: 0.000904
(Iteration 881 ) loss: 0.001029
(Iteration 901 ) loss: 0.000692
(Iteration 921 ) loss: 0.002460
(Iteration 941 ) loss: 0.001142
(Iteration 961 ) loss: 0.001166
(Iteration 981 ) loss: 0.005870
(Epoch 80 % 100) train loss: 0.0015534940352493875, eval loss: 0.0014241984474930287
(Iteration 1 ) loss: 0.003206
(Iteration 21 ) loss: 0.002079
(Iteration 41 ) loss: 0.000777
(Iteration 61 ) loss: 0.000422
(Iteration 81 ) loss: 0.000836
(Iteration 101 ) loss: 0.000785
(Iteration 121 ) loss: 0.001660
(Iteration 141 ) loss: 0.001437
(Iteration 161 ) loss: 0.000749
(Iteration 181 ) loss: 0.003139
(Iteration 201 ) loss: 0.000147
(Iteration 221 ) loss: 0.000522
(Iteration 241 ) loss: 0.000084
(Iteration 261 ) loss: 0.000920
(Iteration 281 ) loss: 0.001400
(Iteration 301 ) loss: 0.003060
(Iteration 321 ) loss: 0.000266
(Iteration 341 ) loss: 0.000091
(Iteration 361 ) loss: 0.000734
(Iteration 381 ) loss: 0.000597
(Iteration 401 ) loss: 0.001448
(Iteration 421 ) loss: 0.000420
(Iteration 441 ) loss: 0.000096
(Iteration 461 ) loss: 0.000493
(Iteration 481 ) loss: 0.003006
(Iteration 501 ) loss: 0.000538
(Iteration 521 ) loss: 0.000889
(Iteration 541 ) loss: 0.000382
(Iteration 561 ) loss: 0.000160
(Iteration 581 ) loss: 0.000073
(Iteration 601 ) loss: 0.000096
(Iteration 621 ) loss: 0.000614
(Iteration 641 ) loss: 0.000588
(Iteration 661 ) loss: 0.000989
(Iteration 681 ) loss: 0.002287
(Iteration 701 ) loss: 0.000171
(Iteration 721 ) loss: 0.001102
(Iteration 741 ) loss: 0.000516
(Iteration 761 ) loss: 0.001654
(Iteration 781 ) loss: 0.000119
(Iteration 801 ) loss: 0.000934
(Iteration 821 ) loss: 0.000143
(Iteration 841 ) loss: 0.000114
(Iteration 861 ) loss: 0.000561
(Iteration 881 ) loss: 0.000792
(Iteration 901 ) loss: 0.000143
(Iteration 921 ) loss: 0.000145
(Iteration 941 ) loss: 0.000436
(Iteration 961 ) loss: 0.000688
(Iteration 981 ) loss: 0.000208
(Epoch 81 % 100) train loss: 0.00041913655996347605, eval loss: 0.0004339437682201973
(Iteration 1 ) loss: 0.000519
(Iteration 21 ) loss: 0.000310
(Iteration 41 ) loss: 0.000976
(Iteration 61 ) loss: 0.001396
(Iteration 81 ) loss: 0.001189
(Iteration 101 ) loss: 0.000367
(Iteration 121 ) loss: 0.000545
(Iteration 141 ) loss: 0.000268
(Iteration 161 ) loss: 0.000264
(Iteration 181 ) loss: 0.000521
(Iteration 201 ) loss: 0.000486
(Iteration 221 ) loss: 0.000017
(Iteration 241 ) loss: 0.001666
(Iteration 261 ) loss: 0.000041
(Iteration 281 ) loss: 0.000492
(Iteration 301 ) loss: 0.002013
(Iteration 321 ) loss: 0.000739
(Iteration 341 ) loss: 0.000181
(Iteration 361 ) loss: 0.000161
(Iteration 381 ) loss: 0.001228
(Iteration 401 ) loss: 0.000058
(Iteration 421 ) loss: 0.000101
(Iteration 441 ) loss: 0.000218
(Iteration 461 ) loss: 0.002976
(Iteration 481 ) loss: 0.000927
(Iteration 501 ) loss: 0.000608
(Iteration 521 ) loss: 0.001262
(Iteration 541 ) loss: 0.000980
(Iteration 561 ) loss: 0.002189
(Iteration 581 ) loss: 0.001710
(Iteration 601 ) loss: 0.002346
(Iteration 621 ) loss: 0.000124
(Iteration 641 ) loss: 0.000400
(Iteration 661 ) loss: 0.000388
(Iteration 681 ) loss: 0.000446
(Iteration 701 ) loss: 0.001053
(Iteration 721 ) loss: 0.000592
(Iteration 741 ) loss: 0.001016
(Iteration 761 ) loss: 0.000214
(Iteration 781 ) loss: 0.001136
(Iteration 801 ) loss: 0.000659
(Iteration 821 ) loss: 0.000174
(Iteration 841 ) loss: 0.000411
(Iteration 861 ) loss: 0.001451
(Iteration 881 ) loss: 0.000047
(Iteration 901 ) loss: 0.000248
(Iteration 921 ) loss: 0.002395
(Iteration 941 ) loss: 0.000495
(Iteration 961 ) loss: 0.001002
(Iteration 981 ) loss: 0.000235
(Epoch 82 % 100) train loss: 0.0004570730632606943, eval loss: 0.0004126013076383763
(Iteration 1 ) loss: 0.000374
(Iteration 21 ) loss: 0.001591
(Iteration 41 ) loss: 0.000108
(Iteration 61 ) loss: 0.000670
(Iteration 81 ) loss: 0.000166
(Iteration 101 ) loss: 0.000222
(Iteration 121 ) loss: 0.000579
(Iteration 141 ) loss: 0.000728
(Iteration 161 ) loss: 0.002842
(Iteration 181 ) loss: 0.004607
(Iteration 201 ) loss: 0.000512
(Iteration 221 ) loss: 0.001655
(Iteration 241 ) loss: 0.002334
(Iteration 261 ) loss: 0.004772
(Iteration 281 ) loss: 0.006366
(Iteration 301 ) loss: 0.002148
(Iteration 321 ) loss: 0.001244
(Iteration 341 ) loss: 0.000336
(Iteration 361 ) loss: 0.001100
(Iteration 381 ) loss: 0.000242
(Iteration 401 ) loss: 0.000611
(Iteration 421 ) loss: 0.000189
(Iteration 441 ) loss: 0.005094
(Iteration 461 ) loss: 0.003133
(Iteration 481 ) loss: 0.002360
(Iteration 501 ) loss: 0.000970
(Iteration 521 ) loss: 0.002145
(Iteration 541 ) loss: 0.001361
(Iteration 561 ) loss: 0.000495
(Iteration 581 ) loss: 0.001279
(Iteration 601 ) loss: 0.000618
(Iteration 621 ) loss: 0.000699
(Iteration 641 ) loss: 0.000346
(Iteration 661 ) loss: 0.000813
(Iteration 681 ) loss: 0.000822
(Iteration 701 ) loss: 0.000175
(Iteration 721 ) loss: 0.000108
(Iteration 741 ) loss: 0.000717
(Iteration 761 ) loss: 0.000205
(Iteration 781 ) loss: 0.000090
(Iteration 801 ) loss: 0.001032
(Iteration 821 ) loss: 0.000975
(Iteration 841 ) loss: 0.001057
(Iteration 861 ) loss: 0.001102
(Iteration 881 ) loss: 0.000991
(Iteration 901 ) loss: 0.000748
(Iteration 921 ) loss: 0.000137
(Iteration 941 ) loss: 0.000208
(Iteration 961 ) loss: 0.000983
(Iteration 981 ) loss: 0.000062
(Epoch 83 % 100) train loss: 0.0005459524364044936, eval loss: 0.0005457337145116266
(Iteration 1 ) loss: 0.000491
(Iteration 21 ) loss: 0.001260
(Iteration 41 ) loss: 0.001111
(Iteration 61 ) loss: 0.000143
(Iteration 81 ) loss: 0.000771
(Iteration 101 ) loss: 0.000349
(Iteration 121 ) loss: 0.000723
(Iteration 141 ) loss: 0.001575
(Iteration 161 ) loss: 0.001382
(Iteration 181 ) loss: 0.000220
(Iteration 201 ) loss: 0.000572
(Iteration 221 ) loss: 0.001287
(Iteration 241 ) loss: 0.000543
(Iteration 261 ) loss: 0.003717
(Iteration 281 ) loss: 0.000714
(Iteration 301 ) loss: 0.001122
(Iteration 321 ) loss: 0.000947
(Iteration 341 ) loss: 0.000260
(Iteration 361 ) loss: 0.000446
(Iteration 381 ) loss: 0.002353
(Iteration 401 ) loss: 0.000762
(Iteration 421 ) loss: 0.000365
(Iteration 441 ) loss: 0.000195
(Iteration 461 ) loss: 0.000586
(Iteration 481 ) loss: 0.000149
(Iteration 501 ) loss: 0.000541
(Iteration 521 ) loss: 0.003055
(Iteration 541 ) loss: 0.000037
(Iteration 561 ) loss: 0.000105
(Iteration 581 ) loss: 0.002291
(Iteration 601 ) loss: 0.000883
(Iteration 621 ) loss: 0.000803
(Iteration 641 ) loss: 0.000483
(Iteration 661 ) loss: 0.001007
(Iteration 681 ) loss: 0.001439
(Iteration 701 ) loss: 0.000707
(Iteration 721 ) loss: 0.000474
(Iteration 741 ) loss: 0.000360
(Iteration 761 ) loss: 0.000748
(Iteration 781 ) loss: 0.001496
(Iteration 801 ) loss: 0.000749
(Iteration 821 ) loss: 0.000916
(Iteration 841 ) loss: 0.000079
(Iteration 861 ) loss: 0.000134
(Iteration 881 ) loss: 0.000785
(Iteration 901 ) loss: 0.001854
(Iteration 921 ) loss: 0.000127
(Iteration 941 ) loss: 0.000479
(Iteration 961 ) loss: 0.001211
(Iteration 981 ) loss: 0.001412
(Epoch 84 % 100) train loss: 0.0007559753111127785, eval loss: 0.0007831366995227544
(Iteration 1 ) loss: 0.001089
(Iteration 21 ) loss: 0.000797
(Iteration 41 ) loss: 0.000648
(Iteration 61 ) loss: 0.000433
(Iteration 81 ) loss: 0.001331
(Iteration 101 ) loss: 0.000345
(Iteration 121 ) loss: 0.001137
(Iteration 141 ) loss: 0.002638
(Iteration 161 ) loss: 0.000671
(Iteration 181 ) loss: 0.000373
(Iteration 201 ) loss: 0.000382
(Iteration 221 ) loss: 0.000367
(Iteration 241 ) loss: 0.000086
(Iteration 261 ) loss: 0.001476
(Iteration 281 ) loss: 0.000975
(Iteration 301 ) loss: 0.000193
(Iteration 321 ) loss: 0.000416
(Iteration 341 ) loss: 0.000670
(Iteration 361 ) loss: 0.001291
(Iteration 381 ) loss: 0.003538
(Iteration 401 ) loss: 0.001062
(Iteration 421 ) loss: 0.000653
(Iteration 441 ) loss: 0.000687
(Iteration 461 ) loss: 0.001091
(Iteration 481 ) loss: 0.000127
(Iteration 501 ) loss: 0.000304
(Iteration 521 ) loss: 0.001816
(Iteration 541 ) loss: 0.000769
(Iteration 561 ) loss: 0.000221
(Iteration 581 ) loss: 0.000517
(Iteration 601 ) loss: 0.003513
(Iteration 621 ) loss: 0.001387
(Iteration 641 ) loss: 0.001241
(Iteration 661 ) loss: 0.000801
(Iteration 681 ) loss: 0.002342
(Iteration 701 ) loss: 0.000105
(Iteration 721 ) loss: 0.000299
(Iteration 741 ) loss: 0.000128
(Iteration 761 ) loss: 0.000981
(Iteration 781 ) loss: 0.000385
(Iteration 801 ) loss: 0.001203
(Iteration 821 ) loss: 0.000306
(Iteration 841 ) loss: 0.000378
(Iteration 861 ) loss: 0.000217
(Iteration 881 ) loss: 0.000146
(Iteration 901 ) loss: 0.000613
(Iteration 921 ) loss: 0.000768
(Iteration 941 ) loss: 0.001062
(Iteration 961 ) loss: 0.001726
(Iteration 981 ) loss: 0.001462
(Epoch 85 % 100) train loss: 0.00051736176631716, eval loss: 0.00047117161877703346
(Iteration 1 ) loss: 0.000856
(Iteration 21 ) loss: 0.001023
(Iteration 41 ) loss: 0.000609
(Iteration 61 ) loss: 0.000587
(Iteration 81 ) loss: 0.000629
(Iteration 101 ) loss: 0.000621
(Iteration 121 ) loss: 0.000243
(Iteration 141 ) loss: 0.000603
(Iteration 161 ) loss: 0.000866
(Iteration 181 ) loss: 0.001435
(Iteration 201 ) loss: 0.001701
(Iteration 221 ) loss: 0.002790
(Iteration 241 ) loss: 0.001560
(Iteration 261 ) loss: 0.000811
(Iteration 281 ) loss: 0.000860
(Iteration 301 ) loss: 0.001675
(Iteration 321 ) loss: 0.000903
(Iteration 341 ) loss: 0.000753
(Iteration 361 ) loss: 0.000095
(Iteration 381 ) loss: 0.000229
(Iteration 401 ) loss: 0.000298
(Iteration 421 ) loss: 0.000178
(Iteration 441 ) loss: 0.000645
(Iteration 461 ) loss: 0.000591
(Iteration 481 ) loss: 0.000395
(Iteration 501 ) loss: 0.000961
(Iteration 521 ) loss: 0.004377
(Iteration 541 ) loss: 0.001264
(Iteration 561 ) loss: 0.002304
(Iteration 581 ) loss: 0.000694
(Iteration 601 ) loss: 0.001127
(Iteration 621 ) loss: 0.000476
(Iteration 641 ) loss: 0.000145
(Iteration 661 ) loss: 0.000744
(Iteration 681 ) loss: 0.001383
(Iteration 701 ) loss: 0.000210
(Iteration 721 ) loss: 0.000399
(Iteration 741 ) loss: 0.000061
(Iteration 761 ) loss: 0.000606
(Iteration 781 ) loss: 0.000675
(Iteration 801 ) loss: 0.000410
(Iteration 821 ) loss: 0.000358
(Iteration 841 ) loss: 0.000057
(Iteration 861 ) loss: 0.000717
(Iteration 881 ) loss: 0.000145
(Iteration 901 ) loss: 0.000746
(Iteration 921 ) loss: 0.000200
(Iteration 941 ) loss: 0.000581
(Iteration 961 ) loss: 0.000298
(Iteration 981 ) loss: 0.002595
(Epoch 86 % 100) train loss: 0.002363046550300031, eval loss: 0.002460988760657134
(Iteration 1 ) loss: 0.003018
(Iteration 21 ) loss: 0.001715
(Iteration 41 ) loss: 0.001403
(Iteration 61 ) loss: 0.000790
(Iteration 81 ) loss: 0.000838
(Iteration 101 ) loss: 0.000421
(Iteration 121 ) loss: 0.002475
(Iteration 141 ) loss: 0.000810
(Iteration 161 ) loss: 0.000759
(Iteration 181 ) loss: 0.000941
(Iteration 201 ) loss: 0.000140
(Iteration 221 ) loss: 0.000708
(Iteration 241 ) loss: 0.003856
(Iteration 261 ) loss: 0.001159
(Iteration 281 ) loss: 0.000786
(Iteration 301 ) loss: 0.000626
(Iteration 321 ) loss: 0.000472
(Iteration 341 ) loss: 0.000986
(Iteration 361 ) loss: 0.001102
(Iteration 381 ) loss: 0.001060
(Iteration 401 ) loss: 0.001938
(Iteration 421 ) loss: 0.000700
(Iteration 441 ) loss: 0.002347
(Iteration 461 ) loss: 0.001595
(Iteration 481 ) loss: 0.003311
(Iteration 501 ) loss: 0.000464
(Iteration 521 ) loss: 0.000221
(Iteration 541 ) loss: 0.001123
(Iteration 561 ) loss: 0.000436
(Iteration 581 ) loss: 0.000964
(Iteration 601 ) loss: 0.000222
(Iteration 621 ) loss: 0.000640
(Iteration 641 ) loss: 0.000447
(Iteration 661 ) loss: 0.000287
(Iteration 681 ) loss: 0.003352
(Iteration 701 ) loss: 0.001470
(Iteration 721 ) loss: 0.001512
(Iteration 741 ) loss: 0.000248
(Iteration 761 ) loss: 0.000575
(Iteration 781 ) loss: 0.000530
(Iteration 801 ) loss: 0.001039
(Iteration 821 ) loss: 0.000253
(Iteration 841 ) loss: 0.000710
(Iteration 861 ) loss: 0.001948
(Iteration 881 ) loss: 0.001720
(Iteration 901 ) loss: 0.007015
(Iteration 921 ) loss: 0.002968
(Iteration 941 ) loss: 0.003787
(Iteration 961 ) loss: 0.000581
(Iteration 981 ) loss: 0.001568
(Epoch 87 % 100) train loss: 0.000884617119832327, eval loss: 0.0008751711590446355
(Iteration 1 ) loss: 0.000563
(Iteration 21 ) loss: 0.003425
(Iteration 41 ) loss: 0.003130
(Iteration 61 ) loss: 0.000509
(Iteration 81 ) loss: 0.000024
(Iteration 101 ) loss: 0.000356
(Iteration 121 ) loss: 0.000722
(Iteration 141 ) loss: 0.002619
(Iteration 161 ) loss: 0.001085
(Iteration 181 ) loss: 0.001229
(Iteration 201 ) loss: 0.000680
(Iteration 221 ) loss: 0.000498
(Iteration 241 ) loss: 0.000113
(Iteration 261 ) loss: 0.000052
(Iteration 281 ) loss: 0.000501
(Iteration 301 ) loss: 0.000676
(Iteration 321 ) loss: 0.000648
(Iteration 341 ) loss: 0.001387
(Iteration 361 ) loss: 0.001285
(Iteration 381 ) loss: 0.000352
(Iteration 401 ) loss: 0.000106
(Iteration 421 ) loss: 0.000237
(Iteration 441 ) loss: 0.000762
(Iteration 461 ) loss: 0.000584
(Iteration 481 ) loss: 0.000109
(Iteration 501 ) loss: 0.000091
(Iteration 521 ) loss: 0.000080
(Iteration 541 ) loss: 0.000512
(Iteration 561 ) loss: 0.001267
(Iteration 581 ) loss: 0.000106
(Iteration 601 ) loss: 0.003751
(Iteration 621 ) loss: 0.001555
(Iteration 641 ) loss: 0.001057
(Iteration 661 ) loss: 0.000323
(Iteration 681 ) loss: 0.000266
(Iteration 701 ) loss: 0.000326
(Iteration 721 ) loss: 0.001256
(Iteration 741 ) loss: 0.000446
(Iteration 761 ) loss: 0.000526
(Iteration 781 ) loss: 0.001172
(Iteration 801 ) loss: 0.000672
(Iteration 821 ) loss: 0.001794
(Iteration 841 ) loss: 0.000448
(Iteration 861 ) loss: 0.000833
(Iteration 881 ) loss: 0.000881
(Iteration 901 ) loss: 0.001548
(Iteration 921 ) loss: 0.000180
(Iteration 941 ) loss: 0.000216
(Iteration 961 ) loss: 0.000142
(Iteration 981 ) loss: 0.001405
(Epoch 88 % 100) train loss: 0.0005109376995197179, eval loss: 0.0005074486838087709
(Iteration 1 ) loss: 0.000129
(Iteration 21 ) loss: 0.001884
(Iteration 41 ) loss: 0.001295
(Iteration 61 ) loss: 0.001281
(Iteration 81 ) loss: 0.000875
(Iteration 101 ) loss: 0.000874
(Iteration 121 ) loss: 0.000064
(Iteration 141 ) loss: 0.000142
(Iteration 161 ) loss: 0.000334
(Iteration 181 ) loss: 0.001462
(Iteration 201 ) loss: 0.000169
(Iteration 221 ) loss: 0.000297
(Iteration 241 ) loss: 0.000951
(Iteration 261 ) loss: 0.000127
(Iteration 281 ) loss: 0.000396
(Iteration 301 ) loss: 0.000598
(Iteration 321 ) loss: 0.000621
(Iteration 341 ) loss: 0.001105
(Iteration 361 ) loss: 0.000344
(Iteration 381 ) loss: 0.001112
(Iteration 401 ) loss: 0.004995
(Iteration 421 ) loss: 0.000755
(Iteration 441 ) loss: 0.000323
(Iteration 461 ) loss: 0.000387
(Iteration 481 ) loss: 0.000257
(Iteration 501 ) loss: 0.002247
(Iteration 521 ) loss: 0.000828
(Iteration 541 ) loss: 0.000273
(Iteration 561 ) loss: 0.000409
(Iteration 581 ) loss: 0.000501
(Iteration 601 ) loss: 0.000721
(Iteration 621 ) loss: 0.001331
(Iteration 641 ) loss: 0.000226
(Iteration 661 ) loss: 0.000623
(Iteration 681 ) loss: 0.000432
(Iteration 701 ) loss: 0.000401
(Iteration 721 ) loss: 0.001080
(Iteration 741 ) loss: 0.001069
(Iteration 761 ) loss: 0.001186
(Iteration 781 ) loss: 0.000601
(Iteration 801 ) loss: 0.000446
(Iteration 821 ) loss: 0.000984
(Iteration 841 ) loss: 0.000577
(Iteration 861 ) loss: 0.000787
(Iteration 881 ) loss: 0.000469
(Iteration 901 ) loss: 0.000372
(Iteration 921 ) loss: 0.000202
(Iteration 941 ) loss: 0.000393
(Iteration 961 ) loss: 0.001034
(Iteration 981 ) loss: 0.003121
(Epoch 89 % 100) train loss: 0.0014244559619106666, eval loss: 0.0014424601044861966
(Iteration 1 ) loss: 0.001449
(Iteration 21 ) loss: 0.000509
(Iteration 41 ) loss: 0.000538
(Iteration 61 ) loss: 0.001399
(Iteration 81 ) loss: 0.000585
(Iteration 101 ) loss: 0.000223
(Iteration 121 ) loss: 0.000347
(Iteration 141 ) loss: 0.000701
(Iteration 161 ) loss: 0.000728
(Iteration 181 ) loss: 0.001412
(Iteration 201 ) loss: 0.000292
(Iteration 221 ) loss: 0.002619
(Iteration 241 ) loss: 0.000973
(Iteration 261 ) loss: 0.000741
(Iteration 281 ) loss: 0.000092
(Iteration 301 ) loss: 0.003162
(Iteration 321 ) loss: 0.004079
(Iteration 341 ) loss: 0.004856
(Iteration 361 ) loss: 0.000750
(Iteration 381 ) loss: 0.000793
(Iteration 401 ) loss: 0.000439
(Iteration 421 ) loss: 0.001094
(Iteration 441 ) loss: 0.000528
(Iteration 461 ) loss: 0.000543
(Iteration 481 ) loss: 0.000862
(Iteration 501 ) loss: 0.001967
(Iteration 521 ) loss: 0.000699
(Iteration 541 ) loss: 0.000128
(Iteration 561 ) loss: 0.001494
(Iteration 581 ) loss: 0.001090
(Iteration 601 ) loss: 0.000893
(Iteration 621 ) loss: 0.000781
(Iteration 641 ) loss: 0.000017
(Iteration 661 ) loss: 0.001583
(Iteration 681 ) loss: 0.001126
(Iteration 701 ) loss: 0.000731
(Iteration 721 ) loss: 0.000179
(Iteration 741 ) loss: 0.000896
(Iteration 761 ) loss: 0.000440
(Iteration 781 ) loss: 0.001332
(Iteration 801 ) loss: 0.002795
(Iteration 821 ) loss: 0.002457
(Iteration 841 ) loss: 0.000748
(Iteration 861 ) loss: 0.004477
(Iteration 881 ) loss: 0.011096
(Iteration 901 ) loss: 0.000796
(Iteration 921 ) loss: 0.000491
(Iteration 941 ) loss: 0.000818
(Iteration 961 ) loss: 0.000642
(Iteration 981 ) loss: 0.000235
(Epoch 90 % 100) train loss: 0.0007279956979111491, eval loss: 0.0007245052402509819
(Iteration 1 ) loss: 0.000828
(Iteration 21 ) loss: 0.000116
(Iteration 41 ) loss: 0.000382
(Iteration 61 ) loss: 0.000987
(Iteration 81 ) loss: 0.000737
(Iteration 101 ) loss: 0.002667
(Iteration 121 ) loss: 0.000246
(Iteration 141 ) loss: 0.000468
(Iteration 161 ) loss: 0.000622
(Iteration 181 ) loss: 0.000798
(Iteration 201 ) loss: 0.000099
(Iteration 221 ) loss: 0.002061
(Iteration 241 ) loss: 0.000377
(Iteration 261 ) loss: 0.001631
(Iteration 281 ) loss: 0.001588
(Iteration 301 ) loss: 0.000262
(Iteration 321 ) loss: 0.000846
(Iteration 341 ) loss: 0.000131
(Iteration 361 ) loss: 0.001477
(Iteration 381 ) loss: 0.001134
(Iteration 401 ) loss: 0.001103
(Iteration 421 ) loss: 0.001793
(Iteration 441 ) loss: 0.000197
(Iteration 461 ) loss: 0.000500
(Iteration 481 ) loss: 0.000549
(Iteration 501 ) loss: 0.000634
(Iteration 521 ) loss: 0.001008
(Iteration 541 ) loss: 0.000664
(Iteration 561 ) loss: 0.000251
(Iteration 581 ) loss: 0.000104
(Iteration 601 ) loss: 0.001623
(Iteration 621 ) loss: 0.001036
(Iteration 641 ) loss: 0.000314
(Iteration 661 ) loss: 0.000781
(Iteration 681 ) loss: 0.000842
(Iteration 701 ) loss: 0.000683
(Iteration 721 ) loss: 0.001300
(Iteration 741 ) loss: 0.001139
(Iteration 761 ) loss: 0.000272
(Iteration 781 ) loss: 0.000533
(Iteration 801 ) loss: 0.000437
(Iteration 821 ) loss: 0.000695
(Iteration 841 ) loss: 0.001056
(Iteration 861 ) loss: 0.000595
(Iteration 881 ) loss: 0.002129
(Iteration 901 ) loss: 0.001015
(Iteration 921 ) loss: 0.001625
(Iteration 941 ) loss: 0.002885
(Iteration 961 ) loss: 0.000368
(Iteration 981 ) loss: 0.000239
(Epoch 91 % 100) train loss: 0.0005276342495343376, eval loss: 0.0005018085657521166
(Iteration 1 ) loss: 0.000283
(Iteration 21 ) loss: 0.000471
(Iteration 41 ) loss: 0.000382
(Iteration 61 ) loss: 0.001403
(Iteration 81 ) loss: 0.000583
(Iteration 101 ) loss: 0.000276
(Iteration 121 ) loss: 0.000741
(Iteration 141 ) loss: 0.000249
(Iteration 161 ) loss: 0.005510
(Iteration 181 ) loss: 0.000239
(Iteration 201 ) loss: 0.000210
(Iteration 221 ) loss: 0.000332
(Iteration 241 ) loss: 0.000240
(Iteration 261 ) loss: 0.000272
(Iteration 281 ) loss: 0.000145
(Iteration 301 ) loss: 0.000584
(Iteration 321 ) loss: 0.000515
(Iteration 341 ) loss: 0.001377
(Iteration 361 ) loss: 0.000964
(Iteration 381 ) loss: 0.001913
(Iteration 401 ) loss: 0.001021
(Iteration 421 ) loss: 0.002458
(Iteration 441 ) loss: 0.004122
(Iteration 461 ) loss: 0.000558
(Iteration 481 ) loss: 0.000211
(Iteration 501 ) loss: 0.000956
(Iteration 521 ) loss: 0.001782
(Iteration 541 ) loss: 0.001963
(Iteration 561 ) loss: 0.000629
(Iteration 581 ) loss: 0.001332
(Iteration 601 ) loss: 0.001228
(Iteration 621 ) loss: 0.000111
(Iteration 641 ) loss: 0.000378
(Iteration 661 ) loss: 0.001023
(Iteration 681 ) loss: 0.000183
(Iteration 701 ) loss: 0.000739
(Iteration 721 ) loss: 0.000902
(Iteration 741 ) loss: 0.002328
(Iteration 761 ) loss: 0.000988
(Iteration 781 ) loss: 0.000059
(Iteration 801 ) loss: 0.000282
(Iteration 821 ) loss: 0.000062
(Iteration 841 ) loss: 0.001106
(Iteration 861 ) loss: 0.001021
(Iteration 881 ) loss: 0.000511
(Iteration 901 ) loss: 0.000169
(Iteration 921 ) loss: 0.000373
(Iteration 941 ) loss: 0.000354
(Iteration 961 ) loss: 0.000962
(Iteration 981 ) loss: 0.000527
(Epoch 92 % 100) train loss: 0.0014721313257452288, eval loss: 0.0014485905995859914
(Iteration 1 ) loss: 0.000736
(Iteration 21 ) loss: 0.001539
(Iteration 41 ) loss: 0.001036
(Iteration 61 ) loss: 0.001732
(Iteration 81 ) loss: 0.000429
(Iteration 101 ) loss: 0.001309
(Iteration 121 ) loss: 0.000314
(Iteration 141 ) loss: 0.002042
(Iteration 161 ) loss: 0.000637
(Iteration 181 ) loss: 0.002872
(Iteration 201 ) loss: 0.008768
(Iteration 221 ) loss: 0.000408
(Iteration 241 ) loss: 0.000233
(Iteration 261 ) loss: 0.000366
(Iteration 281 ) loss: 0.000294
(Iteration 301 ) loss: 0.000635
(Iteration 321 ) loss: 0.001089
(Iteration 341 ) loss: 0.000387
(Iteration 361 ) loss: 0.000600
(Iteration 381 ) loss: 0.000897
(Iteration 401 ) loss: 0.001211
(Iteration 421 ) loss: 0.001701
(Iteration 441 ) loss: 0.000248
(Iteration 461 ) loss: 0.000856
(Iteration 481 ) loss: 0.000184
(Iteration 501 ) loss: 0.000277
(Iteration 521 ) loss: 0.000783
(Iteration 561 ) loss: 0.000447
(Iteration 581 ) loss: 0.000760
(Iteration 601 ) loss: 0.000505
(Iteration 621 ) loss: 0.000169
(Iteration 641 ) loss: 0.000779
(Iteration 661 ) loss: 0.000190
(Iteration 681 ) loss: 0.000118
(Iteration 701 ) loss: 0.000942
(Iteration 721 ) loss: 0.000858
(Iteration 741 ) loss: 0.000970
(Iteration 761 ) loss: 0.001864
(Iteration 781 ) loss: 0.001855
(Iteration 801 ) loss: 0.000458
(Iteration 821 ) loss: 0.001349
(Iteration 841 ) loss: 0.000085
(Iteration 861 ) loss: 0.000324
(Iteration 881 ) loss: 0.000473
(Iteration 901 ) loss: 0.001383
(Iteration 921 ) loss: 0.000534
(Iteration 941 ) loss: 0.000785
(Iteration 961 ) loss: 0.000563
(Iteration 981 ) loss: 0.002388
(Epoch 93 % 100) train loss: 0.0017841064920091853, eval loss: 0.0017734774283278136
(Iteration 1 ) loss: 0.002570
(Iteration 21 ) loss: 0.000408
(Iteration 41 ) loss: 0.000630
(Iteration 61 ) loss: 0.001574
(Iteration 81 ) loss: 0.000643
(Iteration 101 ) loss: 0.002798
(Iteration 121 ) loss: 0.000444
(Iteration 141 ) loss: 0.002808
(Iteration 161 ) loss: 0.001995
(Iteration 181 ) loss: 0.000466
(Iteration 201 ) loss: 0.000887
(Iteration 221 ) loss: 0.000219
(Iteration 241 ) loss: 0.000323
(Iteration 261 ) loss: 0.003877
(Iteration 281 ) loss: 0.000462
(Iteration 301 ) loss: 0.000107
(Iteration 321 ) loss: 0.001653
(Iteration 341 ) loss: 0.000581
(Iteration 361 ) loss: 0.000534
(Iteration 381 ) loss: 0.000339
(Iteration 401 ) loss: 0.000081
(Iteration 421 ) loss: 0.000439
(Iteration 441 ) loss: 0.003570
(Iteration 461 ) loss: 0.001373
(Iteration 481 ) loss: 0.001559
(Iteration 501 ) loss: 0.001027
(Iteration 521 ) loss: 0.000412
(Iteration 541 ) loss: 0.000922
(Iteration 561 ) loss: 0.000863
(Iteration 581 ) loss: 0.000756
(Iteration 601 ) loss: 0.001680
(Iteration 621 ) loss: 0.004630
(Iteration 641 ) loss: 0.001244
(Iteration 661 ) loss: 0.000134
(Iteration 681 ) loss: 0.000350
(Iteration 701 ) loss: 0.000140
(Iteration 721 ) loss: 0.000426
(Iteration 741 ) loss: 0.000632
(Iteration 761 ) loss: 0.000770
(Iteration 781 ) loss: 0.001676
(Iteration 801 ) loss: 0.001501
(Iteration 821 ) loss: 0.000474
(Iteration 841 ) loss: 0.000144
(Iteration 861 ) loss: 0.000391
(Iteration 881 ) loss: 0.002987
(Iteration 901 ) loss: 0.005793
(Iteration 921 ) loss: 0.000841
(Iteration 941 ) loss: 0.001184
(Iteration 961 ) loss: 0.000868
(Iteration 981 ) loss: 0.001046
(Epoch 94 % 100) train loss: 0.0014835284186762775, eval loss: 0.0013485380800431917
(Iteration 1 ) loss: 0.000965
(Iteration 21 ) loss: 0.000801
(Iteration 41 ) loss: 0.000380
(Iteration 61 ) loss: 0.000465
(Iteration 81 ) loss: 0.000189
(Iteration 101 ) loss: 0.000668
(Iteration 121 ) loss: 0.000201
(Iteration 141 ) loss: 0.000423
(Iteration 161 ) loss: 0.001285
(Iteration 181 ) loss: 0.000443
(Iteration 201 ) loss: 0.000932
(Iteration 221 ) loss: 0.000804
(Iteration 241 ) loss: 0.001597
(Iteration 261 ) loss: 0.000301
(Iteration 281 ) loss: 0.001031
(Iteration 301 ) loss: 0.000077
(Iteration 321 ) loss: 0.005271
(Iteration 341 ) loss: 0.001279
(Iteration 361 ) loss: 0.002916
(Iteration 381 ) loss: 0.000509
(Iteration 401 ) loss: 0.001421
(Iteration 421 ) loss: 0.000886
(Iteration 441 ) loss: 0.000111
(Iteration 461 ) loss: 0.000068
(Iteration 481 ) loss: 0.001783
(Iteration 501 ) loss: 0.001330
(Iteration 521 ) loss: 0.000386
(Iteration 541 ) loss: 0.000796
(Iteration 561 ) loss: 0.002324
(Iteration 581 ) loss: 0.001674
(Iteration 601 ) loss: 0.003591
(Iteration 621 ) loss: 0.000357
(Iteration 641 ) loss: 0.000522
(Iteration 661 ) loss: 0.000559
(Iteration 681 ) loss: 0.000229
(Iteration 701 ) loss: 0.000118
(Iteration 721 ) loss: 0.001215
(Iteration 741 ) loss: 0.000230
(Iteration 761 ) loss: 0.000065
(Iteration 781 ) loss: 0.000318
(Iteration 801 ) loss: 0.001117
(Iteration 821 ) loss: 0.000277
(Iteration 841 ) loss: 0.000803
(Iteration 861 ) loss: 0.000564
(Iteration 881 ) loss: 0.001520
(Iteration 901 ) loss: 0.001274
(Iteration 921 ) loss: 0.000159
(Iteration 941 ) loss: 0.000388
(Iteration 961 ) loss: 0.001374
(Iteration 981 ) loss: 0.000419
(Epoch 95 % 100) train loss: 0.0020644487414944006, eval loss: 0.0021046985879102967
(Iteration 1 ) loss: 0.000451
(Iteration 21 ) loss: 0.000284
(Iteration 41 ) loss: 0.001828
(Iteration 61 ) loss: 0.000267
(Iteration 81 ) loss: 0.000506
(Iteration 101 ) loss: 0.000860
(Iteration 121 ) loss: 0.000234
(Iteration 141 ) loss: 0.000813
(Iteration 161 ) loss: 0.000916
(Iteration 181 ) loss: 0.001005
(Iteration 201 ) loss: 0.001321
(Iteration 221 ) loss: 0.000629
(Iteration 241 ) loss: 0.002140
(Iteration 261 ) loss: 0.000473
(Iteration 281 ) loss: 0.000523
(Iteration 301 ) loss: 0.001711
(Iteration 321 ) loss: 0.000255
(Iteration 341 ) loss: 0.000079
(Iteration 361 ) loss: 0.000249
(Iteration 381 ) loss: 0.000751
(Iteration 401 ) loss: 0.000669
(Iteration 421 ) loss: 0.001206
(Iteration 441 ) loss: 0.000892
(Iteration 461 ) loss: 0.003042
(Iteration 481 ) loss: 0.000233
(Iteration 501 ) loss: 0.000609
(Iteration 521 ) loss: 0.001003
(Iteration 541 ) loss: 0.000089
(Iteration 561 ) loss: 0.000219
(Iteration 581 ) loss: 0.000256
(Iteration 601 ) loss: 0.003278
(Iteration 621 ) loss: 0.005281
(Iteration 641 ) loss: 0.001060
(Iteration 661 ) loss: 0.001139
(Iteration 681 ) loss: 0.001248
(Iteration 701 ) loss: 0.000380
(Iteration 721 ) loss: 0.000551
(Iteration 741 ) loss: 0.002220
(Iteration 761 ) loss: 0.000344
(Iteration 781 ) loss: 0.000364
(Iteration 801 ) loss: 0.000213
(Iteration 821 ) loss: 0.001033
(Iteration 841 ) loss: 0.000480
(Iteration 861 ) loss: 0.000649
(Iteration 881 ) loss: 0.000240
(Iteration 901 ) loss: 0.000643
(Iteration 921 ) loss: 0.000218
(Iteration 941 ) loss: 0.000131
(Iteration 961 ) loss: 0.000161
(Iteration 981 ) loss: 0.000384
(Epoch 96 % 100) train loss: 0.0022744986656699916, eval loss: 0.00204380579532839
(Iteration 1 ) loss: 0.002915
(Iteration 21 ) loss: 0.001689
(Iteration 41 ) loss: 0.002370
(Iteration 61 ) loss: 0.000804
(Iteration 81 ) loss: 0.002231
(Iteration 101 ) loss: 0.000222
(Iteration 121 ) loss: 0.000386
(Iteration 141 ) loss: 0.000768
(Iteration 161 ) loss: 0.000313
(Iteration 181 ) loss: 0.000102
(Iteration 201 ) loss: 0.000547
(Iteration 221 ) loss: 0.000981
(Iteration 241 ) loss: 0.000118
(Iteration 261 ) loss: 0.000207
(Iteration 281 ) loss: 0.000539
(Iteration 301 ) loss: 0.001721
(Iteration 321 ) loss: 0.000839
(Iteration 341 ) loss: 0.000842
(Iteration 361 ) loss: 0.001330
(Iteration 381 ) loss: 0.002187
(Iteration 401 ) loss: 0.000460
(Iteration 421 ) loss: 0.000587
(Iteration 441 ) loss: 0.001303
(Iteration 461 ) loss: 0.000514
(Iteration 481 ) loss: 0.000293
(Iteration 501 ) loss: 0.000068
(Iteration 521 ) loss: 0.001394
(Iteration 541 ) loss: 0.000825
(Iteration 561 ) loss: 0.000267
(Iteration 581 ) loss: 0.000730
(Iteration 601 ) loss: 0.000845
(Iteration 621 ) loss: 0.000348
(Iteration 641 ) loss: 0.007704
(Iteration 661 ) loss: 0.003684
(Iteration 681 ) loss: 0.000403
(Iteration 701 ) loss: 0.002915
(Iteration 721 ) loss: 0.000675
(Iteration 741 ) loss: 0.000944
(Iteration 761 ) loss: 0.000962
(Iteration 781 ) loss: 0.001081
(Iteration 801 ) loss: 0.001529
(Iteration 821 ) loss: 0.000577
(Iteration 841 ) loss: 0.000272
(Iteration 861 ) loss: 0.000217
(Iteration 881 ) loss: 0.000352
(Iteration 901 ) loss: 0.000998
(Iteration 921 ) loss: 0.000229
(Iteration 941 ) loss: 0.000231
(Iteration 961 ) loss: 0.000160
(Iteration 981 ) loss: 0.001295
(Epoch 97 % 100) train loss: 0.0013128437851834917, eval loss: 0.0012638665932738103
(Iteration 1 ) loss: 0.000937
(Iteration 21 ) loss: 0.001227
(Iteration 41 ) loss: 0.000429
(Iteration 61 ) loss: 0.000330
(Iteration 81 ) loss: 0.002229
(Iteration 101 ) loss: 0.000363
(Iteration 121 ) loss: 0.000589
(Iteration 141 ) loss: 0.000307
(Iteration 161 ) loss: 0.000253
(Iteration 181 ) loss: 0.001032
(Iteration 201 ) loss: 0.001369
(Iteration 221 ) loss: 0.000388
(Iteration 241 ) loss: 0.004070
(Iteration 261 ) loss: 0.000434
(Iteration 281 ) loss: 0.001497
(Iteration 301 ) loss: 0.000122
(Iteration 321 ) loss: 0.000138
(Iteration 341 ) loss: 0.000364
(Iteration 361 ) loss: 0.000450
(Iteration 381 ) loss: 0.000957
(Iteration 401 ) loss: 0.000806
(Iteration 421 ) loss: 0.000294
(Iteration 441 ) loss: 0.000620
(Iteration 461 ) loss: 0.000231
(Iteration 481 ) loss: 0.000354
(Iteration 501 ) loss: 0.000183
(Iteration 521 ) loss: 0.002753
(Iteration 541 ) loss: 0.003256
(Iteration 561 ) loss: 0.000456
(Iteration 581 ) loss: 0.000560
(Iteration 601 ) loss: 0.001556
(Iteration 621 ) loss: 0.000137
(Iteration 641 ) loss: 0.000209
(Iteration 661 ) loss: 0.000644
(Iteration 681 ) loss: 0.000605
(Iteration 701 ) loss: 0.001113
(Iteration 721 ) loss: 0.002147
(Iteration 741 ) loss: 0.002273
(Iteration 761 ) loss: 0.001151
(Iteration 781 ) loss: 0.001992
(Iteration 801 ) loss: 0.000612
(Iteration 821 ) loss: 0.000559
(Iteration 841 ) loss: 0.000640
(Iteration 861 ) loss: 0.000610
(Iteration 881 ) loss: 0.001116
(Iteration 901 ) loss: 0.001447
(Iteration 921 ) loss: 0.000275
(Iteration 941 ) loss: 0.000853
(Iteration 961 ) loss: 0.001247
(Iteration 981 ) loss: 0.000355
(Epoch 98 % 100) train loss: 0.0005235336433437867, eval loss: 0.0006148611765598368
(Iteration 1 ) loss: 0.001652
(Iteration 21 ) loss: 0.000255
(Iteration 41 ) loss: 0.000455
(Iteration 61 ) loss: 0.000565
(Iteration 81 ) loss: 0.004404
(Iteration 101 ) loss: 0.001972
(Iteration 121 ) loss: 0.000090
(Iteration 141 ) loss: 0.000554
(Iteration 161 ) loss: 0.002104
(Iteration 181 ) loss: 0.004213
(Iteration 201 ) loss: 0.000226
(Iteration 221 ) loss: 0.000656
(Iteration 241 ) loss: 0.000180
(Iteration 261 ) loss: 0.000328
(Iteration 281 ) loss: 0.001049
(Iteration 301 ) loss: 0.000494
(Iteration 321 ) loss: 0.000714
(Iteration 341 ) loss: 0.001250
(Iteration 361 ) loss: 0.001007
(Iteration 381 ) loss: 0.000661
(Iteration 401 ) loss: 0.000488
(Iteration 421 ) loss: 0.000463
(Iteration 441 ) loss: 0.000468
(Iteration 461 ) loss: 0.000919
(Iteration 481 ) loss: 0.001909
(Iteration 501 ) loss: 0.000663
(Iteration 521 ) loss: 0.002126
(Iteration 541 ) loss: 0.000752
(Iteration 561 ) loss: 0.001115
(Iteration 581 ) loss: 0.001880
(Iteration 601 ) loss: 0.000481
(Iteration 621 ) loss: 0.001414
(Iteration 641 ) loss: 0.003915
(Iteration 661 ) loss: 0.000973
(Iteration 681 ) loss: 0.001161
(Iteration 701 ) loss: 0.000910
(Iteration 721 ) loss: 0.000412
(Iteration 741 ) loss: 0.000402
(Iteration 761 ) loss: 0.000642
(Iteration 781 ) loss: 0.003126
(Iteration 801 ) loss: 0.000143
(Iteration 821 ) loss: 0.000795
(Iteration 841 ) loss: 0.000523
(Iteration 861 ) loss: 0.000263
(Iteration 881 ) loss: 0.001020
(Iteration 901 ) loss: 0.000361
(Iteration 921 ) loss: 0.000115
(Iteration 941 ) loss: 0.000267
(Iteration 961 ) loss: 0.000524
(Iteration 981 ) loss: 0.000011
(Epoch 99 % 100) train loss: 0.0006081134576766315, eval loss: 0.0006014266022928081
True