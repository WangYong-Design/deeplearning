(Iteration 1 ) loss: 1.108642
(Iteration 21 ) loss: 0.347179
(Iteration 41 ) loss: 1.043859
(Iteration 61 ) loss: 0.163422
(Iteration 81 ) loss: 0.548061
(Iteration 101 ) loss: 0.586549
(Iteration 121 ) loss: 0.411233
(Iteration 141 ) loss: 0.428022
(Iteration 161 ) loss: 0.581682
(Iteration 181 ) loss: 0.612984
(Iteration 201 ) loss: 0.357906
(Iteration 221 ) loss: 0.217790
(Iteration 241 ) loss: 0.518703
(Iteration 261 ) loss: 0.653203
(Iteration 281 ) loss: 0.327907
(Iteration 301 ) loss: 0.456808
(Iteration 321 ) loss: 0.348482
(Iteration 341 ) loss: 0.268867
(Iteration 361 ) loss: 0.411037
(Iteration 381 ) loss: 0.525081
(Iteration 401 ) loss: 0.517116
(Iteration 421 ) loss: 0.186658
(Iteration 441 ) loss: 0.183417
(Iteration 461 ) loss: 0.278140
(Iteration 481 ) loss: 0.386567
(Iteration 501 ) loss: 0.101080
(Iteration 521 ) loss: 0.312241
(Iteration 541 ) loss: 0.151312
(Iteration 561 ) loss: 0.186196
(Iteration 581 ) loss: 0.648635
(Iteration 601 ) loss: 0.384862
(Iteration 621 ) loss: 0.405092
(Iteration 641 ) loss: 0.112070
(Iteration 661 ) loss: 0.275895
(Iteration 681 ) loss: 0.522910
(Iteration 701 ) loss: 0.531098
(Iteration 721 ) loss: 0.366863
(Iteration 741 ) loss: 0.276151
(Iteration 761 ) loss: 0.494669
(Iteration 781 ) loss: 0.255600
(Iteration 801 ) loss: 0.311028
(Iteration 821 ) loss: 0.348216
(Iteration 841 ) loss: 0.263801
(Iteration 861 ) loss: 0.484241
(Iteration 881 ) loss: 0.193293
(Iteration 901 ) loss: 0.487104
(Iteration 921 ) loss: 0.396235
(Iteration 941 ) loss: 0.210651
(Iteration 961 ) loss: 0.480078
(Iteration 981 ) loss: 0.235895
(Epoch 0 % 100) train loss: 0.2506407998976471, eval loss: 0.24866451840525236
(Iteration 1 ) loss: 0.231922
(Iteration 21 ) loss: 0.173519
(Iteration 41 ) loss: 0.151694
(Iteration 61 ) loss: 0.282068
(Iteration 81 ) loss: 0.177852
(Iteration 101 ) loss: 0.377083
(Iteration 121 ) loss: 0.251486
(Iteration 141 ) loss: 0.097319
(Iteration 161 ) loss: 0.238095
(Iteration 181 ) loss: 0.146836
(Iteration 201 ) loss: 0.078375
(Iteration 221 ) loss: 0.165083
(Iteration 241 ) loss: 0.077154
(Iteration 261 ) loss: 0.598601
(Iteration 281 ) loss: 0.360813
(Iteration 301 ) loss: 0.237137
(Iteration 321 ) loss: 0.204429
(Iteration 341 ) loss: 0.186065
(Iteration 361 ) loss: 0.206337
(Iteration 381 ) loss: 0.218242
(Iteration 401 ) loss: 0.181890
(Iteration 421 ) loss: 0.199459
(Iteration 441 ) loss: 0.292823
(Iteration 461 ) loss: 0.131104
(Iteration 481 ) loss: 0.271694
(Iteration 501 ) loss: 0.128195
(Iteration 521 ) loss: 0.262095
(Iteration 541 ) loss: 0.154977
(Iteration 561 ) loss: 0.081897
(Iteration 581 ) loss: 0.143665
(Iteration 601 ) loss: 0.143599
(Iteration 621 ) loss: 0.161121
(Iteration 641 ) loss: 0.077110
(Iteration 661 ) loss: 0.145842
(Iteration 681 ) loss: 0.067695
(Iteration 701 ) loss: 0.139532
(Iteration 721 ) loss: 0.088437
(Iteration 741 ) loss: 0.115637
(Iteration 761 ) loss: 0.110880
(Iteration 781 ) loss: 0.103605
(Iteration 801 ) loss: 0.176836
(Iteration 821 ) loss: 0.083862
(Iteration 841 ) loss: 0.137531
(Iteration 861 ) loss: 0.078184
(Iteration 881 ) loss: 0.119761
(Iteration 901 ) loss: 0.160401
(Iteration 921 ) loss: 0.062276
(Iteration 941 ) loss: 0.293835
(Iteration 961 ) loss: 0.096288
(Iteration 981 ) loss: 0.060625
(Epoch 1 % 100) train loss: 0.1038764988274882, eval loss: 0.09874795844184728
(Iteration 1 ) loss: 0.199366
(Iteration 21 ) loss: 0.219717
(Iteration 41 ) loss: 0.125192
(Iteration 61 ) loss: 0.064235
(Iteration 81 ) loss: 0.052976
(Iteration 101 ) loss: 0.118839
(Iteration 121 ) loss: 0.141210
(Iteration 141 ) loss: 0.048662
(Iteration 161 ) loss: 0.059544
(Iteration 181 ) loss: 0.186148
(Iteration 201 ) loss: 0.039421
(Iteration 221 ) loss: 0.141687
(Iteration 241 ) loss: 0.014135
(Iteration 261 ) loss: 0.036571
(Iteration 281 ) loss: 0.044673
(Iteration 301 ) loss: 0.048558
(Iteration 321 ) loss: 0.065818
(Iteration 341 ) loss: 0.047555
(Iteration 361 ) loss: 0.166954
(Iteration 381 ) loss: 0.038615
(Iteration 401 ) loss: 0.043553
(Iteration 421 ) loss: 0.035787
(Iteration 441 ) loss: 0.041213
(Iteration 461 ) loss: 0.062162
(Iteration 481 ) loss: 0.036141
(Iteration 501 ) loss: 0.098191
(Iteration 521 ) loss: 0.187195
(Iteration 541 ) loss: 0.032767
(Iteration 561 ) loss: 0.008588
(Iteration 581 ) loss: 0.063191
(Iteration 601 ) loss: 0.055334
(Iteration 621 ) loss: 0.051930
(Iteration 641 ) loss: 0.054791
(Iteration 661 ) loss: 0.021267
(Iteration 681 ) loss: 0.028464
(Iteration 701 ) loss: 0.103813
(Iteration 721 ) loss: 0.073983
(Iteration 741 ) loss: 0.010471
(Iteration 761 ) loss: 0.040331
(Iteration 781 ) loss: 0.106850
(Iteration 801 ) loss: 0.014950
(Iteration 821 ) loss: 0.032562
(Iteration 841 ) loss: 0.127815
(Iteration 861 ) loss: 0.065549
(Iteration 881 ) loss: 0.072566
(Iteration 901 ) loss: 0.005283
(Iteration 921 ) loss: 0.063539
(Iteration 941 ) loss: 0.014214
(Iteration 961 ) loss: 0.110717
(Iteration 981 ) loss: 0.027153
(Epoch 2 % 100) train loss: 0.043326051671082014, eval loss: 0.04247220593743172
(Iteration 1 ) loss: 0.082884
(Iteration 21 ) loss: 0.006529
(Iteration 41 ) loss: 0.035571
(Iteration 61 ) loss: 0.075666
(Iteration 81 ) loss: 0.010926
(Iteration 101 ) loss: 0.007281
(Iteration 121 ) loss: 0.005284
(Iteration 141 ) loss: 0.006093
(Iteration 161 ) loss: 0.015923
(Iteration 181 ) loss: 0.077740
(Iteration 201 ) loss: 0.035576
(Iteration 221 ) loss: 0.031443
(Iteration 241 ) loss: 0.158237
(Iteration 261 ) loss: 0.024550
(Iteration 281 ) loss: 0.029244
(Iteration 301 ) loss: 0.056509
(Iteration 321 ) loss: 0.088924
(Iteration 341 ) loss: 0.063308
(Iteration 361 ) loss: 0.043346
(Iteration 381 ) loss: 0.061440
(Iteration 401 ) loss: 0.070390
(Iteration 421 ) loss: 0.024547
(Iteration 441 ) loss: 0.005621
(Iteration 461 ) loss: 0.035998
(Iteration 481 ) loss: 0.022953
(Iteration 501 ) loss: 0.109979
(Iteration 521 ) loss: 0.017758
(Iteration 541 ) loss: 0.025605
(Iteration 561 ) loss: 0.062287
(Iteration 581 ) loss: 0.099450
(Iteration 601 ) loss: 0.005691
(Iteration 621 ) loss: 0.002739
(Iteration 641 ) loss: 0.016091
(Iteration 661 ) loss: 0.003343
(Iteration 681 ) loss: 0.078527
(Iteration 701 ) loss: 0.041352
(Iteration 721 ) loss: 0.027157
(Iteration 741 ) loss: 0.027605
(Iteration 761 ) loss: 0.001779
(Iteration 781 ) loss: 0.061484
(Iteration 801 ) loss: 0.004676
(Iteration 821 ) loss: 0.035050
(Iteration 841 ) loss: 0.020627
(Iteration 861 ) loss: 0.071451
(Iteration 881 ) loss: 0.024807
(Iteration 901 ) loss: 0.006621
(Iteration 921 ) loss: 0.002308
(Iteration 941 ) loss: 0.047161
(Iteration 961 ) loss: 0.087178
(Iteration 981 ) loss: 0.028923
(Epoch 3 % 100) train loss: 0.027011383479857605, eval loss: 0.029103255592158542
(Iteration 1 ) loss: 0.009315
(Iteration 21 ) loss: 0.029270
(Iteration 41 ) loss: 0.053784
(Iteration 61 ) loss: 0.012899
(Iteration 81 ) loss: 0.025414
(Iteration 101 ) loss: 0.127422
(Iteration 121 ) loss: 0.083167
(Iteration 141 ) loss: 0.004137
(Iteration 161 ) loss: 0.093830
(Iteration 181 ) loss: 0.008717
(Iteration 201 ) loss: 0.010831
(Iteration 221 ) loss: 0.023018
(Iteration 241 ) loss: 0.004684
(Iteration 261 ) loss: 0.005404
(Iteration 281 ) loss: 0.026315
(Iteration 301 ) loss: 0.040268
(Iteration 321 ) loss: 0.096646
(Iteration 341 ) loss: 0.021667
(Iteration 361 ) loss: 0.055297
(Iteration 381 ) loss: 0.014240
(Iteration 401 ) loss: 0.003569
(Iteration 421 ) loss: 0.003882
(Iteration 441 ) loss: 0.014721
(Iteration 461 ) loss: 0.044806
(Iteration 481 ) loss: 0.050002
(Iteration 501 ) loss: 0.006526
(Iteration 521 ) loss: 0.003680
(Iteration 541 ) loss: 0.027217
(Iteration 561 ) loss: 0.018379
(Iteration 581 ) loss: 0.004076
(Iteration 601 ) loss: 0.004418
(Iteration 621 ) loss: 0.020299
(Iteration 641 ) loss: 0.006127
(Iteration 661 ) loss: 0.106875
(Iteration 681 ) loss: 0.051385
(Iteration 701 ) loss: 0.039769
(Iteration 721 ) loss: 0.016122
(Iteration 741 ) loss: 0.013357
(Iteration 761 ) loss: 0.049538
(Iteration 781 ) loss: 0.057737
(Iteration 801 ) loss: 0.011090
(Iteration 821 ) loss: 0.031883
(Iteration 841 ) loss: 0.021538
(Iteration 861 ) loss: 0.007830
(Iteration 881 ) loss: 0.012526
(Iteration 901 ) loss: 0.015667
(Iteration 921 ) loss: 0.006457
(Iteration 941 ) loss: 0.023848
(Iteration 961 ) loss: 0.033971
(Iteration 981 ) loss: 0.007837
(Epoch 4 % 100) train loss: 0.021182141801182157, eval loss: 0.023143298880688647
(Iteration 1 ) loss: 0.001445
(Iteration 21 ) loss: 0.037210
(Iteration 41 ) loss: 0.000946
(Iteration 61 ) loss: 0.016659
(Iteration 81 ) loss: 0.021913
(Iteration 101 ) loss: 0.002030
(Iteration 121 ) loss: 0.012117
(Iteration 141 ) loss: 0.036955
(Iteration 161 ) loss: 0.143988
(Iteration 181 ) loss: 0.017369
(Iteration 201 ) loss: 0.002765
(Iteration 221 ) loss: 0.038584
(Iteration 241 ) loss: 0.020130
(Iteration 261 ) loss: 0.000482
(Iteration 281 ) loss: 0.002538
(Iteration 301 ) loss: 0.022851
(Iteration 321 ) loss: 0.000928
(Iteration 341 ) loss: 0.007967
(Iteration 361 ) loss: 0.008671
(Iteration 381 ) loss: 0.004722
(Iteration 401 ) loss: 0.044568
(Iteration 421 ) loss: 0.023474
(Iteration 441 ) loss: 0.035284
(Iteration 461 ) loss: 0.005570
(Iteration 481 ) loss: 0.012975
(Iteration 501 ) loss: 0.007391
(Iteration 521 ) loss: 0.005242
(Iteration 541 ) loss: 0.023160
(Iteration 561 ) loss: 0.005193
(Iteration 581 ) loss: 0.011612
(Iteration 601 ) loss: 0.090194
(Iteration 621 ) loss: 0.033225
(Iteration 641 ) loss: 0.033818
(Iteration 661 ) loss: 0.004226
(Iteration 681 ) loss: 0.088804
(Iteration 701 ) loss: 0.008564
(Iteration 721 ) loss: 0.003536
(Iteration 741 ) loss: 0.022278
(Iteration 761 ) loss: 0.032254
(Iteration 781 ) loss: 0.010165
(Iteration 801 ) loss: 0.076860
(Iteration 821 ) loss: 0.009408
(Iteration 841 ) loss: 0.013063
(Iteration 861 ) loss: 0.017401
(Iteration 881 ) loss: 0.009448
(Iteration 901 ) loss: 0.017107
(Iteration 921 ) loss: 0.041670
(Iteration 941 ) loss: 0.021513
(Iteration 961 ) loss: 0.019655
(Iteration 981 ) loss: 0.001852
(Epoch 5 % 100) train loss: 0.024097787758050444, eval loss: 0.020380804701716354
(Iteration 1 ) loss: 0.043737
(Iteration 21 ) loss: 0.015387
(Iteration 41 ) loss: 0.003332
(Iteration 61 ) loss: 0.007873
(Iteration 81 ) loss: 0.002821
(Iteration 101 ) loss: 0.009455
(Iteration 121 ) loss: 0.047258
(Iteration 141 ) loss: 0.025111
(Iteration 161 ) loss: 0.005052
(Iteration 181 ) loss: 0.020622
(Iteration 201 ) loss: 0.007766
(Iteration 221 ) loss: 0.015886
(Iteration 241 ) loss: 0.070241
(Iteration 261 ) loss: 0.017651
(Iteration 281 ) loss: 0.002235
(Iteration 301 ) loss: 0.049198
(Iteration 321 ) loss: 0.036237
(Iteration 341 ) loss: 0.030762
(Iteration 361 ) loss: 0.008573
(Iteration 381 ) loss: 0.034977
(Iteration 401 ) loss: 0.046768
(Iteration 421 ) loss: 0.028545
(Iteration 441 ) loss: 0.009324
(Iteration 461 ) loss: 0.003524
(Iteration 481 ) loss: 0.045117
(Iteration 501 ) loss: 0.057465
(Iteration 521 ) loss: 0.007389
(Iteration 541 ) loss: 0.038017
(Iteration 561 ) loss: 0.007983
(Iteration 581 ) loss: 0.010575
(Iteration 601 ) loss: 0.020729
(Iteration 621 ) loss: 0.064383
(Iteration 641 ) loss: 0.008992
(Iteration 661 ) loss: 0.044256
(Iteration 681 ) loss: 0.012052
(Iteration 701 ) loss: 0.001704
(Iteration 721 ) loss: 0.014911
(Iteration 741 ) loss: 0.002427
(Iteration 761 ) loss: 0.025212
(Iteration 781 ) loss: 0.059985
(Iteration 801 ) loss: 0.067465
(Iteration 821 ) loss: 0.047761
(Iteration 841 ) loss: 0.009627
(Iteration 861 ) loss: 0.005347
(Iteration 881 ) loss: 0.018516
(Iteration 901 ) loss: 0.016941
(Iteration 921 ) loss: 0.026669
(Iteration 941 ) loss: 0.010001
(Iteration 961 ) loss: 0.006178
(Iteration 981 ) loss: 0.003457
(Epoch 6 % 100) train loss: 0.027843200753854404, eval loss: 0.02671223911223796
(Iteration 1 ) loss: 0.014239
(Iteration 21 ) loss: 0.016990
(Iteration 41 ) loss: 0.006252
(Iteration 61 ) loss: 0.006996
(Iteration 81 ) loss: 0.034178
(Iteration 101 ) loss: 0.072993
(Iteration 121 ) loss: 0.005803
(Iteration 141 ) loss: 0.005125
(Iteration 161 ) loss: 0.021577
(Iteration 181 ) loss: 0.012288
(Iteration 201 ) loss: 0.021446
(Iteration 221 ) loss: 0.020744
(Iteration 241 ) loss: 0.027447
(Iteration 261 ) loss: 0.078848
(Iteration 281 ) loss: 0.035736
(Iteration 301 ) loss: 0.058660
(Iteration 321 ) loss: 0.053272
(Iteration 341 ) loss: 0.021606
(Iteration 361 ) loss: 0.009739
(Iteration 381 ) loss: 0.030521
(Iteration 401 ) loss: 0.001678
(Iteration 421 ) loss: 0.027053
(Iteration 441 ) loss: 0.023643
(Iteration 461 ) loss: 0.037293
(Iteration 481 ) loss: 0.007972
(Iteration 501 ) loss: 0.016530
(Iteration 521 ) loss: 0.004927
(Iteration 541 ) loss: 0.001638
(Iteration 561 ) loss: 0.034007
(Iteration 581 ) loss: 0.016467
(Iteration 601 ) loss: 0.004780
(Iteration 621 ) loss: 0.000592
(Iteration 641 ) loss: 0.047988
(Iteration 661 ) loss: 0.006613
(Iteration 681 ) loss: 0.000554
(Iteration 701 ) loss: 0.010571
(Iteration 721 ) loss: 0.000822
(Iteration 741 ) loss: 0.014706
(Iteration 761 ) loss: 0.010319
(Iteration 781 ) loss: 0.003919
(Iteration 801 ) loss: 0.026847
(Iteration 821 ) loss: 0.027872
(Iteration 841 ) loss: 0.001976
(Iteration 861 ) loss: 0.016996
(Iteration 881 ) loss: 0.084830
(Iteration 901 ) loss: 0.006092
(Iteration 921 ) loss: 0.022023
(Iteration 941 ) loss: 0.073730
(Iteration 961 ) loss: 0.000284
(Iteration 981 ) loss: 0.010884
(Epoch 7 % 100) train loss: 0.017223275411507824, eval loss: 0.01929357094999242
(Iteration 1 ) loss: 0.000997
(Iteration 21 ) loss: 0.029836
(Iteration 41 ) loss: 0.001029
(Iteration 61 ) loss: 0.067367
(Iteration 81 ) loss: 0.023883
(Iteration 101 ) loss: 0.021378
(Iteration 121 ) loss: 0.015170
(Iteration 141 ) loss: 0.010493
(Iteration 161 ) loss: 0.001675
(Iteration 181 ) loss: 0.067158
(Iteration 201 ) loss: 0.012400
(Iteration 221 ) loss: 0.013280
(Iteration 241 ) loss: 0.003997
(Iteration 261 ) loss: 0.037197
(Iteration 281 ) loss: 0.010529
(Iteration 301 ) loss: 0.026625
(Iteration 321 ) loss: 0.001253
(Iteration 341 ) loss: 0.030468
(Iteration 361 ) loss: 0.069836
(Iteration 381 ) loss: 0.000492
(Iteration 401 ) loss: 0.038644
(Iteration 421 ) loss: 0.019378
(Iteration 441 ) loss: 0.003222
(Iteration 461 ) loss: 0.013001
(Iteration 481 ) loss: 0.015767
(Iteration 501 ) loss: 0.052089
(Iteration 521 ) loss: 0.001846
(Iteration 541 ) loss: 0.077478
(Iteration 561 ) loss: 0.002448
(Iteration 581 ) loss: 0.010860
(Iteration 601 ) loss: 0.015492
(Iteration 621 ) loss: 0.002185
(Iteration 641 ) loss: 0.001538
(Iteration 661 ) loss: 0.002866
(Iteration 681 ) loss: 0.005209
(Iteration 701 ) loss: 0.035123
(Iteration 721 ) loss: 0.040876
(Iteration 741 ) loss: 0.048818
(Iteration 761 ) loss: 0.053374
(Iteration 781 ) loss: 0.021826
(Iteration 801 ) loss: 0.050020
(Iteration 821 ) loss: 0.014273
(Iteration 841 ) loss: 0.020018
(Iteration 861 ) loss: 0.011183
(Iteration 881 ) loss: 0.006911
(Iteration 901 ) loss: 0.008478
(Iteration 921 ) loss: 0.001596
(Iteration 941 ) loss: 0.041075
(Iteration 961 ) loss: 0.012295
(Iteration 981 ) loss: 0.037707
(Epoch 8 % 100) train loss: 0.01569601050221879, eval loss: 0.017837200948346878
(Iteration 1 ) loss: 0.042729
(Iteration 21 ) loss: 0.022409
(Iteration 41 ) loss: 0.011110
(Iteration 61 ) loss: 0.003379
(Iteration 81 ) loss: 0.087593
(Iteration 101 ) loss: 0.049159
(Iteration 121 ) loss: 0.014648
(Iteration 141 ) loss: 0.020392
(Iteration 161 ) loss: 0.019038
(Iteration 181 ) loss: 0.017340
(Iteration 201 ) loss: 0.013202
(Iteration 221 ) loss: 0.023245
(Iteration 241 ) loss: 0.016315
(Iteration 261 ) loss: 0.002150
(Iteration 281 ) loss: 0.008858
(Iteration 301 ) loss: 0.023524
(Iteration 321 ) loss: 0.010070
(Iteration 341 ) loss: 0.011125
(Iteration 361 ) loss: 0.002266
(Iteration 381 ) loss: 0.006313
(Iteration 401 ) loss: 0.001851
(Iteration 421 ) loss: 0.003928
(Iteration 441 ) loss: 0.001205
(Iteration 461 ) loss: 0.072026
(Iteration 481 ) loss: 0.004664
(Iteration 501 ) loss: 0.080947
(Iteration 521 ) loss: 0.034470
(Iteration 541 ) loss: 0.000464
(Iteration 561 ) loss: 0.000790
(Iteration 581 ) loss: 0.038715
(Iteration 601 ) loss: 0.029017
(Iteration 621 ) loss: 0.008812
(Iteration 641 ) loss: 0.009396
(Iteration 661 ) loss: 0.002834
(Iteration 681 ) loss: 0.006515
(Iteration 701 ) loss: 0.004089
(Iteration 721 ) loss: 0.013291
(Iteration 741 ) loss: 0.010857
(Iteration 761 ) loss: 0.039284
(Iteration 781 ) loss: 0.026754
(Iteration 801 ) loss: 0.004846
(Iteration 821 ) loss: 0.017848
(Iteration 841 ) loss: 0.000918
(Iteration 861 ) loss: 0.000906
(Iteration 881 ) loss: 0.001457
(Iteration 901 ) loss: 0.003706
(Iteration 921 ) loss: 0.003540
(Iteration 941 ) loss: 0.008519
(Iteration 961 ) loss: 0.006992
(Iteration 981 ) loss: 0.006225
(Epoch 9 % 100) train loss: 0.017875091981011934, eval loss: 0.017490030747232883
(Iteration 1 ) loss: 0.013584
(Iteration 21 ) loss: 0.024062
(Iteration 41 ) loss: 0.045644
(Iteration 61 ) loss: 0.003514
(Iteration 81 ) loss: 0.006101
(Iteration 101 ) loss: 0.023382
(Iteration 121 ) loss: 0.021348
(Iteration 141 ) loss: 0.000867
(Iteration 161 ) loss: 0.003558
(Iteration 181 ) loss: 0.001337
(Iteration 201 ) loss: 0.026693
(Iteration 221 ) loss: 0.046451
(Iteration 241 ) loss: 0.022769
(Iteration 261 ) loss: 0.001312
(Iteration 281 ) loss: 0.002116
(Iteration 301 ) loss: 0.012360
(Iteration 321 ) loss: 0.021681
(Iteration 341 ) loss: 0.003052
(Iteration 361 ) loss: 0.002025
(Iteration 381 ) loss: 0.001978
(Iteration 401 ) loss: 0.037825
(Iteration 421 ) loss: 0.056024
(Iteration 441 ) loss: 0.014771
(Iteration 461 ) loss: 0.001937
(Iteration 481 ) loss: 0.011563
(Iteration 501 ) loss: 0.006539
(Iteration 521 ) loss: 0.010705
(Iteration 541 ) loss: 0.005460
(Iteration 561 ) loss: 0.025555
(Iteration 581 ) loss: 0.003660
(Iteration 601 ) loss: 0.006961
(Iteration 621 ) loss: 0.014337
(Iteration 641 ) loss: 0.022827
(Iteration 661 ) loss: 0.007993
(Iteration 681 ) loss: 0.001560
(Iteration 701 ) loss: 0.028599
(Iteration 721 ) loss: 0.007545
(Iteration 741 ) loss: 0.008764
(Iteration 761 ) loss: 0.009308
(Iteration 781 ) loss: 0.004930
(Iteration 801 ) loss: 0.001208
(Iteration 821 ) loss: 0.007185
(Iteration 841 ) loss: 0.008020
(Iteration 861 ) loss: 0.005077
(Iteration 881 ) loss: 0.031277
(Iteration 901 ) loss: 0.007109
(Iteration 921 ) loss: 0.006002
(Iteration 941 ) loss: 0.055083
(Iteration 961 ) loss: 0.017491
(Iteration 981 ) loss: 0.002999
(Epoch 10 % 100) train loss: 0.018521510922894002, eval loss: 0.016386339662870335
(Iteration 1 ) loss: 0.029737
(Iteration 21 ) loss: 0.008391
(Iteration 41 ) loss: 0.004202
(Iteration 61 ) loss: 0.035147
(Iteration 81 ) loss: 0.001719
(Iteration 101 ) loss: 0.001977
(Iteration 121 ) loss: 0.004140
(Iteration 141 ) loss: 0.012439
(Iteration 161 ) loss: 0.011139
(Iteration 181 ) loss: 0.004483
(Iteration 201 ) loss: 0.028268
(Iteration 221 ) loss: 0.036204
(Iteration 241 ) loss: 0.002309
(Iteration 261 ) loss: 0.000661
(Iteration 281 ) loss: 0.003072
(Iteration 301 ) loss: 0.034295
(Iteration 321 ) loss: 0.002904
(Iteration 341 ) loss: 0.007900
(Iteration 361 ) loss: 0.001640
(Iteration 381 ) loss: 0.007547
(Iteration 401 ) loss: 0.162688
(Iteration 421 ) loss: 0.001910
(Iteration 441 ) loss: 0.000071
(Iteration 461 ) loss: 0.000416
(Iteration 481 ) loss: 0.023478
(Iteration 501 ) loss: 0.000922
(Iteration 521 ) loss: 0.010419
(Iteration 541 ) loss: 0.002415
(Iteration 561 ) loss: 0.012498
(Iteration 581 ) loss: 0.001609
(Iteration 601 ) loss: 0.007394
(Iteration 621 ) loss: 0.004421
(Iteration 641 ) loss: 0.004319
(Iteration 661 ) loss: 0.010836
(Iteration 681 ) loss: 0.004582
(Iteration 701 ) loss: 0.016162
(Iteration 721 ) loss: 0.004661
(Iteration 741 ) loss: 0.056410
(Iteration 761 ) loss: 0.032048
(Iteration 781 ) loss: 0.005674
(Iteration 801 ) loss: 0.054739
(Iteration 821 ) loss: 0.073849
(Iteration 841 ) loss: 0.047965
(Iteration 861 ) loss: 0.002316
(Iteration 881 ) loss: 0.045128
(Iteration 901 ) loss: 0.006118
(Iteration 921 ) loss: 0.016839
(Iteration 941 ) loss: 0.058734
(Iteration 961 ) loss: 0.012226
(Iteration 981 ) loss: 0.009894
(Epoch 11 % 100) train loss: 0.01607535076416616, eval loss: 0.015673236187769106
(Iteration 1 ) loss: 0.007069
(Iteration 21 ) loss: 0.022344
(Iteration 41 ) loss: 0.009242
(Iteration 61 ) loss: 0.010564
(Iteration 81 ) loss: 0.000572
(Iteration 101 ) loss: 0.001767
(Iteration 121 ) loss: 0.048321
(Iteration 141 ) loss: 0.025560
(Iteration 161 ) loss: 0.050472
(Iteration 181 ) loss: 0.002683
(Iteration 201 ) loss: 0.017577
(Iteration 221 ) loss: 0.004453
(Iteration 241 ) loss: 0.004773
(Iteration 261 ) loss: 0.005945
(Iteration 281 ) loss: 0.011160
(Iteration 301 ) loss: 0.031732
(Iteration 321 ) loss: 0.013343
(Iteration 341 ) loss: 0.003569
(Iteration 361 ) loss: 0.019934
(Iteration 381 ) loss: 0.000903
(Iteration 401 ) loss: 0.037877
(Iteration 421 ) loss: 0.009201
(Iteration 441 ) loss: 0.030702
(Iteration 461 ) loss: 0.008204
(Iteration 481 ) loss: 0.003655
(Iteration 501 ) loss: 0.003340
(Iteration 521 ) loss: 0.006401
(Iteration 541 ) loss: 0.000312
(Iteration 561 ) loss: 0.001171
(Iteration 581 ) loss: 0.006041
(Iteration 601 ) loss: 0.003699
(Iteration 621 ) loss: 0.022747
(Iteration 641 ) loss: 0.003338
(Iteration 661 ) loss: 0.007547
(Iteration 681 ) loss: 0.021382
(Iteration 701 ) loss: 0.017195
(Iteration 721 ) loss: 0.011439
(Iteration 741 ) loss: 0.017530
(Iteration 761 ) loss: 0.015046
(Iteration 781 ) loss: 0.009030
(Iteration 801 ) loss: 0.041935
(Iteration 821 ) loss: 0.004423
(Iteration 841 ) loss: 0.012359
(Iteration 861 ) loss: 0.018765
(Iteration 881 ) loss: 0.002300
(Iteration 901 ) loss: 0.000661
(Iteration 921 ) loss: 0.008736
(Iteration 941 ) loss: 0.010061
(Iteration 961 ) loss: 0.019982
(Iteration 981 ) loss: 0.019744
(Epoch 12 % 100) train loss: 0.013513651113487393, eval loss: 0.010413337180619315
(Iteration 1 ) loss: 0.003308
(Iteration 21 ) loss: 0.000267
(Iteration 41 ) loss: 0.021338
(Iteration 61 ) loss: 0.002497
(Iteration 81 ) loss: 0.013048
(Iteration 101 ) loss: 0.043328
(Iteration 121 ) loss: 0.032021
(Iteration 141 ) loss: 0.001122
(Iteration 161 ) loss: 0.008495
(Iteration 181 ) loss: 0.009899
(Iteration 201 ) loss: 0.007906
(Iteration 221 ) loss: 0.001152
(Iteration 241 ) loss: 0.005204
(Iteration 261 ) loss: 0.008334
(Iteration 281 ) loss: 0.006734
(Iteration 301 ) loss: 0.000669
(Iteration 321 ) loss: 0.001692
(Iteration 341 ) loss: 0.010774
(Iteration 361 ) loss: 0.001669
(Iteration 381 ) loss: 0.004795
(Iteration 401 ) loss: 0.011546
(Iteration 421 ) loss: 0.017513
(Iteration 441 ) loss: 0.006807
(Iteration 461 ) loss: 0.003648
(Iteration 481 ) loss: 0.006106
(Iteration 501 ) loss: 0.056225
(Iteration 521 ) loss: 0.005228
(Iteration 541 ) loss: 0.015778
(Iteration 561 ) loss: 0.020747
(Iteration 581 ) loss: 0.007445
(Iteration 601 ) loss: 0.020510
(Iteration 621 ) loss: 0.010426
(Iteration 641 ) loss: 0.016336
(Iteration 661 ) loss: 0.045131
(Iteration 681 ) loss: 0.006672
(Iteration 701 ) loss: 0.001908
(Iteration 721 ) loss: 0.006182
(Iteration 741 ) loss: 0.008333
(Iteration 761 ) loss: 0.005094
(Iteration 781 ) loss: 0.002992
(Iteration 801 ) loss: 0.019435
(Iteration 821 ) loss: 0.012707
(Iteration 841 ) loss: 0.008443
(Iteration 861 ) loss: 0.037902
(Iteration 881 ) loss: 0.010609
(Iteration 901 ) loss: 0.012732
(Iteration 921 ) loss: 0.000249
(Iteration 941 ) loss: 0.024055
(Iteration 961 ) loss: 0.003981
(Iteration 981 ) loss: 0.000830
(Epoch 13 % 100) train loss: 0.011107546968172944, eval loss: 0.01240484397345288
(Iteration 1 ) loss: 0.016667
(Iteration 21 ) loss: 0.004572
(Iteration 41 ) loss: 0.003889
(Iteration 61 ) loss: 0.012678
(Iteration 81 ) loss: 0.019580
(Iteration 101 ) loss: 0.001607
(Iteration 121 ) loss: 0.010039
(Iteration 141 ) loss: 0.004332
(Iteration 161 ) loss: 0.001076
(Iteration 181 ) loss: 0.003601
(Iteration 201 ) loss: 0.004939
(Iteration 221 ) loss: 0.002897
(Iteration 241 ) loss: 0.020333
(Iteration 261 ) loss: 0.021851
(Iteration 281 ) loss: 0.000274
(Iteration 301 ) loss: 0.006949
(Iteration 321 ) loss: 0.003682
(Iteration 341 ) loss: 0.008962
(Iteration 361 ) loss: 0.003355
(Iteration 381 ) loss: 0.003649
(Iteration 401 ) loss: 0.003812
(Iteration 421 ) loss: 0.001092
(Iteration 441 ) loss: 0.008757
(Iteration 461 ) loss: 0.004239
(Iteration 481 ) loss: 0.016639
(Iteration 501 ) loss: 0.001683
(Iteration 521 ) loss: 0.006160
(Iteration 541 ) loss: 0.033948
(Iteration 561 ) loss: 0.009139
(Iteration 581 ) loss: 0.026694
(Iteration 601 ) loss: 0.007790
(Iteration 621 ) loss: 0.001147
(Iteration 641 ) loss: 0.014119
(Iteration 661 ) loss: 0.019042
(Iteration 681 ) loss: 0.005377
(Iteration 701 ) loss: 0.002563
(Iteration 721 ) loss: 0.010558
(Iteration 741 ) loss: 0.019402
(Iteration 761 ) loss: 0.002857
(Iteration 781 ) loss: 0.003175
(Iteration 801 ) loss: 0.010976
(Iteration 821 ) loss: 0.002698
(Iteration 841 ) loss: 0.009500
(Iteration 861 ) loss: 0.013627
(Iteration 881 ) loss: 0.004616
(Iteration 901 ) loss: 0.021119
(Iteration 921 ) loss: 0.001432
(Iteration 941 ) loss: 0.004944
(Iteration 961 ) loss: 0.000326
(Iteration 981 ) loss: 0.001702
(Epoch 14 % 100) train loss: 0.005716352526256466, eval loss: 0.005764139414507267
(Iteration 1 ) loss: 0.004641
(Iteration 21 ) loss: 0.021340
(Iteration 41 ) loss: 0.008671
(Iteration 61 ) loss: 0.003597
(Iteration 81 ) loss: 0.001784
(Iteration 101 ) loss: 0.000899
(Iteration 121 ) loss: 0.004226
(Iteration 141 ) loss: 0.006254
(Iteration 161 ) loss: 0.008680
(Iteration 181 ) loss: 0.018014
(Iteration 201 ) loss: 0.007510
(Iteration 221 ) loss: 0.004370
(Iteration 241 ) loss: 0.008005
(Iteration 261 ) loss: 0.017485
(Iteration 281 ) loss: 0.004090
(Iteration 301 ) loss: 0.001946
(Iteration 321 ) loss: 0.000384
(Iteration 341 ) loss: 0.025531
(Iteration 361 ) loss: 0.000862
(Iteration 381 ) loss: 0.012450
(Iteration 401 ) loss: 0.023876
(Iteration 421 ) loss: 0.015118
(Iteration 441 ) loss: 0.002662
(Iteration 461 ) loss: 0.017211
(Iteration 481 ) loss: 0.023149
(Iteration 501 ) loss: 0.004595
(Iteration 521 ) loss: 0.003083
(Iteration 541 ) loss: 0.000549
(Iteration 561 ) loss: 0.001987
(Iteration 581 ) loss: 0.001913
(Iteration 601 ) loss: 0.001471
(Iteration 621 ) loss: 0.007526
(Iteration 641 ) loss: 0.006872
(Iteration 661 ) loss: 0.002336
(Iteration 681 ) loss: 0.010114
(Iteration 701 ) loss: 0.005980
(Iteration 721 ) loss: 0.000618
(Iteration 741 ) loss: 0.007262
(Iteration 761 ) loss: 0.001383
(Iteration 781 ) loss: 0.013514
(Iteration 801 ) loss: 0.005392
(Iteration 821 ) loss: 0.000437
(Iteration 841 ) loss: 0.008857
(Iteration 861 ) loss: 0.002585
(Iteration 881 ) loss: 0.011823
(Iteration 901 ) loss: 0.002633
(Iteration 921 ) loss: 0.003550
(Iteration 941 ) loss: 0.022062
(Iteration 961 ) loss: 0.001717
(Iteration 981 ) loss: 0.004416
(Epoch 15 % 100) train loss: 0.006958562101830962, eval loss: 0.006923000036061732
(Iteration 1 ) loss: 0.024477
(Iteration 21 ) loss: 0.002092
(Iteration 41 ) loss: 0.014474
(Iteration 61 ) loss: 0.002044
(Iteration 81 ) loss: 0.000669
(Iteration 101 ) loss: 0.004079
(Iteration 121 ) loss: 0.000661
(Iteration 141 ) loss: 0.002293
(Iteration 161 ) loss: 0.006841
(Iteration 181 ) loss: 0.001012
(Iteration 201 ) loss: 0.024161
(Iteration 221 ) loss: 0.006143
(Iteration 241 ) loss: 0.010803
(Iteration 261 ) loss: 0.008531
(Iteration 281 ) loss: 0.009399
(Iteration 301 ) loss: 0.002764
(Iteration 321 ) loss: 0.010235
(Iteration 341 ) loss: 0.004464
(Iteration 361 ) loss: 0.000782
(Iteration 381 ) loss: 0.001428
(Iteration 401 ) loss: 0.003854
(Iteration 421 ) loss: 0.014365
(Iteration 441 ) loss: 0.002474
(Iteration 461 ) loss: 0.004769
(Iteration 481 ) loss: 0.001175
(Iteration 501 ) loss: 0.025245
(Iteration 521 ) loss: 0.002536
(Iteration 541 ) loss: 0.005069
(Iteration 561 ) loss: 0.019379
(Iteration 581 ) loss: 0.005306
(Iteration 601 ) loss: 0.008015
(Iteration 621 ) loss: 0.004193
(Iteration 641 ) loss: 0.002535
(Iteration 661 ) loss: 0.010681
(Iteration 681 ) loss: 0.001711
(Iteration 701 ) loss: 0.000554
(Iteration 721 ) loss: 0.000363
(Iteration 741 ) loss: 0.011835
(Iteration 761 ) loss: 0.003303
(Iteration 781 ) loss: 0.014398
(Iteration 801 ) loss: 0.000736
(Iteration 821 ) loss: 0.005980
(Iteration 841 ) loss: 0.011196
(Iteration 861 ) loss: 0.003997
(Iteration 881 ) loss: 0.008285
(Iteration 901 ) loss: 0.007328
(Iteration 921 ) loss: 0.014203
(Iteration 941 ) loss: 0.003392
(Iteration 961 ) loss: 0.000889
(Iteration 981 ) loss: 0.001704
(Epoch 16 % 100) train loss: 0.006330046880211506, eval loss: 0.0071345449662082614
(Iteration 1 ) loss: 0.019591
(Iteration 21 ) loss: 0.004409
(Iteration 41 ) loss: 0.000834
(Iteration 61 ) loss: 0.000120
(Iteration 81 ) loss: 0.012657
(Iteration 101 ) loss: 0.019582
(Iteration 121 ) loss: 0.004112
(Iteration 141 ) loss: 0.002492
(Iteration 161 ) loss: 0.004786
(Iteration 181 ) loss: 0.004400
(Iteration 201 ) loss: 0.004904
(Iteration 221 ) loss: 0.001848
(Iteration 241 ) loss: 0.000593
(Iteration 261 ) loss: 0.000363
(Iteration 281 ) loss: 0.017977
(Iteration 301 ) loss: 0.009459
(Iteration 321 ) loss: 0.018233
(Iteration 341 ) loss: 0.011533
(Iteration 361 ) loss: 0.008446
(Iteration 381 ) loss: 0.001548
(Iteration 401 ) loss: 0.003783
(Iteration 421 ) loss: 0.013222
(Iteration 441 ) loss: 0.001866
(Iteration 461 ) loss: 0.001510
(Iteration 481 ) loss: 0.001762
(Iteration 501 ) loss: 0.001980
(Iteration 521 ) loss: 0.007255
(Iteration 541 ) loss: 0.004023
(Iteration 561 ) loss: 0.002173
(Iteration 581 ) loss: 0.000527
(Iteration 601 ) loss: 0.001030
(Iteration 621 ) loss: 0.006095
(Iteration 641 ) loss: 0.021375
(Iteration 661 ) loss: 0.001513
(Iteration 681 ) loss: 0.008241
(Iteration 701 ) loss: 0.000947
(Iteration 721 ) loss: 0.002662
(Iteration 741 ) loss: 0.002903
(Iteration 761 ) loss: 0.019885
(Iteration 781 ) loss: 0.005890
(Iteration 801 ) loss: 0.002636
(Iteration 821 ) loss: 0.002123
(Iteration 841 ) loss: 0.001293
(Iteration 861 ) loss: 0.014966
(Iteration 881 ) loss: 0.012874
(Iteration 901 ) loss: 0.005296
(Iteration 921 ) loss: 0.000807
(Iteration 941 ) loss: 0.006196
(Iteration 961 ) loss: 0.004206
(Iteration 981 ) loss: 0.002882
(Epoch 17 % 100) train loss: 0.003301484536092321, eval loss: 0.0038230318486922963
(Iteration 1 ) loss: 0.001713
(Iteration 21 ) loss: 0.002944
(Iteration 41 ) loss: 0.001859
(Iteration 61 ) loss: 0.000445
(Iteration 81 ) loss: 0.014959
(Iteration 101 ) loss: 0.000375
(Iteration 121 ) loss: 0.001960
(Iteration 141 ) loss: 0.007588
(Iteration 161 ) loss: 0.013963
(Iteration 181 ) loss: 0.007895
(Iteration 201 ) loss: 0.002936
(Iteration 221 ) loss: 0.000308
(Iteration 241 ) loss: 0.000992
(Iteration 261 ) loss: 0.002242
(Iteration 281 ) loss: 0.004977
(Iteration 301 ) loss: 0.001852
(Iteration 321 ) loss: 0.005644
(Iteration 341 ) loss: 0.002858
(Iteration 361 ) loss: 0.010915
(Iteration 381 ) loss: 0.002415
(Iteration 401 ) loss: 0.009217
(Iteration 421 ) loss: 0.003040
(Iteration 441 ) loss: 0.003199
(Iteration 461 ) loss: 0.000994
(Iteration 481 ) loss: 0.003259
(Iteration 501 ) loss: 0.007585
(Iteration 521 ) loss: 0.008961
(Iteration 541 ) loss: 0.001783
(Iteration 561 ) loss: 0.003791
(Iteration 581 ) loss: 0.000674
(Iteration 601 ) loss: 0.007195
(Iteration 621 ) loss: 0.004049
(Iteration 641 ) loss: 0.001667
(Iteration 661 ) loss: 0.022376
(Iteration 681 ) loss: 0.005124
(Iteration 701 ) loss: 0.002774
(Iteration 721 ) loss: 0.003049
(Iteration 741 ) loss: 0.019337
(Iteration 761 ) loss: 0.005157
(Iteration 781 ) loss: 0.001808
(Iteration 801 ) loss: 0.009971
(Iteration 821 ) loss: 0.002401
(Iteration 841 ) loss: 0.005700
(Iteration 861 ) loss: 0.010134
(Iteration 881 ) loss: 0.000944
(Iteration 901 ) loss: 0.004216
(Iteration 921 ) loss: 0.001562
(Iteration 941 ) loss: 0.002064
(Iteration 961 ) loss: 0.007423
(Iteration 981 ) loss: 0.001578
(Epoch 18 % 100) train loss: 0.002905349436111076, eval loss: 0.0029364367124334405
(Iteration 1 ) loss: 0.003027
(Iteration 21 ) loss: 0.004430
(Iteration 41 ) loss: 0.003489
(Iteration 61 ) loss: 0.008067
(Iteration 81 ) loss: 0.006238
(Iteration 101 ) loss: 0.002224
(Iteration 121 ) loss: 0.004962
(Iteration 141 ) loss: 0.004700
(Iteration 161 ) loss: 0.000325
(Iteration 181 ) loss: 0.002916
(Iteration 201 ) loss: 0.024508
(Iteration 221 ) loss: 0.003561
(Iteration 241 ) loss: 0.001308
(Iteration 261 ) loss: 0.000430
(Iteration 281 ) loss: 0.009851
(Iteration 301 ) loss: 0.001127
(Iteration 321 ) loss: 0.010750
(Iteration 341 ) loss: 0.009821
(Iteration 361 ) loss: 0.004788
(Iteration 381 ) loss: 0.004189
(Iteration 401 ) loss: 0.002436
(Iteration 421 ) loss: 0.008052
(Iteration 441 ) loss: 0.005058
(Iteration 461 ) loss: 0.000869
(Iteration 481 ) loss: 0.004551
(Iteration 501 ) loss: 0.003444
(Iteration 521 ) loss: 0.002918
(Iteration 541 ) loss: 0.002835
(Iteration 561 ) loss: 0.007361
(Iteration 581 ) loss: 0.008208
(Iteration 601 ) loss: 0.000684
(Iteration 621 ) loss: 0.002778
(Iteration 641 ) loss: 0.001527
(Iteration 661 ) loss: 0.002016
(Iteration 681 ) loss: 0.006898
(Iteration 701 ) loss: 0.002960
(Iteration 721 ) loss: 0.001759
(Iteration 741 ) loss: 0.002909
(Iteration 761 ) loss: 0.005090
(Iteration 781 ) loss: 0.002389
(Iteration 801 ) loss: 0.002944
(Iteration 821 ) loss: 0.003093
(Iteration 841 ) loss: 0.001705
(Iteration 861 ) loss: 0.004041
(Iteration 881 ) loss: 0.001805
(Iteration 901 ) loss: 0.001418
(Iteration 921 ) loss: 0.000217
(Iteration 941 ) loss: 0.000862
(Iteration 961 ) loss: 0.004675
(Iteration 981 ) loss: 0.004529
(Epoch 19 % 100) train loss: 0.0018635474026266567, eval loss: 0.0018306684470061007
(Iteration 1 ) loss: 0.000439
(Iteration 21 ) loss: 0.000971
(Iteration 41 ) loss: 0.004314
(Iteration 61 ) loss: 0.001703
(Iteration 81 ) loss: 0.011375
(Iteration 101 ) loss: 0.005068
(Iteration 121 ) loss: 0.007264
(Iteration 141 ) loss: 0.001127
(Iteration 161 ) loss: 0.004896
(Iteration 181 ) loss: 0.005092
(Iteration 201 ) loss: 0.008599
(Iteration 221 ) loss: 0.000364
(Iteration 241 ) loss: 0.000452
(Iteration 261 ) loss: 0.001616
(Iteration 281 ) loss: 0.002394
(Iteration 301 ) loss: 0.000975
(Iteration 321 ) loss: 0.002408
(Iteration 341 ) loss: 0.000228
(Iteration 361 ) loss: 0.000580
(Iteration 381 ) loss: 0.000400
(Iteration 401 ) loss: 0.001392
(Iteration 421 ) loss: 0.002615
(Iteration 441 ) loss: 0.001251
(Iteration 461 ) loss: 0.001087
(Iteration 481 ) loss: 0.001251
(Iteration 501 ) loss: 0.008164
(Iteration 521 ) loss: 0.000343
(Iteration 541 ) loss: 0.001378
(Iteration 561 ) loss: 0.002493
(Iteration 581 ) loss: 0.004495
(Iteration 601 ) loss: 0.001366
(Iteration 621 ) loss: 0.003214
(Iteration 641 ) loss: 0.001527
(Iteration 661 ) loss: 0.000826
(Iteration 681 ) loss: 0.006711
(Iteration 701 ) loss: 0.001361
(Iteration 721 ) loss: 0.019273
(Iteration 741 ) loss: 0.002538
(Iteration 761 ) loss: 0.006862
(Iteration 781 ) loss: 0.006255
(Iteration 801 ) loss: 0.001535
(Iteration 821 ) loss: 0.007485
(Iteration 841 ) loss: 0.000395
(Iteration 861 ) loss: 0.001093
(Iteration 881 ) loss: 0.013896
(Iteration 901 ) loss: 0.002469
(Iteration 921 ) loss: 0.001892
(Iteration 941 ) loss: 0.000763
(Iteration 961 ) loss: 0.001130
(Iteration 981 ) loss: 0.000885
(Epoch 20 % 100) train loss: 0.007189086999609947, eval loss: 0.007032941696229151
(Iteration 1 ) loss: 0.004250
(Iteration 21 ) loss: 0.017502
(Iteration 41 ) loss: 0.010587
(Iteration 61 ) loss: 0.000885
(Iteration 81 ) loss: 0.005527
(Iteration 101 ) loss: 0.003968
(Iteration 121 ) loss: 0.003098
(Iteration 141 ) loss: 0.004973
(Iteration 161 ) loss: 0.001296
(Iteration 181 ) loss: 0.003160
(Iteration 201 ) loss: 0.002239
(Iteration 221 ) loss: 0.001127
(Iteration 241 ) loss: 0.000627
(Iteration 261 ) loss: 0.003136
(Iteration 281 ) loss: 0.002231
(Iteration 301 ) loss: 0.000745
(Iteration 321 ) loss: 0.001089
(Iteration 341 ) loss: 0.002442
(Iteration 361 ) loss: 0.009660
(Iteration 381 ) loss: 0.008544
(Iteration 401 ) loss: 0.001472
(Iteration 421 ) loss: 0.006490
(Iteration 441 ) loss: 0.001185
(Iteration 461 ) loss: 0.002762
(Iteration 481 ) loss: 0.000861
(Iteration 501 ) loss: 0.008155
(Iteration 521 ) loss: 0.003366
(Iteration 541 ) loss: 0.003498
(Iteration 561 ) loss: 0.009686
(Iteration 581 ) loss: 0.002024
(Iteration 601 ) loss: 0.001036
(Iteration 621 ) loss: 0.002581
(Iteration 641 ) loss: 0.001661
(Iteration 661 ) loss: 0.000089
(Iteration 681 ) loss: 0.001838
(Iteration 701 ) loss: 0.001050
(Iteration 721 ) loss: 0.003834
(Iteration 741 ) loss: 0.002693
(Iteration 761 ) loss: 0.005564
(Iteration 781 ) loss: 0.000596
(Iteration 801 ) loss: 0.001685
(Iteration 821 ) loss: 0.002693
(Iteration 841 ) loss: 0.002099
(Iteration 861 ) loss: 0.001905
(Iteration 881 ) loss: 0.002596
(Iteration 901 ) loss: 0.001432
(Iteration 921 ) loss: 0.000120
(Iteration 941 ) loss: 0.001606
(Iteration 961 ) loss: 0.005841
(Iteration 981 ) loss: 0.006423
(Epoch 21 % 100) train loss: 0.002647841351397484, eval loss: 0.002704040179244356
(Iteration 1 ) loss: 0.002140
(Iteration 21 ) loss: 0.009105
(Iteration 41 ) loss: 0.005206
(Iteration 61 ) loss: 0.006209
(Iteration 81 ) loss: 0.000260
(Iteration 101 ) loss: 0.005055
(Iteration 121 ) loss: 0.000393
(Iteration 141 ) loss: 0.002514
(Iteration 161 ) loss: 0.001579
(Iteration 181 ) loss: 0.000492
(Iteration 201 ) loss: 0.001382
(Iteration 221 ) loss: 0.004659
(Iteration 241 ) loss: 0.001310
(Iteration 261 ) loss: 0.001031
(Iteration 281 ) loss: 0.000285
(Iteration 301 ) loss: 0.002221
(Iteration 321 ) loss: 0.001982
(Iteration 341 ) loss: 0.000744
(Iteration 361 ) loss: 0.001576
(Iteration 381 ) loss: 0.001437
(Iteration 401 ) loss: 0.000609
(Iteration 421 ) loss: 0.001435
(Iteration 441 ) loss: 0.000157
(Iteration 461 ) loss: 0.001659
(Iteration 481 ) loss: 0.006672
(Iteration 501 ) loss: 0.000372
(Iteration 521 ) loss: 0.006669
(Iteration 541 ) loss: 0.000406
(Iteration 561 ) loss: 0.004149
(Iteration 581 ) loss: 0.002881
(Iteration 601 ) loss: 0.005675
(Iteration 621 ) loss: 0.017405
(Iteration 641 ) loss: 0.005742
(Iteration 661 ) loss: 0.004595
(Iteration 681 ) loss: 0.002287
(Iteration 701 ) loss: 0.011971
(Iteration 721 ) loss: 0.007486
(Iteration 741 ) loss: 0.001947
(Iteration 761 ) loss: 0.000504
(Iteration 781 ) loss: 0.000659
(Iteration 801 ) loss: 0.002624
(Iteration 821 ) loss: 0.001573
(Iteration 841 ) loss: 0.002146
(Iteration 861 ) loss: 0.002761
(Iteration 881 ) loss: 0.006280
(Iteration 901 ) loss: 0.000594
(Iteration 921 ) loss: 0.000717
(Iteration 941 ) loss: 0.000881
(Iteration 961 ) loss: 0.001790
(Iteration 981 ) loss: 0.009597
(Epoch 22 % 100) train loss: 0.002156511668414685, eval loss: 0.0019961347920332637
(Iteration 1 ) loss: 0.005969
(Iteration 21 ) loss: 0.000411
(Iteration 41 ) loss: 0.001607
(Iteration 61 ) loss: 0.001842
(Iteration 81 ) loss: 0.000903
(Iteration 101 ) loss: 0.000084
(Iteration 121 ) loss: 0.000269
(Iteration 141 ) loss: 0.003179
(Iteration 161 ) loss: 0.001223
(Iteration 181 ) loss: 0.005427
(Iteration 201 ) loss: 0.002128
(Iteration 221 ) loss: 0.000704
(Iteration 241 ) loss: 0.007202
(Iteration 261 ) loss: 0.010758
(Iteration 281 ) loss: 0.006390
(Iteration 301 ) loss: 0.004985
(Iteration 321 ) loss: 0.001130
(Iteration 341 ) loss: 0.000243
(Iteration 361 ) loss: 0.001238
(Iteration 381 ) loss: 0.001210
(Iteration 401 ) loss: 0.000274
(Iteration 421 ) loss: 0.000468
(Iteration 441 ) loss: 0.005434
(Iteration 461 ) loss: 0.002184
(Iteration 481 ) loss: 0.012818
(Iteration 501 ) loss: 0.007170
(Iteration 521 ) loss: 0.006943
